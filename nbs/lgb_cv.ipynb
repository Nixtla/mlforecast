{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb976f-eafc-4236-8a27-02e142948574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cceedc-91c9-4d75-bd51-32ce33829ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948c2e2-c5ee-40fe-90d3-dab34d7d6bbf",
   "metadata": {},
   "source": [
    "# LightGBMCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f556b78-d988-4bbe-8d9a-c52b3fe5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import copy\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "from mlforecast import Forecast, TimeSeries\n",
    "from mlforecast.utils import backtest_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc238-1d21-4e47-bda7-1ac1a8665395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class EarlyStopException(BaseException):\n",
    "    ...\n",
    "\n",
    "def _update(bst, n):\n",
    "    for _ in range(n):\n",
    "        bst.update()\n",
    "\n",
    "def _predict(ts, bst, valid, h, time_col, target_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    preds = ts.predict(bst, h, dynamic_dfs, predict_fn, **predict_fn_kwargs).set_index(time_col, append=True)\n",
    "    preds = preds.join(valid)\n",
    "    preds['sq_err'] = (preds['Booster'] - preds[target_col]) ** 2\n",
    "    rmse = preds.groupby(level=0, observed=True)['sq_err'].mean().pow(0.5).mean()\n",
    "    return rmse\n",
    "\n",
    "def _update_and_predict(ts, bst, valid, n, h, time_col, target_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    _update(bst, n)\n",
    "    return _predict(ts, bst, valid, h, time_col, target_col, dynamic_dfs, predict_fn, **predict_fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dd93f-7d13-4905-9fa6-727e9b9c8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LightGBMCV:\n",
    "    def __init__(\n",
    "        self,\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[str] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek\n",
    "        num_threads: int = 1,  # number of threads to use when computing the predictions of each window.\n",
    "    ):\n",
    "        self.num_threads = num_threads\n",
    "        self.ts = TimeSeries(freq, lags, lag_transforms, date_features, 1)\n",
    "        \n",
    "    def _should_stop(self, hist, early_stopping_evals, early_stopping_pct):\n",
    "        if len(hist) < early_stopping_evals + 1:\n",
    "            return False\n",
    "        improvement_pct = 1 - hist[-1][1] / hist[-(early_stopping_evals + 1)][1]\n",
    "        return improvement_pct < early_stopping_pct\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        params: Dict[str, Any] = {},  # lightgbm parameters\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        weights: Sequence[float] = None,  # weight for each window\n",
    "        eval_every: int = 10,  # number of iterations to train before evaluating the full window\n",
    "        fit_on_all: bool = True,  # return model fitted on all data\n",
    "        verbose_eval: bool = True,  # print evaluation metrics\n",
    "        early_stopping_evals: int = 2,  # stop if the score doesn't improve in these many evaluations\n",
    "        early_stopping_pct: float = 0.01,  # score must improve at least in this percentage to keep training\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ):\n",
    "        if eval_every <= 0:\n",
    "            raise ValueError(\n",
    "                \"eval_every should be > 0. If you don't want to evaluate the complete horizon use \"\n",
    "                \"Forecast.cross_validation instead.\"\n",
    "            )\n",
    "        if weights is None:\n",
    "            weights = np.full(n_windows, 1 / n_windows)        \n",
    "        elif len(weights) != n_windows:\n",
    "            raise ValueError('Must specify as many weights as the number of windows')\n",
    "        else:\n",
    "            weights = np.asarray(weights)\n",
    "            \n",
    "        if id_col != 'index':\n",
    "            data = data.set_index(id_col)\n",
    "        \n",
    "        if np.issubdtype(data['ds'].dtype.type, np.integer):\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = self.ts.freq\n",
    "        items = []\n",
    "        bst_threads = os.cpu_count() // self.num_threads\n",
    "        for _, train, valid in backtest_splits(data, n_windows, window_size, freq):\n",
    "            ts = copy.deepcopy(self.ts)\n",
    "            prep = ts.fit_transform(train, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "            ds = lgb.Dataset(prep.drop(columns=[time_col, target_col]), prep[target_col]).construct()\n",
    "            bst = lgb.Booster({**params, 'num_threads': bst_threads}, ds)\n",
    "            bst.predict = partial(bst.predict, num_threads=bst_threads)\n",
    "            valid = valid.set_index(time_col, append=True)\n",
    "            items.append((ts, bst, valid))\n",
    "\n",
    "        hist = []\n",
    "        n_iter = lgb.basic._choose_param_value('num_iterations', params, 100)['num_iterations']\n",
    "        rmses = np.empty(n_windows)\n",
    "\n",
    "        if self.num_threads == 1:\n",
    "            try:\n",
    "                for i in range(0, n_iter, eval_every):\n",
    "                    for j, (ts, bst, valid) in enumerate(items):\n",
    "                        rmses[j] = _update_and_predict(\n",
    "                            ts,\n",
    "                            bst,\n",
    "                            valid,\n",
    "                            eval_every,\n",
    "                            window_size,\n",
    "                            time_col,\n",
    "                            target_col,\n",
    "                            dynamic_dfs,\n",
    "                            predict_fn,\n",
    "                            **predict_fn_kwargs\n",
    "                        )\n",
    "                    rmse = rmses @ weights\n",
    "                    rounds = eval_every + i\n",
    "                    hist.append((rounds, rmse))\n",
    "                    if verbose_eval:\n",
    "                        print(f'[{rounds:,d}] RMSE: {rmse:,f}')                \n",
    "                    if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                        raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}')\n",
    "        else:\n",
    "            try:\n",
    "                with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "                    for i in range(0, n_iter, eval_every):\n",
    "                        futures = []\n",
    "                        for ts, bst, valid in items:\n",
    "                            _update(bst, eval_every)\n",
    "                            future = executor.submit(\n",
    "                                _predict,\n",
    "                                ts,\n",
    "                                bst,\n",
    "                                valid,\n",
    "                                window_size,\n",
    "                                time_col,\n",
    "                                target_col,\n",
    "                                dynamic_dfs,\n",
    "                                predict_fn,\n",
    "                                **predict_fn_kwargs\n",
    "                            )\n",
    "                            futures.append(future)\n",
    "                        rmses[:] = [f.result() for f in futures]\n",
    "                        rmse = rmses @ weights\n",
    "                        rounds = eval_every + i\n",
    "                        hist.append((rounds, rmse))\n",
    "                        if verbose_eval:\n",
    "                            print(f'[{rounds:,d}] RMSE: {rmse:,f}')\n",
    "                        if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                            raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}.')\n",
    "        \n",
    "        self.cv_models_ = [item[1] for item in items]\n",
    "            \n",
    "        if fit_on_all:\n",
    "            self.fcst = Forecast([], lags=[1])\n",
    "            self.fcst.ts = self.ts\n",
    "            self.fcst.models = [lgb.LGBMRegressor(**params)]\n",
    "            self.fcst.fit(\n",
    "                data,\n",
    "                id_col,\n",
    "                time_col,\n",
    "                target_col,\n",
    "                static_features,\n",
    "                dropna,\n",
    "                keep_last_n,\n",
    "            )\n",
    "        return hist\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ):\n",
    "        return self.fcst.predict(horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "    \n",
    "    def cv_predict(self, horizon):\n",
    "        return self.ts.predict(self.cv_models_, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f82f1-a305-4be3-8f63-78dd38a6f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.utils import generate_daily_series\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean, seasonal_rolling_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9d1a-7c10-4b24-bf54-a0d1e765e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_daily_series(1_000, min_length=500, max_length=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921b826-e67f-4d53-8c3c-b85bf46efff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] RMSE: 1.380531\n",
      "[20] RMSE: 0.335082\n",
      "[30] RMSE: 0.166009\n",
      "[40] RMSE: 0.146650\n",
      "[50] RMSE: 0.144134\n",
      "[60] RMSE: 0.143820\n",
      "[70] RMSE: 0.143783\n",
      "Early stopping at round 70.\n",
      "CPU times: user 32.1 s, sys: 229 ms, total: 32.3 s\n",
      "Wall time: 11.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 1.3805311266473483),\n",
       " (20, 0.3350815367875217),\n",
       " (30, 0.16600853805617782),\n",
       " (40, 0.14664959228063223),\n",
       " (50, 0.144134480339),\n",
       " (60, 0.14382003487619435),\n",
       " (70, 0.1437826285951646)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = LightGBMCV(\n",
    "    freq='D',\n",
    "    lags=[i + 1 for i in range(4)],\n",
    "    lag_transforms={\n",
    "        7 : [expanding_mean] + [(rolling_mean, 7)],\n",
    "        14: [expanding_mean] + [(rolling_mean, 14)],\n",
    "    },\n",
    "    num_threads=4,\n",
    ")\n",
    "%time cv.fit(data, n_windows=4, window_size=14, params={'verbosity': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c23a2-77da-4c80-8fbc-40e0bc474658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.247302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.249704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.251363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.249986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>1.250885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_998</th>\n",
       "      <td>2002-05-08</td>\n",
       "      <td>3.250413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-30</td>\n",
       "      <td>3.249795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-31</td>\n",
       "      <td>4.249041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-01</td>\n",
       "      <td>5.247625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-02</td>\n",
       "      <td>6.249185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor\n",
       "unique_id                          \n",
       "id_000    2001-11-03       0.247302\n",
       "id_000    2001-11-04       1.249704\n",
       "id_000    2001-11-05       2.251363\n",
       "id_000    2001-11-06       3.249986\n",
       "id_001    2001-07-01       1.250885\n",
       "...              ...            ...\n",
       "id_998    2002-05-08       3.250413\n",
       "id_999    2002-07-30       3.249795\n",
       "id_999    2002-07-31       4.249041\n",
       "id_999    2002-08-01       5.247625\n",
       "id_999    2002-08-02       6.249185\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.predict(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26b1c8-8def-4471-bfc7-196f2c68d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Booster</th>\n",
       "      <th>Booster2</th>\n",
       "      <th>Booster3</th>\n",
       "      <th>Booster4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.252332</td>\n",
       "      <td>0.252214</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.252412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.251639</td>\n",
       "      <td>1.251870</td>\n",
       "      <td>1.252035</td>\n",
       "      <td>1.251550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.250045</td>\n",
       "      <td>2.251298</td>\n",
       "      <td>2.251576</td>\n",
       "      <td>2.251924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.249621</td>\n",
       "      <td>3.249849</td>\n",
       "      <td>3.249896</td>\n",
       "      <td>3.249992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>1.251639</td>\n",
       "      <td>1.251870</td>\n",
       "      <td>1.252035</td>\n",
       "      <td>1.251550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_998</th>\n",
       "      <td>2002-05-08</td>\n",
       "      <td>3.250212</td>\n",
       "      <td>3.250324</td>\n",
       "      <td>3.250011</td>\n",
       "      <td>3.250453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-30</td>\n",
       "      <td>3.250212</td>\n",
       "      <td>3.250324</td>\n",
       "      <td>3.240011</td>\n",
       "      <td>3.250284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-31</td>\n",
       "      <td>4.242646</td>\n",
       "      <td>4.229230</td>\n",
       "      <td>4.239973</td>\n",
       "      <td>4.247728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-01</td>\n",
       "      <td>5.247403</td>\n",
       "      <td>5.247179</td>\n",
       "      <td>5.248409</td>\n",
       "      <td>5.249136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-02</td>\n",
       "      <td>6.247432</td>\n",
       "      <td>6.248114</td>\n",
       "      <td>6.246020</td>\n",
       "      <td>6.247379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds   Booster  Booster2  Booster3  Booster4\n",
       "unique_id                                                   \n",
       "id_000    2001-11-03  0.252332  0.252214  0.251296  0.252412\n",
       "id_000    2001-11-04  1.251639  1.251870  1.252035  1.251550\n",
       "id_000    2001-11-05  2.250045  2.251298  2.251576  2.251924\n",
       "id_000    2001-11-06  3.249621  3.249849  3.249896  3.249992\n",
       "id_001    2001-07-01  1.251639  1.251870  1.252035  1.251550\n",
       "...              ...       ...       ...       ...       ...\n",
       "id_998    2002-05-08  3.250212  3.250324  3.250011  3.250453\n",
       "id_999    2002-07-30  3.250212  3.250324  3.240011  3.250284\n",
       "id_999    2002-07-31  4.242646  4.229230  4.239973  4.247728\n",
       "id_999    2002-08-01  5.247403  5.247179  5.248409  5.249136\n",
       "id_999    2002-08-02  6.247432  6.248114  6.246020  6.247379\n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_predict(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
