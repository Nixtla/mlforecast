{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb976f-eafc-4236-8a27-02e142948574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cceedc-91c9-4d75-bd51-32ce33829ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948c2e2-c5ee-40fe-90d3-dab34d7d6bbf",
   "metadata": {},
   "source": [
    "# LightGBMCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f556b78-d988-4bbe-8d9a-c52b3fe5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import copy\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mlforecast import Forecast, TimeSeries\n",
    "from mlforecast.utils import backtest_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc238-1d21-4e47-bda7-1ac1a8665395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _mape(y_true, y_pred):\n",
    "    abs_pct_err = abs(y_true - y_pred) / y_true\n",
    "    return abs_pct_err.groupby(y_true.index.get_level_values(0), observed=True).mean().mean()\n",
    "\n",
    "def _rmse(y_true, y_pred):\n",
    "    sq_err = (y_true - y_pred) ** 2\n",
    "    return sq_err.groupby(y_true.index.get_level_values(0), observed=True).mean().pow(0.5).mean()\n",
    "\n",
    "_metric2fn = {'mape': _mape, 'rmse': _rmse}\n",
    "\n",
    "def _update(bst, n):\n",
    "    for _ in range(n):\n",
    "        bst.update()\n",
    "\n",
    "def _predict(ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    preds = ts.predict(bst, h, dynamic_dfs, predict_fn, **predict_fn_kwargs).set_index(time_col, append=True)\n",
    "    return valid.join(preds)\n",
    "\n",
    "def _update_and_predict(ts, bst, valid, n, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    _update(bst, n)\n",
    "    return _predict(ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dd93f-7d13-4905-9fa6-727e9b9c8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LightGBMCV:\n",
    "    def __init__(\n",
    "        self,\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[str] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek\n",
    "        differences: Optional[List[int]] = None,  # differences to apply to the series before fitting        \n",
    "        num_threads: int = 1,  # number of threads to use when computing the predictions of each window.\n",
    "    ):\n",
    "        self.num_threads = num_threads\n",
    "        cpu_count = os.cpu_count()\n",
    "        if cpu_count is None:\n",
    "            num_cpus = 1\n",
    "        else:\n",
    "            num_cpus = cpu_count\n",
    "        self.bst_threads = num_cpus // num_threads\n",
    "        self.ts = TimeSeries(freq, lags, lag_transforms, date_features, differences, self.bst_threads)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'{self.__class__.__name__}('\n",
    "            f'ts={self.ts}, '\n",
    "            f'num_threads={self.num_threads}, '\n",
    "            f'bst_threads={self.bst_threads})'\n",
    "        )\n",
    "        \n",
    "    def _should_stop(self, hist, early_stopping_evals, early_stopping_pct):\n",
    "        if len(hist) < early_stopping_evals + 1:\n",
    "            return False\n",
    "        improvement_pct = 1 - hist[-1][1] / hist[-(early_stopping_evals + 1)][1]\n",
    "        return improvement_pct < early_stopping_pct\n",
    "    \n",
    "    def setup(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        params: Dict[str, Any] = {},  # lightgbm parameters\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "        weights: Sequence[float] = None,  # weight for each window\n",
    "        metric: Union[str, Callable] = 'mape',  # evaluation metric        \n",
    "    ):\n",
    "        if weights is None:\n",
    "            self.weights = np.full(n_windows, 1 / n_windows)        \n",
    "        elif len(weights) != n_windows:\n",
    "            raise ValueError('Must specify as many weights as the number of windows')\n",
    "        else:\n",
    "            self.weights = np.asarray(weights)\n",
    "        if callable(metric):\n",
    "            self.metric_fn = metric\n",
    "            self.metric_name = 'custom_metric'\n",
    "        else:\n",
    "            if metric not in _metric2fn:\n",
    "                raise ValueError(f'{metric} is not one of the implemented metrics: ({\", \".join(_metric2fn.keys())})')\n",
    "            self.metric_fn = _metric2fn[metric]\n",
    "            self.metric_name = metric\n",
    "\n",
    "        if id_col != 'index':\n",
    "            data = data.set_index(id_col)\n",
    "        \n",
    "        if np.issubdtype(data[time_col].dtype.type, np.integer):\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = self.ts.freq\n",
    "        self.items = []\n",
    "        self.window_size = window_size\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "        for _, train, valid in backtest_splits(data, n_windows, window_size, freq):\n",
    "            ts = copy.deepcopy(self.ts)\n",
    "            prep = ts.fit_transform(train, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "            ds = lgb.Dataset(prep.drop(columns=[time_col, target_col]), prep[target_col]).construct()\n",
    "            bst = lgb.Booster({**params, 'num_threads': self.bst_threads}, ds)\n",
    "            bst.predict = partial(bst.predict, num_threads=self.bst_threads)\n",
    "            valid = valid.set_index(time_col, append=True)\n",
    "            self.items.append((ts, bst, valid))\n",
    "        return self\n",
    "\n",
    "    def _single_threaded_partial_fit(\n",
    "        self,\n",
    "        metric_values,\n",
    "        n_iter,\n",
    "        dynamic_dfs,\n",
    "        predict_fn,\n",
    "        **predict_fn_kwargs,\n",
    "    ):  \n",
    "        for j, (ts, bst, valid) in enumerate(self.items):                        \n",
    "            preds = _update_and_predict(\n",
    "                ts,\n",
    "                bst,\n",
    "                valid,\n",
    "                n_iter,\n",
    "                self.window_size,\n",
    "                self.time_col,\n",
    "                dynamic_dfs,\n",
    "                predict_fn,\n",
    "                **predict_fn_kwargs\n",
    "            )\n",
    "            metric_values[j] = self.metric_fn(preds[self.target_col], preds['Booster'])\n",
    "\n",
    "    def _multithreaded_partial_fit(\n",
    "        self,\n",
    "        metric_values,\n",
    "        n_iter,\n",
    "        dynamic_dfs,\n",
    "        predict_fn,\n",
    "        **predict_fn_kwargs,\n",
    "    ):                           \n",
    "        with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "            futures = []\n",
    "            for ts, bst, valid in self.items:\n",
    "                _update(bst, n_iter)\n",
    "                future = executor.submit(\n",
    "                    _predict,\n",
    "                    ts,\n",
    "                    bst,\n",
    "                    valid,\n",
    "                    self.window_size,\n",
    "                    self.time_col,\n",
    "                    dynamic_dfs,\n",
    "                    predict_fn,\n",
    "                    **predict_fn_kwargs\n",
    "                )\n",
    "                futures.append(future)\n",
    "            cv_preds = [f.result() for f in futures]\n",
    "        metric_values[:] = [self.metric_fn(preds[self.target_col], preds['Booster']) for preds in cv_preds]\n",
    "        \n",
    "    def partial_fit(\n",
    "        self,\n",
    "        n_iter: int, # number of boosting iterations to run\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ):\n",
    "        metric_values = np.empty(len(self.items))\n",
    "        if self.num_threads == 1:\n",
    "            self._single_threaded_partial_fit(metric_values, n_iter, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "        else:\n",
    "            self._multithreaded_partial_fit(metric_values, n_iter, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "        return metric_values @ self.weights\n",
    "   \n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        params: Dict[str, Any] = {},  # lightgbm parameters\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        weights: Sequence[float] = None,  # weight for each window\n",
    "        eval_every: int = 10,  # number of iterations to train before evaluating the full window\n",
    "        fit_on_all: bool = False,  # return model fitted on all data\n",
    "        compute_cv_preds: bool = False,  # compute predictions on all folds using final models\n",
    "        verbose_eval: bool = True,  # print evaluation metrics\n",
    "        metric: Union[str, Callable] = 'mape',  # evaluation metric\n",
    "        early_stopping_evals: int = 2,  # stop if the score doesn't improve in these many evaluations\n",
    "        early_stopping_pct: float = 0.01,  # score must improve at least in this percentage to keep training\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ):\n",
    "        self.setup(\n",
    "            data,\n",
    "            n_windows,\n",
    "            window_size,\n",
    "            params,\n",
    "            id_col,\n",
    "            time_col,\n",
    "            target_col,\n",
    "            static_features,\n",
    "            dropna,\n",
    "            keep_last_n,\n",
    "            weights,\n",
    "            metric,\n",
    "        )\n",
    "        hist = []\n",
    "        n_iter = lgb.basic._choose_param_value('num_iterations', params, 100)['num_iterations']\n",
    "        for i in range(0, n_iter, eval_every):\n",
    "            metric_value = self.partial_fit(eval_every, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "            rounds = eval_every + i\n",
    "            hist.append((rounds, metric_value))\n",
    "            if verbose_eval:\n",
    "                print(f'[{rounds:,d}] {self.metric_name}: {metric_value:,f}')                \n",
    "            if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                print(f\"Early stopping at round {rounds:,}\")\n",
    "                break        \n",
    "\n",
    "        self.cv_models_ = [item[1] for item in self.items]\n",
    "        if compute_cv_preds:\n",
    "            with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "                futures = []            \n",
    "                for ts, bst, valid in self.items:\n",
    "                    future = executor.submit(\n",
    "                        _predict,\n",
    "                        ts,\n",
    "                        bst,\n",
    "                        valid,\n",
    "                        window_size,\n",
    "                        time_col,\n",
    "                        dynamic_dfs,\n",
    "                        predict_fn,\n",
    "                        **predict_fn_kwargs\n",
    "                    )\n",
    "                    futures.append(future)            \n",
    "                self.cv_preds_ = [f.result() for f in futures]\n",
    "\n",
    "        if fit_on_all:\n",
    "            params['n_estimators'] = rounds\n",
    "            self.fcst = Forecast([])\n",
    "            self.fcst.ts = self.ts\n",
    "            self.fcst.models = [lgb.LGBMRegressor(**params)]\n",
    "            self.fcst.fit(\n",
    "                data,\n",
    "                id_col,\n",
    "                time_col,\n",
    "                target_col,\n",
    "                static_features,\n",
    "                dropna,\n",
    "                keep_last_n,\n",
    "            )\n",
    "        else:\n",
    "            self.ts._fit(data, id_col, time_col, target_col, static_features, keep_last_n)\n",
    "        return hist\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Computes the predictions of the final model trained using all of the data.\"\"\"        \n",
    "        if not hasattr(self, 'fcst'):\n",
    "            raise ValueError('Must call fit with fit_on_all=True before. Did you mean cv_predict?')\n",
    "        return self.fcst.predict(horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "    \n",
    "    def cv_predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Computes the predictions of the models fitted during the CV step.\"\"\"\n",
    "        return self.ts.predict(self.cv_models_, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f82f1-a305-4be3-8f63-78dd38a6f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_fail\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean, seasonal_rolling_mean\n",
    "\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9d1a-7c10-4b24-bf54-a0d1e765e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_daily_series(1_000, min_length=500, max_length=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5a4aa-55ab-42ad-9917-fcbb3ad3cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_windows = 2\n",
    "window_size = 14\n",
    "params = {'verbosity': -1}\n",
    "config = dict(\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        7 : [(rolling_mean, 7)],\n",
    "        14: [(rolling_mean, 7)],\n",
    "    },\n",
    "    num_threads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44e00a-c83c-41a7-ada1-7c094a021922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] mape: 4.927520\n",
      "[20] mape: 2.953376\n",
      "[30] mape: 1.026298\n",
      "[40] mape: 0.798347\n",
      "[50] mape: 0.723009\n",
      "[60] mape: 0.697055\n",
      "[70] mape: 0.688403\n",
      "[80] mape: 0.685681\n",
      "[90] mape: 0.684835\n",
      "Early stopping at round 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 4.927519638482391),\n",
       " (20, 2.953376099241727),\n",
       " (30, 1.026298126222729),\n",
       " (40, 0.7983465295648418),\n",
       " (50, 0.7230094339375586),\n",
       " (60, 0.6970552320257407),\n",
       " (70, 0.6884026039892563),\n",
       " (80, 0.6856806008289287),\n",
       " (90, 0.6848354338163578)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = LightGBMCV(**config)\n",
    "cv.fit(data, n_windows, window_size, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d47bb-b95e-4b10-928c-200144b02d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Booster</th>\n",
       "      <th>Booster2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.252886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.249231</td>\n",
       "      <td>1.249613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.250441</td>\n",
       "      <td>2.249819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.249947</td>\n",
       "      <td>3.250130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>4.252896</td>\n",
       "      <td>4.252406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>5.249912</td>\n",
       "      <td>5.249056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>6.249346</td>\n",
       "      <td>6.249097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>0.252552</td>\n",
       "      <td>0.249360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>1.248313</td>\n",
       "      <td>1.250127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>2.249805</td>\n",
       "      <td>2.251380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds   Booster  Booster2\n",
       "unique_id                               \n",
       "id_000    2001-11-03  0.251411  0.252886\n",
       "id_000    2001-11-04  1.249231  1.249613\n",
       "id_000    2001-11-05  2.250441  2.249819\n",
       "id_000    2001-11-06  3.249947  3.250130\n",
       "id_000    2001-11-07  4.252896  4.252406\n",
       "...              ...       ...       ...\n",
       "id_999    2002-08-08  5.249912  5.249056\n",
       "id_999    2002-08-09  6.249346  6.249097\n",
       "id_999    2002-08-10  0.252552  0.249360\n",
       "id_999    2002-08-11  1.248313  1.250127\n",
       "id_999    2002-08-12  2.249805  2.251380\n",
       "\n",
       "[14000 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562167f6-a600-4693-a482-f4d1ff365dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: cv.predict(1), contains='Must call fit with fit_on_all=True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef177fe-d9c5-46c7-b2c1-3d50012bdaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] rmse: 0.936530\n",
      "[20] rmse: 0.442142\n",
      "[30] rmse: 0.171922\n",
      "[40] rmse: 0.152935\n",
      "[50] rmse: 0.150601\n",
      "[60] rmse: 0.150273\n",
      "[70] rmse: 0.150235\n",
      "Early stopping at round 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 0.9365296382142947),\n",
       " (20, 0.4421418925471978),\n",
       " (30, 0.1719218176729842),\n",
       " (40, 0.152935170306639),\n",
       " (50, 0.15060126754993408),\n",
       " (60, 0.15027318065520012),\n",
       " (70, 0.150234674236362)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = LightGBMCV(**config)\n",
    "cv2.fit(data, n_windows, window_size, params, metric='rmse', fit_on_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26b1c8-8def-4471-bfc7-196f2c68d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.253787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.250694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.249748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.250048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>4.253456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>5.248980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>6.247837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>0.251838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>1.250694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>2.250688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor\n",
       "unique_id                          \n",
       "id_000    2001-11-03       0.253787\n",
       "id_000    2001-11-04       1.250694\n",
       "id_000    2001-11-05       2.249748\n",
       "id_000    2001-11-06       3.250048\n",
       "id_000    2001-11-07       4.253456\n",
       "...              ...            ...\n",
       "id_999    2002-08-08       5.248980\n",
       "id_999    2002-08-09       6.247837\n",
       "id_999    2002-08-10       0.251838\n",
       "id_999    2002-08-11       1.250694\n",
       "id_999    2002-08-12       2.250688\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bddf5-4892-46a8-b7c6-992712835510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365296382142947"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3 = LightGBMCV(**config)\n",
    "cv3.setup(data, n_windows, window_size, params, metric='rmse')\n",
    "cv3.partial_fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2818c33-dd57-4abf-bb73-5d8748c3b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4421418925471978"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.partial_fit(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
