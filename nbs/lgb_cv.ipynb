{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb976f-eafc-4236-8a27-02e142948574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cceedc-91c9-4d75-bd51-32ce33829ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948c2e2-c5ee-40fe-90d3-dab34d7d6bbf",
   "metadata": {},
   "source": [
    "# LightGBMCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f556b78-d988-4bbe-8d9a-c52b3fe5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import copy\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mlforecast import Forecast, TimeSeries\n",
    "from mlforecast.utils import backtest_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc238-1d21-4e47-bda7-1ac1a8665395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class EarlyStopException(BaseException):\n",
    "    ...\n",
    "    \n",
    "def _mape(y_true, y_pred):\n",
    "    abs_pct_err = abs(y_true - y_pred) / y_true\n",
    "    return abs_pct_err.groupby(y_true.index.get_level_values(0), observed=True).mean().mean()\n",
    "\n",
    "def _rmse(y_true, y_pred):\n",
    "    sq_err = (y_true - y_pred) ** 2\n",
    "    return sq_err.groupby(y_true.index.get_level_values(0), observed=True).mean().pow(0.5).mean()\n",
    "\n",
    "def _update(bst, n):\n",
    "    for _ in range(n):\n",
    "        bst.update()\n",
    "\n",
    "def _predict(ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    preds = ts.predict(bst, h, dynamic_dfs, predict_fn, **predict_fn_kwargs).set_index(time_col, append=True)\n",
    "    preds = preds.join(valid)\n",
    "    return preds\n",
    "\n",
    "def _update_and_predict(ts, bst, valid, n, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):\n",
    "    _update(bst, n)\n",
    "    return _predict(ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dd93f-7d13-4905-9fa6-727e9b9c8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LightGBMCV:\n",
    "    def __init__(\n",
    "        self,\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[str] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek\n",
    "        num_threads: int = 1,  # number of threads to use when computing the predictions of each window.\n",
    "    ):\n",
    "        self.num_threads = num_threads\n",
    "        cpu_count = os.cpu_count()\n",
    "        if cpu_count is None:\n",
    "            num_cpus = 1\n",
    "        else:\n",
    "            num_cpus = cpu_count\n",
    "        self.bst_threads = num_cpus // num_threads\n",
    "        self.ts = TimeSeries(freq, lags, lag_transforms, date_features, self.bst_threads)\n",
    "        \n",
    "    def _should_stop(self, hist, early_stopping_evals, early_stopping_pct):\n",
    "        if len(hist) < early_stopping_evals + 1:\n",
    "            return False\n",
    "        improvement_pct = 1 - hist[-1][1] / hist[-(early_stopping_evals + 1)][1]\n",
    "        return improvement_pct < early_stopping_pct\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        params: Dict[str, Any] = {},  # lightgbm parameters\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        weights: Sequence[float] = None,  # weight for each window\n",
    "        eval_every: int = 10,  # number of iterations to train before evaluating the full window\n",
    "        fit_on_all: bool = False,  # return model fitted on all data\n",
    "        compute_cv_preds: bool = False,  # compute predictions on all folds using final models\n",
    "        verbose_eval: bool = True,  # print evaluation metrics\n",
    "        metric: Union[str, Callable] = 'mape',  # evaluation metric\n",
    "        early_stopping_evals: int = 2,  # stop if the score doesn't improve in these many evaluations\n",
    "        early_stopping_pct: float = 0.01,  # score must improve at least in this percentage to keep training\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ):\n",
    "        if eval_every <= 0:\n",
    "            raise ValueError(\n",
    "                \"eval_every should be > 0. If you don't want to evaluate the complete horizon use \"\n",
    "                \"Forecast.cross_validation instead.\"\n",
    "            )\n",
    "        if weights is None:\n",
    "            use_weights = np.full(n_windows, 1 / n_windows)        \n",
    "        elif len(weights) != n_windows:\n",
    "            raise ValueError('Must specify as many weights as the number of windows')\n",
    "        else:\n",
    "            use_weights = np.asarray(weights)\n",
    "        metric2fn = {'mape': _mape, 'rmse': _rmse}\n",
    "        if callable(metric):\n",
    "            metric_fn = metric\n",
    "            metric_name = 'metric'\n",
    "        else:\n",
    "            if metric not in metric2fn:\n",
    "                raise ValueError(f'{metric} is not one of the implemented metrics: ({\", \".join(metric2fn.keys())})')\n",
    "            metric_fn = metric2fn[metric]\n",
    "            metric_name = metric            \n",
    "            \n",
    "        if id_col != 'index':\n",
    "            data = data.set_index(id_col)\n",
    "        \n",
    "        if np.issubdtype(data['ds'].dtype.type, np.integer):\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = self.ts.freq\n",
    "        items = []\n",
    "        for _, train, valid in backtest_splits(data, n_windows, window_size, freq):\n",
    "            ts = copy.deepcopy(self.ts)\n",
    "            prep = ts.fit_transform(train, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "            ds = lgb.Dataset(prep.drop(columns=[time_col, target_col]), prep[target_col]).construct()\n",
    "            bst = lgb.Booster({**params, 'num_threads': self.bst_threads}, ds)\n",
    "            bst.predict = partial(bst.predict, num_threads=self.bst_threads)\n",
    "            valid = valid.set_index(time_col, append=True)\n",
    "            items.append((ts, bst, valid))\n",
    "\n",
    "        hist = []\n",
    "        n_iter = lgb.basic._choose_param_value('num_iterations', params, 100)['num_iterations']\n",
    "        metric_values = np.empty(n_windows)\n",
    "\n",
    "        if self.num_threads == 1:\n",
    "            try:\n",
    "                for i in range(0, n_iter, eval_every):\n",
    "                    for j, (ts, bst, valid) in enumerate(items):                        \n",
    "                        preds = _update_and_predict(\n",
    "                            ts,\n",
    "                            bst,\n",
    "                            valid,\n",
    "                            eval_every,\n",
    "                            window_size,\n",
    "                            time_col,\n",
    "                            dynamic_dfs,\n",
    "                            predict_fn,\n",
    "                            **predict_fn_kwargs\n",
    "                        )\n",
    "                        metric_values[j] = metric_fn(preds[target_col], preds['Booster'])\n",
    "                    metric_value = metric_values @ use_weights\n",
    "                    rounds = eval_every + i\n",
    "                    hist.append((rounds, metric_value))\n",
    "                    if verbose_eval:\n",
    "                        print(f'[{rounds:,d}] {metric_name}: {metric_value:,f}')                \n",
    "                    if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                        raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}')\n",
    "        else:\n",
    "            try:\n",
    "                with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "                    for i in range(0, n_iter, eval_every):\n",
    "                        futures = []\n",
    "                        for ts, bst, valid in items:\n",
    "                            _update(bst, eval_every)\n",
    "                            future = executor.submit(\n",
    "                                _predict,\n",
    "                                ts,\n",
    "                                bst,\n",
    "                                valid,\n",
    "                                window_size,\n",
    "                                time_col,\n",
    "                                dynamic_dfs,\n",
    "                                predict_fn,\n",
    "                                **predict_fn_kwargs\n",
    "                            )\n",
    "                            futures.append(future)\n",
    "                        cv_preds = [f.result() for f in futures]\n",
    "                        metric_values[:] = [metric_fn(preds[target_col], preds['Booster']) for preds in cv_preds]\n",
    "                        metric_value = metric_values @ use_weights\n",
    "                        rounds = eval_every + i\n",
    "                        hist.append((rounds, metric_value))\n",
    "                        if verbose_eval:\n",
    "                            print(f'[{rounds:,d}] {metric_name}: {metric_value:,f}')\n",
    "                        if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                            raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}.')\n",
    "        \n",
    "        self.cv_models_ = [item[1] for item in items]\n",
    "        if compute_cv_preds:\n",
    "            with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "                futures = []            \n",
    "                for ts, bst, valid in items:\n",
    "                    future = executor.submit(\n",
    "                        _predict,\n",
    "                        ts,\n",
    "                        bst,\n",
    "                        valid,\n",
    "                        window_size,\n",
    "                        time_col,\n",
    "                        dynamic_dfs,\n",
    "                        predict_fn,\n",
    "                        **predict_fn_kwargs\n",
    "                    )\n",
    "                    futures.append(future)            \n",
    "                self.cv_preds_ = [f.result() for f in futures]\n",
    "\n",
    "        if fit_on_all:\n",
    "            params['num_iterations'] = rounds\n",
    "            self.fcst = Forecast([])\n",
    "            self.fcst.ts = self.ts\n",
    "            self.fcst.models = [lgb.LGBMRegressor(**params)]\n",
    "            self.fcst.fit(\n",
    "                data,\n",
    "                id_col,\n",
    "                time_col,\n",
    "                target_col,\n",
    "                static_features,\n",
    "                dropna,\n",
    "                keep_last_n,\n",
    "            )\n",
    "        else:\n",
    "            self.ts._fit(data, id_col, time_col, target_col, static_features, keep_last_n)\n",
    "        return hist\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Computes the predictions of the final model trained using all of the data.\"\"\"        \n",
    "        if not hasattr(self, 'fcst'):\n",
    "            raise ValueError('Must call fit with fit_on_all=True before. Did you mean cv_predict?')\n",
    "        return self.fcst.predict(horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs)\n",
    "    \n",
    "    def cv_predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Computes the predictions of the models fitted during the CV step.\"\"\"\n",
    "        return self.ts.predict(self.cv_models_, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f82f1-a305-4be3-8f63-78dd38a6f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_fail\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean, seasonal_rolling_mean\n",
    "\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9d1a-7c10-4b24-bf54-a0d1e765e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_daily_series(1_000, min_length=500, max_length=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921b826-e67f-4d53-8c3c-b85bf46efff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] mape: 4.802779\n",
      "[20] mape: 2.769556\n",
      "[30] mape: 1.014805\n",
      "[40] mape: 0.789982\n",
      "[50] mape: 0.715410\n",
      "[60] mape: 0.689871\n",
      "[70] mape: 0.681331\n",
      "[80] mape: 0.678559\n",
      "[90] mape: 0.677732\n",
      "Early stopping at round 90.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 4.802779209175606),\n",
       " (20, 2.769555796385574),\n",
       " (30, 1.0148054032228888),\n",
       " (40, 0.7899819488940557),\n",
       " (50, 0.7154097791759417),\n",
       " (60, 0.6898714371663679),\n",
       " (70, 0.681331404792988),\n",
       " (80, 0.678559226720473),\n",
       " (90, 0.677732335081906)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        7 : [(rolling_mean, 7)],\n",
    "        14: [(rolling_mean, 7)],\n",
    "    },\n",
    "    num_threads=4,\n",
    ")\n",
    "cv = LightGBMCV(**config)\n",
    "cv.fit(data, n_windows=4, window_size=14, params={'verbosity': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb878e37-b526-42b3-afec-2e8b5d6c1d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Booster</th>\n",
       "      <th>Booster2</th>\n",
       "      <th>Booster3</th>\n",
       "      <th>Booster4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.248238</td>\n",
       "      <td>0.251411</td>\n",
       "      <td>0.252886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.249829</td>\n",
       "      <td>1.250071</td>\n",
       "      <td>1.249231</td>\n",
       "      <td>1.249613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.250443</td>\n",
       "      <td>2.250281</td>\n",
       "      <td>2.250441</td>\n",
       "      <td>2.249819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.249589</td>\n",
       "      <td>3.249735</td>\n",
       "      <td>3.249947</td>\n",
       "      <td>3.250130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>4.252215</td>\n",
       "      <td>4.251210</td>\n",
       "      <td>4.252896</td>\n",
       "      <td>4.252406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>5.249569</td>\n",
       "      <td>5.250838</td>\n",
       "      <td>5.249912</td>\n",
       "      <td>5.249056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>6.249209</td>\n",
       "      <td>6.249434</td>\n",
       "      <td>6.249346</td>\n",
       "      <td>6.249097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>0.250684</td>\n",
       "      <td>0.251182</td>\n",
       "      <td>0.252552</td>\n",
       "      <td>0.249360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>1.250043</td>\n",
       "      <td>1.248775</td>\n",
       "      <td>1.248313</td>\n",
       "      <td>1.250127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>2.245958</td>\n",
       "      <td>2.249159</td>\n",
       "      <td>2.249805</td>\n",
       "      <td>2.251380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds   Booster  Booster2  Booster3  Booster4\n",
       "unique_id                                                   \n",
       "id_000    2001-11-03  0.253586  0.248238  0.251411  0.252886\n",
       "id_000    2001-11-04  1.249829  1.250071  1.249231  1.249613\n",
       "id_000    2001-11-05  2.250443  2.250281  2.250441  2.249819\n",
       "id_000    2001-11-06  3.249589  3.249735  3.249947  3.250130\n",
       "id_000    2001-11-07  4.252215  4.251210  4.252896  4.252406\n",
       "...              ...       ...       ...       ...       ...\n",
       "id_999    2002-08-08  5.249569  5.250838  5.249912  5.249056\n",
       "id_999    2002-08-09  6.249209  6.249434  6.249346  6.249097\n",
       "id_999    2002-08-10  0.250684  0.251182  0.252552  0.249360\n",
       "id_999    2002-08-11  1.250043  1.248775  1.248313  1.250127\n",
       "id_999    2002-08-12  2.245958  2.249159  2.249805  2.251380\n",
       "\n",
       "[14000 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562167f6-a600-4693-a482-f4d1ff365dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: cv.predict(1), contains='Must call fit with fit_on_all=True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef177fe-d9c5-46c7-b2c1-3d50012bdaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] rmse: 0.927015\n",
      "[20] rmse: 0.449317\n",
      "[30] rmse: 0.171730\n",
      "[40] rmse: 0.152624\n",
      "[50] rmse: 0.150212\n",
      "[60] rmse: 0.149881\n",
      "[70] rmse: 0.149869\n",
      "Early stopping at round 70.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 0.9270148870967521),\n",
       " (20, 0.44931746152420554),\n",
       " (30, 0.17173020966422342),\n",
       " (40, 0.15262354479234572),\n",
       " (50, 0.15021186993934657),\n",
       " (60, 0.14988069283784167),\n",
       " (70, 0.149868546603391)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = LightGBMCV(**config)\n",
    "cv2.fit(data, n_windows=4, window_size=14, metric='rmse', fit_on_all=True, params={'verbosity': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26b1c8-8def-4471-bfc7-196f2c68d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.252406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.249564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.249034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.250075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>4.254464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>5.249972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>6.249404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>0.250580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>1.249169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>2.249718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor\n",
       "unique_id                          \n",
       "id_000    2001-11-03       0.252406\n",
       "id_000    2001-11-04       1.249564\n",
       "id_000    2001-11-05       2.249034\n",
       "id_000    2001-11-06       3.250075\n",
       "id_000    2001-11-07       4.254464\n",
       "...              ...            ...\n",
       "id_999    2002-08-08       5.249972\n",
       "id_999    2002-08-09       6.249404\n",
       "id_999    2002-08-10       0.250580\n",
       "id_999    2002-08-11       1.249169\n",
       "id_999    2002-08-12       2.249718\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.predict(14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
