{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9693434b-0290-4ffd-88f9-a4267c11b548",
   "metadata": {},
   "source": [
    "# Quick start (distributed)\n",
    "\n",
    "> Minimal example of distributed training with MLForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a829526-7edd-4c9d-9aba-95441d184b31",
   "metadata": {},
   "source": [
    "## Main concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc46367-361e-4e2b-9297-31a98a5c4b09",
   "metadata": {},
   "source": [
    "The main component for distributed training with mlforecast is the `DistributedMLForecast` class, which abstracts away:\n",
    "\n",
    "* Feature engineering and model training through `DistributedMLForecast.fit`\n",
    "* Feature updates and multi step ahead predictions through `DistributedMLForecast.predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088eaaf-6c5b-4292-b420-da2916233558",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d06187-a523-46de-af83-17f17d63849d",
   "metadata": {},
   "source": [
    "In order to perform distributed training you need a dask cluster. In this example we'll use a local cluster but you can replace it with any other type of remote cluster and the processing will take place there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9225b4-4eeb-445f-b4bd-fd9bef11cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=2, threads_per_worker=1)  # change this to use a remote cluster\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa9351-46ab-4f64-9bbc-86d0069630cd",
   "metadata": {},
   "source": [
    "## Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b91ff7-2661-46a5-a127-a1fce8c02611",
   "metadata": {},
   "source": [
    "The data is expected to be a dask dataframe in long format, that is, each row represents an observation of a single serie at a given time, with at least three columns:\n",
    "\n",
    "* `id_col`: column that identifies each serie.\n",
    "* `target_col`: column that has the series values at each timestamp.\n",
    "* `time_col`: column that contains the time the series value was observed. These are usually timestamps, but can also be consecutive integers.\n",
    "\n",
    "**You need to make sure that each serie is only in a single partition**. You can do so by setting the id_col as the index in dask or with repartitionByRange in spark.\n",
    "\n",
    "Here we present an example with synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1f392-29e3-4328-af11-5e1935aa0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09142c9-6105-4c39-9503-9b55054f66e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.497650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.554489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.734311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>4.028039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>5.366009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2000-06-25</td>\n",
       "      <td>34.165302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2000-06-26</td>\n",
       "      <td>28.277320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2000-06-27</td>\n",
       "      <td>29.450129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27001</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2000-06-28</td>\n",
       "      <td>30.241885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27002</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2000-06-29</td>\n",
       "      <td>31.576907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27003 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds          y\n",
       "0         id_00 2000-01-01   0.497650\n",
       "1         id_00 2000-01-02   1.554489\n",
       "2         id_00 2000-01-03   2.734311\n",
       "3         id_00 2000-01-04   4.028039\n",
       "4         id_00 2000-01-05   5.366009\n",
       "...         ...        ...        ...\n",
       "26998     id_99 2000-06-25  34.165302\n",
       "26999     id_99 2000-06-26  28.277320\n",
       "27000     id_99 2000-06-27  29.450129\n",
       "27001     id_99 2000-06-28  30.241885\n",
       "27002     id_99 2000-06-29  31.576907\n",
       "\n",
       "[27003 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, with_trend=True)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905be3b-30e7-459e-94ed-aa6008201ccc",
   "metadata": {},
   "source": [
    "Here we can see that the index goes from `id_00` to `id_99`, which means we have 100 different series stacked together.\n",
    "\n",
    "We also have the `ds` column that contains the timestamps, in this case with a daily frequency, and the `y` column that contains the series values in each timestamp.\n",
    "\n",
    "In order to perform distributed processing and training we need to have these in a dask dataframe, this is typically done loading them directly in a distributed way, for example with `dd.read_parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ac871-05a8-48c7-b38d-b56174a9ed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_49</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 5 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              unique_id              ds        y\n",
       "npartitions=2                                   \n",
       "id_00            object  datetime64[ns]  float64\n",
       "id_49               ...             ...      ...\n",
       "id_99               ...             ...      ...\n",
       "Dask Name: assign, 5 graph layers"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_ddf = dd.from_pandas(series.set_index('unique_id'), npartitions=2)  # make sure we split by id\n",
    "series_ddf = series_ddf.map_partitions(lambda part: part.reset_index())  # we can't have an index\n",
    "series_ddf['unique_id'] = series_ddf['unique_id'].astype('str') # categoricals aren't supported at the moment\n",
    "series_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52c394-8b5c-46b6-8963-b60ebf3736f9",
   "metadata": {},
   "source": [
    "We now have a dask dataframe with two partitions which will be processed independently in each machine and their outputs will be combined to perform distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b5f8b-fa7c-4e4f-8fc3-799fc6a0d160",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f984a5-eae5-4cc8-8636-ad56834c7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(df, ax):\n",
    "    idxs = df['unique_id'].unique()\n",
    "    random.seed(0)\n",
    "    sample_idxs = random.choices(idxs, k=4)\n",
    "    for uid, axi in zip(sample_idxs, ax.flat):\n",
    "        df[df['unique_id'].eq(uid)].set_index('ds').plot(ax=axi, title=uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdb56e-595c-4099-b703-9f9baec846d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 6), gridspec_kw=dict(hspace=0.5))\n",
    "plot_sample(series, ax)\n",
    "fig.savefig('../figs/quick_start_distributed__sample.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422d6e2-12d5-431d-bd5a-0973d2f49fd0",
   "metadata": {},
   "source": [
    "![](../figs/quick_start_distributed__sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efdf73-8533-4315-a0f4-404cca531a94",
   "metadata": {},
   "source": [
    "We can see that the series have a clear trend, so we can take the first difference, i.e. take each value and subtract the value at the previous month. This can be achieved by passing an `mlforecast.target_transforms.Differences([1])` instance to `target_transforms`.\n",
    "\n",
    "We can then train a LightGBM model using the value from the same day of the week at the previous week (lag 7) as a feature, this is done by passing `lags=[7]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03d9d2-8cd6-4c14-aa1c-e092781a083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed import DistributedMLForecast\n",
    "from mlforecast.distributed.models.dask.lgb import DaskLGBMForecast\n",
    "from mlforecast.target_transforms import Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdec3a1-f615-4681-a8ee-87cc6e34e22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/mambaforge/envs/mlforecast/lib/python3.10/site-packages/lightgbm/dask.py:525: UserWarning: Parameter n_jobs will be ignored.\n",
      "  _log_warning(f\"Parameter {param_alias} will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Info] Trying to bind port 52367...\n",
      "[LightGBM] [Info] Binding port 52367 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Trying to bind port 48789...\n",
      "[LightGBM] [Info] Binding port 48789 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Local rank: 0, total number of machines: 2\n",
      "[LightGBM] [Info] Local rank: 1, total number of machines: 2\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistributedMLForecast(models=[DaskLGBMForecast], freq=<Day>, lag_features=['lag7'], date_features=[], num_threads=1, engine=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models=DaskLGBMForecast(verbosity=-1),\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    target_transforms=[Differences([1])],\n",
    ")\n",
    "fcst.fit(series_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61860c-8e00-416a-8cc5-ee6b54f8578a",
   "metadata": {},
   "source": [
    "The previous line computed the features and trained the model, so now we're ready to compute our forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ba3510-84fc-4b09-8f0b-e4abe2b1b9e6",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67c696-c3d1-4270-9b17-9644eca5e32e",
   "metadata": {},
   "source": [
    "Compute the forecast for the next 14 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63c1a6-a709-4fed-a6d2-35d5648b79e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_49</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: map, 17 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              unique_id              ds DaskLGBMForecast\n",
       "npartitions=2                                           \n",
       "id_00            object  datetime64[ns]          float64\n",
       "id_49               ...             ...              ...\n",
       "id_99               ...             ...              ...\n",
       "Dask Name: map, 17 graph layers"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(14)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3b53b-e6ed-4939-9e76-f43051203718",
   "metadata": {},
   "source": [
    "These are returned as a dask dataframe as well. If it's safe (memory-wise) we can bring them to the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45104e-11d2-4a5f-85fa-c2573f545f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_preds = preds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783cf79-5d52-43e3-9e3c-290530504d4e",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0ea21-b713-4c46-bd43-e162b21dbfb8",
   "metadata": {},
   "source": [
    "We can visualize what our prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e208d-6eb8-4e41-8dfb-0095c3e70f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b060f4e-e037-428b-b38c-195981be66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 6), gridspec_kw=dict(hspace=0.5))\n",
    "plot_sample(pd.concat([series, local_preds.set_index('unique_id')]), ax)\n",
    "fig.savefig('../figs/quick_start_distributed__sample_prediction.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65a60b-246b-42ee-a888-b082822c568e",
   "metadata": {},
   "source": [
    "![](../figs/quick_start_distributed__sample_prediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7076e1-0388-4fbf-a27c-bc99ed291259",
   "metadata": {},
   "source": [
    "And that's it! You've trained a distributed LightGBM model and computed predictions for the next 14 days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
