{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Demand Peaks\n",
    "\n",
    "> In this example we will show how to perform electricity load forecasting on the ERCOT (Texas) market for detecting daily peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting peaks in different markets is useful. In the electricity market, consuming electricity at peak demand is penalized with higher tarifs. When an individual or company consumes electricity when its most demanded, regulators calls that a coincident peak (CP).\n",
    "\n",
    "In the Texas electricity market (ERCOT), the peak is the monthly 15-minute interval when the ERCOT Grid is at a point of highest capacity. The peak is caused by all consumersâ€™ combined demand on the electrical grid. The coincident peak demand is an important factor used by ERCOT to determine final electricity consumption bills. ERCOT registers the CP demand of each client for 4 months, between June and September, and uses this to adjust electricity prices. Clients can therefore save on electricity bills by reducing the coincident peak demand.\n",
    "\n",
    "In this example we will train a `LightGBM` model on historic load data to forecast day-ahead peaks on September 2022. Multiple seasonality is traditionally present in low sampled electricity data. Demand exhibits daily and weekly seasonality, with clear patterns for specific hours of the day such as 6:00pm vs 3:00am or for specific days such as Sunday vs Friday.\n",
    "\n",
    "First, we will load ERCOT historic demand, then we will use the `MLForecast.cross_validation` method to fit the `LightGBM` model and forecast daily load during September. Finally, we show how to use the forecasts to detect the coincident peak. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "1. Install libraries\n",
    "1. Load and explore the data\n",
    "1. Fit LightGBM model and forecast\n",
    "1. Peak detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "You can use Colab to run this Notebook interactively <a href=\"https://colab.research.google.com/github/Nixtla/mlforecast/blob/main/nbs/examples/electricity_peak_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume you have MLForecast already installed. Check this guide for instructions on [how to install MLForecast](../getting-started/install.html).\n",
    "\n",
    "Install the necessary packages using `pip install mlforecast`.\n",
    "\n",
    "Also we have to install `LightGBM` using `pip install lightgbm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to MLForecast is always a data frame in [long format](https://www.theanalysisfactor.com/wide-and-long-data/) with three columns: `unique_id`, `ds` and `y`:\n",
    "\n",
    "* The `unique_id` (string, int or category) represents an identifier for the series. \n",
    "\n",
    "* The `ds` (datestamp or int) column should be either an integer indexing time or a datestamp ideally like YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\n",
    "\n",
    "* The `y` (numeric) represents the measurement we wish to forecast. \n",
    "We will rename the \n",
    "\n",
    "First, read the 2022 historic total demand of the ERCOT market. We processed the original data (available [here](https://www.ercot.com/gridinfo/load/load_hist)), by adding the missing hour due to daylight saving time, parsing the date to datetime format, and filtering columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utilsforecast.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Y_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/ERCOT-clean.csv', parse_dates=['ds'])\n",
    "Y_df = Y_df.query(\"ds >= '2022-01-01' & ds <= '2022-10-01'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_series(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "fig.savefig('../../figs/electricity_peak_forecasting__eda.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../figs/electricity_peak_forecasting__eda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the time series exhibits seasonal patterns. Moreover, the time series contains `6,552` observations, so it is necessary to use computationally efficient methods to deploy them in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Forecast LightGBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `MLForecast` class and the models you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, instantiate the model and define the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "In this example we are using the default parameters of the `lgb.LGBMRegressor` model, but you can change them to improve the forecasting performance.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    lgb.LGBMRegressor(verbosity=-1) # you can include more models here\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model by instantiating a `MLForecast` object with the following required parameters:\n",
    "\n",
    "* `models`: a list of sklearn-like (fit and predict) models.\n",
    "\n",
    "* `freq`: a string indicating the frequency of the data. (See [panda's available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).)\n",
    "\n",
    "- `target_transforms`: Transformations to apply to the target before computing the features. These are restored at the forecasting step.\n",
    "\n",
    "* `lags`: Lags of the target to use as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MLForecast class as mlf\n",
    "mlf = MLForecast(\n",
    "    models=models,\n",
    "    freq='H', \n",
    "    target_transforms=[Differences([24])],\n",
    "    lags=range(1, 25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "In this example, we are only using differences and lags to produce features. See the [full documentation](https://nixtla.github.io/mlforecast/forecast.html#mlforecast) to see all available features. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cross_validation` method allows the user to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with `fit` and `predict` methods. This method re-trains the model and forecast each window. See [this tutorial](https://nixtla.github.io/statsforecast/examples/getting_started_complete.html) for an animation of how the windows are defined. \n",
    "\n",
    "Use the `cross_validation` method to produce all the daily forecasts for September. To produce daily forecasts set the forecasting horizon `window_size` as 24. In this example we are simulating deploying the pipeline during September, so set the number of windows as 30 (one for each day). Finally, the step size between windows is 24 (equal to the `window_size`). This ensure to only produce one forecast per day.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "* `id_col`: identifies each time series.\n",
    "* `time_col`: indetifies the temporal column of the time series.\n",
    "* `target_col`: identifies the column to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df = mlf.cross_validation(\n",
    "    df=Y_df,\n",
    "    h=24,\n",
    "    n_windows=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERCOT</td>\n",
       "      <td>2022-09-01 00:00:00</td>\n",
       "      <td>2022-08-31 23:00:00</td>\n",
       "      <td>45482.471757</td>\n",
       "      <td>45685.265537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERCOT</td>\n",
       "      <td>2022-09-01 01:00:00</td>\n",
       "      <td>2022-08-31 23:00:00</td>\n",
       "      <td>43602.658043</td>\n",
       "      <td>43779.819515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERCOT</td>\n",
       "      <td>2022-09-01 02:00:00</td>\n",
       "      <td>2022-08-31 23:00:00</td>\n",
       "      <td>42284.817342</td>\n",
       "      <td>42672.470923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERCOT</td>\n",
       "      <td>2022-09-01 03:00:00</td>\n",
       "      <td>2022-08-31 23:00:00</td>\n",
       "      <td>41663.156771</td>\n",
       "      <td>42091.768192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERCOT</td>\n",
       "      <td>2022-09-01 04:00:00</td>\n",
       "      <td>2022-08-31 23:00:00</td>\n",
       "      <td>41710.621904</td>\n",
       "      <td>42481.403168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id                  ds              cutoff             y  \\\n",
       "0     ERCOT 2022-09-01 00:00:00 2022-08-31 23:00:00  45482.471757   \n",
       "1     ERCOT 2022-09-01 01:00:00 2022-08-31 23:00:00  43602.658043   \n",
       "2     ERCOT 2022-09-01 02:00:00 2022-08-31 23:00:00  42284.817342   \n",
       "3     ERCOT 2022-09-01 03:00:00 2022-08-31 23:00:00  41663.156771   \n",
       "4     ERCOT 2022-09-01 04:00:00 2022-08-31 23:00:00  41710.621904   \n",
       "\n",
       "   LGBMRegressor  \n",
       "0   45685.265537  \n",
       "1   43779.819515  \n",
       "2   42672.470923  \n",
       "3   42091.768192  \n",
       "4   42481.403168  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "When using `cross_validation` make sure the forecasts are produced at the desired timestamps. Check the `cutoff` column which specifices the last timestamp before the forecasting window.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the forecasts in `crossvaldation_df` to detect the daily hourly demand peaks. For each day, we set the detected peaks as the highest forecasts. In this case, we want to predict one peak (`npeaks`); depending on your setting and goals, this parameter might change. For example, the number of peaks can correspond to how many hours a battery can be discharged to reduce demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npeaks = 1 # Number of peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ERCOT 4CP detection task we are interested in correctly predicting the highest monthly load. Next, we filter the day in September with the highest hourly demand and predict the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df = crossvalidation_df.reset_index()[['ds','y','LGBMRegressor']]\n",
    "max_day = crossvalidation_df.iloc[crossvalidation_df['y'].argmax()].ds.day # Day with maximum load\n",
    "cv_df_day = crossvalidation_df.query('ds.dt.day == @max_day')\n",
    "max_hour = cv_df_day['y'].argmax()\n",
    "peaks = cv_df_day['LGBMRegressor'].argsort().iloc[-npeaks:].values # Predicted peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot we see how the LightGBM model is able to correctly detect the coincident peak for September 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axvline(cv_df_day.iloc[max_hour]['ds'], color='black', label='True Peak')\n",
    "ax.scatter(cv_df_day.iloc[peaks]['ds'], cv_df_day.iloc[peaks]['LGBMRegressor'], color='green', label=f'Predicted Top-{npeaks}')\n",
    "ax.plot(cv_df_day['ds'], cv_df_day['y'], label='y', color='blue')\n",
    "ax.plot(cv_df_day['ds'], cv_df_day['LGBMRegressor'], label='Forecast', color='red')\n",
    "ax.set(xlabel='Time', ylabel='Load (MW)')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.savefig('../../figs/electricity_peak_forecasting__predicted_peak.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../figs/electricity_peak_forecasting__predicted_peak.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "In this example we only include September. However, MLForecast and LightGBM can correctly predict the peaks for the 4 months of 2022. You can try this by increasing the `n_windows` parameter of `cross_validation` or filtering the `Y_df` dataset. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLForecast and LightGBM in particular are good benchmarking models for peak detection. However, it might be useful to explore further and newer forecasting algorithms or perform hyperparameter optimization. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
