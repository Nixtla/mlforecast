{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f8d66-0dd7-4112-9467-f82d924aedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2665d-82ae-4280-a5e2-91d52fd344db",
   "metadata": {},
   "source": [
    "# Target transformations\n",
    "> Seamlessly transform target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74e4d3-5b9e-4c76-8778-ce8fe95cfe43",
   "metadata": {},
   "source": [
    "Since mlforecast uses a single global model it can be helpful to apply some transformations to the target to ensure that all series have similar distributions. They can also help remove trend for models that can't deal with it out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2d107-a0f0-4a41-9f7f-e764a4a80c8e",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26831f7d-8889-41f1-87b6-cb9f1fe4e47a",
   "metadata": {},
   "source": [
    "For this example we'll use a single serie from the M4 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5f7c0-e127-4c9a-a239-d0ae11f4fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasetsforecast.m4 import M4\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences, LocalStandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb76ed-0991-4113-bb76-fbf0ec1c865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "await M4.async_download(data_path, group='Hourly')\n",
    "df, *_ = M4.load(data_path, 'Hourly')\n",
    "df['ds'] = df['ds'].astype('int32')\n",
    "serie = df[df['unique_id'].eq('H196')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e95bbb-f441-4019-916b-3272044cc96a",
   "metadata": {},
   "source": [
    "## Local transformations\n",
    "> Transformations applied per serie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26129d96-35e7-4d19-8076-ca90cc36134f",
   "metadata": {},
   "source": [
    "### Differences\n",
    "We'll take a look at our serie to see possible differences that would help our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c549f-381e-4bd0-becb-1d672546dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(series, fname):\n",
    "    n_series = len(series)\n",
    "    fig, ax = plt.subplots(ncols=n_series, figsize=(7 * n_series, 6), squeeze=False)\n",
    "    for (title, serie), axi in zip(series.items(), ax.flat):\n",
    "        serie.set_index('ds')['y'].plot(title=title, ax=axi)\n",
    "    fig.savefig(f'../../figs/{fname}', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111da55-85a7-4f26-b537-485304f9c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot({'original': serie}, 'target_transforms__eda.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756737f-3e0f-49b8-89fb-c4eeedc96720",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__eda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc61824-3baf-4493-a584-4cb4795ad8e5",
   "metadata": {},
   "source": [
    "We can see that our data has a trend as well as a clear seasonality. We can try removing the trend first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277020a9-965c-420b-b5b0-ed1bb9c0873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([1])],\n",
    ")\n",
    "without_trend = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'without trend': without_trend}, 'target_transforms__diff1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3d460-5044-4faa-ac80-2985ab8865d9",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__diff1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd347a12-ee49-410b-a781-b727802cef51",
   "metadata": {},
   "source": [
    "The trend is gone, we can now try taking the 24 difference (subtract the value at the same hour in the previous day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78b22e-845d-4e3e-8b6a-e26a72ee4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([1, 24])],\n",
    ")\n",
    "without_trend_and_seasonality = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'without trend and seasonality': without_trend_and_seasonality}, 'target_transforms__diff2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fce7a3-a6da-41ae-ac6d-c2fcb199cb52",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__diff2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86989bf-15c4-4e47-b302-9870ae668bea",
   "metadata": {},
   "source": [
    "### LocalStandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee30bb5-e5e1-4cf0-8540-9435d773968e",
   "metadata": {},
   "source": [
    "We see that our serie is random noise now. Suppose we also want to standardize it, i.e. make it have a mean of 0 and variance of 1. We can add the LocalStandardScaler transformation after these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73253f3-44f7-4e94-82a9-5f91fc0debf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean   -0.0\n",
       "var     1.0\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([1, 24]), LocalStandardScaler()],\n",
    ")\n",
    "standardized = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'standardized': standardized}, 'target_transforms__standardized.png')\n",
    "standardized['y'].agg(['mean', 'var']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e8236-2f51-4787-9af0-40c298f92a09",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__standardized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbf14e-8037-44e8-8ff2-95a5a39bec6d",
   "metadata": {},
   "source": [
    "Now that we've captured the components of the serie (trend + seasonality), we could try forecasting it with a model that always predicts 0, which will basically project the trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55cab0-7c7a-4fd8-9557-968d5ad161f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zeros(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return np.zeros(X.shape[0])\n",
    "\n",
    "fcst = MLForecast(\n",
    "    models={'zeros_model': Zeros()},\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([1, 24]), LocalStandardScaler()],\n",
    ")\n",
    "preds = fcst.fit(serie).predict(48)\n",
    "fig, ax = plt.subplots()\n",
    "pd.concat([serie.tail(24 * 10), preds]).set_index('ds').plot(ax=ax)\n",
    "plt.close()\n",
    "fig.savefig('../../target_transforms__zeros.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01fc3d-5884-46d9-95aa-b40cd010f493",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__zeros.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7c5c2-a01e-4d33-9762-eb429f49f3c1",
   "metadata": {},
   "source": [
    "## Global transformations\n",
    "> Transformations applied to all series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb4a28-3d9b-4f67-9f7e-807fbbda9ec8",
   "metadata": {},
   "source": [
    "### GlobalSklearnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5acae-2625-4754-9933-cfb4bfc5e96e",
   "metadata": {},
   "source": [
    "There are some transformations that don't require to learn any parameters, such as applying logarithm for example. These can be easily defined using the `GlobalSklearnTransformer`, which takes a scikit-learn compatible transformer and applies it to all series. Here's an example on how to define a transformation that applies logarithm to each value of the series + 1, which can help avoid computing the log of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bd6e8-b64b-4c50-ba66-00129db958bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from mlforecast.target_transforms import GlobalSklearnTransformer\n",
    "\n",
    "sk_log1p = FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\n",
    "fcst = MLForecast(\n",
    "    models={'zeros_model': Zeros()},\n",
    "    freq=1,\n",
    "    target_transforms=[GlobalSklearnTransformer(sk_log1p)],\n",
    ")\n",
    "log1p_transformed = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'Log transformed': log1p_transformed}, 'target_transforms__log.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d9a50-0c34-4ee2-972b-52c35d010678",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__log.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88ff48-fd68-4c7f-bd09-cf8a1f9ebebe",
   "metadata": {},
   "source": [
    "We can also combine this with local transformations. For example we can apply log first and then differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4121fa3-9438-47df-b86a-747b4d7375cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[GlobalSklearnTransformer(sk_log1p), Differences([1, 24])],\n",
    ")\n",
    "log_diffs = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'Log + Differences': log_diffs}, 'target_transforms__log_diffs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f26993-e65c-4bee-b5cb-15eb8dcdcff0",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__log_diffs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759e1a6-d99e-4a8b-9d2c-71607edd7e66",
   "metadata": {},
   "source": [
    "## Custom transformations\n",
    "> Implementing your own target transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6fb6cb-a69d-477d-978f-f8deda8f4e3c",
   "metadata": {},
   "source": [
    "In order to implement your own target transformation you have to define a class that inherits from `mlforecast.target_transforms.BaseTargetTransform` (this takes care of setting the column names as the `id_col`, `time_col` and `target_col` attributes) and implement the `fit_transform` and `inverse_transform` methods. Here's an example on how to define a min-max scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894b1b2-d1dd-444c-b7e4-09887a59d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.target_transforms import BaseTargetTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bef992-d813-4373-a906-9ee5a18246ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMinMaxScaler(BaseTargetTransform):\n",
    "    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        self.stats_ = df.groupby(self.id_col)[self.target_col].agg(['min', 'max'])\n",
    "        df = df.merge(self.stats_, on=self.id_col)\n",
    "        df[self.target_col] = (df[self.target_col] - df['min']) / (df['max'] - df['min'])\n",
    "        df = df.drop(columns=['min', 'max'])\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.merge(self.stats_, on=self.id_col)\n",
    "        for col in df.columns.drop([self.id_col, self.time_col, 'min', 'max']):\n",
    "            df[col] = df[col] * (df['max'] - df['min']) + df['min']\n",
    "        df = df.drop(columns=['min', 'max'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ed7a5-0dcb-4f45-aba9-dcedba23a3d7",
   "metadata": {},
   "source": [
    "And now you can pass an instance of this class to the `target_transforms` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac3014-16e8-4b7a-8db6-49ab1f99c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[LocalMinMaxScaler()],\n",
    ")\n",
    "minmax_scaled = fcst.preprocess(serie)\n",
    "plot({'original': serie, 'min-max scaled': minmax_scaled}, 'target_transforms__minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca024e8f-14fa-4c67-a422-d14b3c9604c8",
   "metadata": {},
   "source": [
    "![](../../figs/target_transforms__minmax.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
