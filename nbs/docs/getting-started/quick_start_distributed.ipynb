{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9693434b-0290-4ffd-88f9-a4267c11b548",
   "metadata": {},
   "source": [
    "# Quick start (distributed)\n",
    "\n",
    "> Minimal example of distributed training with MLForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e9e05-e8b2-433e-9ff2-16e652cf6acb",
   "metadata": {},
   "source": [
    "The `DistributedMLForecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way.\n",
    "\n",
    "The different things that you need to use `DistributedMLForecast` (as opposed to `MLForecast`) are:\n",
    "\n",
    "1. You need to set up a cluster. We currently support dask, ray and spark.\n",
    "2. Your data needs to be a distributed collection (dask, ray or spark dataframe).\n",
    "3. You need to use a model that implements distributed training in your framework of choice, e.g. SynapseML for LightGBM in spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7853f-df6e-4bf2-b2d9-cb3b4c6a0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.distributed import DistributedMLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast.utils import backtest_splits, generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f930a27-b15f-438a-aab2-ccafc77e09f4",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af70aed-bfb9-4c36-a4c4-cf546f8655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe3454-b2e1-40d0-a623-6ae1fe486536",
   "metadata": {},
   "source": [
    "### Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9868f8-38a5-4a9f-829c-47a10a522fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd61b21-9a22-42dc-ba19-d6de68dc8eba",
   "metadata": {},
   "source": [
    "Here we define a client that connects to a `dask.distributed.LocalCluster`, however it could be any other kind of cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b968e6d-cbc8-499b-8a41-ef12fe4fdd69",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "\n",
    "For dask, the data must be a `dask.dataframe.DataFrame`. You need to make sure that each time serie is only in one partition and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, except that it's a `dask.dataframe.DataFrame` instead of a `pandas.Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acdff6-49c0-4f28-8a2c-1a75e2c1c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_10</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_89</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 5 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               unique_id              ds        y static_0 static_1\n",
       "npartitions=10                                                     \n",
       "id_00             object  datetime64[ns]  float64    int64    int64\n",
       "id_10                ...             ...      ...      ...      ...\n",
       "...                  ...             ...      ...      ...      ...\n",
       "id_89                ...             ...      ...      ...      ...\n",
       "id_99                ...             ...      ...      ...      ...\n",
       "Dask Name: assign, 5 graph layers"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "npartitions = 10\n",
    "partitioned_series = dd.from_pandas(series.set_index('unique_id'), npartitions=npartitions)  # make sure we split by the id_col\n",
    "partitioned_series = partitioned_series.map_partitions(lambda df: df.reset_index())\n",
    "partitioned_series['unique_id'] = partitioned_series['unique_id'].astype(str)  # can't handle categoricals atm\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa4f88-1a4d-4175-a33c-80d34f61f8cc",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `dask`. The current implementations are in `DaskLGBMForecast` and `DaskXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997af98-7a6e-468a-8f22-d7271b85ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.dask.lgb import DaskLGBMForecast\n",
    "from mlforecast.distributed.models.dask.xgb import DaskXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e482699-e3c3-4fef-b081-112c23bff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DaskXGBForecast(random_state=0), DaskLGBMForecast(random_state=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab284f5f-e6d7-4d73-b0b6-efdf0aea581a",
   "metadata": {},
   "source": [
    "### Training\n",
    "Once we have our models we instantiate a `DistributedMLForecast` object defining our features. We can then call `fit` on this object passing our dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5821d-6c04-4fd6-b5d6-9bbfefe9d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    ")\n",
    "fcst.fit(partitioned_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49e861-74ab-42b0-a220-a823e5c7070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import fugue.api as fa\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241e4da-fc38-4744-bb88-e72c77e63ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# function to test the partition_results data\n",
    "# has the right size\n",
    "def test_partition_results_size(fcst_object, expected_n_partitions):\n",
    "    test_eq(\n",
    "        fa.get_num_partitions(fcst_object.partition_results),\n",
    "        expected_n_partitions,\n",
    "    )\n",
    "    test_eq(\n",
    "        fa.count(fcst_object.partition_results),\n",
    "        expected_n_partitions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4219d-4c48-43a1-87c4-58dfb520022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8531-014f-4d0e-a33e-fe8504d164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "num_partitions_test = 4\n",
    "test_dd = dd.from_pandas(series, npartitions=num_partitions_test) # In this case we dont have to specify the column\n",
    "test_dd['unique_id'] = test_dd['unique_id'].astype(str)\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    "    num_partitions=num_partitions_test\n",
    ")\n",
    "fcst_np.fit(test_dd)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2d411-66f8-425a-bcfe-8c5cc28ca324",
   "metadata": {},
   "source": [
    "Once we have our fitted models we can compute the predictions for the next 7 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21511e5a-750b-4a27-8f68-e9ceff5c7536",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58769a05-3961-49c9-9b50-e1b0713d8c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>421.880432</td>\n",
       "      <td>421.607612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>503.725891</td>\n",
       "      <td>501.287188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>21.745794</td>\n",
       "      <td>20.218114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>103.609970</td>\n",
       "      <td>103.614699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>184.415192</td>\n",
       "      <td>184.327408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast\n",
       "0     id_00 2001-05-15       421.880432        421.607612\n",
       "1     id_00 2001-05-16       503.725891        501.287188\n",
       "2     id_00 2001-05-17        21.745794         20.218114\n",
       "3     id_00 2001-05-18       103.609970        103.614699\n",
       "4     id_00 2001-05-19       184.415192        184.327408"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7)\n",
    "preds.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6f1f2-d22b-48d7-a5e5-77d400cd4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "preds = preds.compute()\n",
    "preds2 = fcst.predict(7).compute()\n",
    "preds3 = fcst.predict(7, new_df=partitioned_series).compute()\n",
    "pd.testing.assert_frame_equal(preds, preds2)\n",
    "pd.testing.assert_frame_equal(preds, preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29841c02-b0bc-44cc-a8f3-da31b442584b",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296af9be-4149-4b47-9386-fc92bff65d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=2,\n",
    "    h=14,\n",
    ")\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bc2ce-27e9-4245-b98f-9e88b2a7829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>416.596832</td>\n",
       "      <td>414.746359</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>404.993322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-18</td>\n",
       "      <td>501.541565</td>\n",
       "      <td>495.292467</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>508.883226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-19</td>\n",
       "      <td>22.663921</td>\n",
       "      <td>20.404674</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>1.218119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-20</td>\n",
       "      <td>100.937668</td>\n",
       "      <td>100.720564</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>109.879770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>184.458405</td>\n",
       "      <td>188.645839</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>163.703847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast     cutoff  \\\n",
       "0     id_00 2001-04-17       416.596832        414.746359 2001-04-16   \n",
       "1     id_00 2001-04-18       501.541565        495.292467 2001-04-16   \n",
       "2     id_00 2001-04-19        22.663921         20.404674 2001-04-16   \n",
       "3     id_00 2001-04-20       100.937668        100.720564 2001-04-16   \n",
       "4     id_00 2001-04-21       184.458405        188.645839 2001-04-16   \n",
       "\n",
       "            y  \n",
       "0  404.993322  \n",
       "1  508.883226  \n",
       "2    1.218119  \n",
       "3  109.879770  \n",
       "4  163.703847  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d27b0-ba00-4141-a50c-ab39385e8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mlforecast.distributed.forecast import WindowInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457500-a299-4eb7-b13f-78412f4d302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# input_size\n",
    "input_size = 100\n",
    "reduced_train = fcst._preprocess(\n",
    "    partitioned_series,\n",
    "    id_col='unique_id',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    dropna=False,\n",
    "    window_info=WindowInfo(\n",
    "        n_windows=1,\n",
    "        window_size=10,\n",
    "        step_size=None,\n",
    "        i_window=0,\n",
    "        input_size=input_size,\n",
    "    ),\n",
    ")\n",
    "assert reduced_train.groupby('unique_id').size().compute().max() == input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cdca0-6368-42d9-bc57-2390e6430b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "cv_res_no_refit = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=2,\n",
    "    h=14,\n",
    "    refit=False\n",
    ")\n",
    "cv_results_df = cv_res.compute()\n",
    "cv_results_no_refit_df = cv_res_no_refit.compute()\n",
    "# test we recover the same \"metadata\"\n",
    "models = ['DaskXGBForecast', 'DaskLGBMForecast']\n",
    "test_eq(\n",
    "    cv_results_no_refit_df.drop(columns=models),\n",
    "    cv_results_df.drop(columns=models)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34651ae-5be4-4e86-b44f-fbd15c4d72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "non_std_series = partitioned_series.copy()\n",
    "non_std_series['ds'] = non_std_series.map_partitions(lambda part: part.groupby('unique_id').cumcount())\n",
    "non_std_series = non_std_series.rename(columns={'ds': 'time', 'y': 'value', 'unique_id': 'some_id'})\n",
    "flow_params = dict(\n",
    "    models=[DaskXGBForecast(random_state=0)],\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst = DistributedMLForecast(freq='D', **flow_params)\n",
    "fcst.fit(partitioned_series)\n",
    "preds = fcst.predict(7).compute()\n",
    "fcst2 = DistributedMLForecast(**flow_params)\n",
    "fcst2.preprocess(non_std_series, id_col='some_id', time_col='time', target_col='value')\n",
    "fcst2.models_ = fcst.models_  # distributed training can end up with different fits\n",
    "non_std_preds = fcst2.predict(7).compute()\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds.drop(columns='ds'),\n",
    "    non_std_preds.drop(columns='time').rename(columns={'some_id': 'unique_id'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9b3ae-3859-4989-aa56-85390f63cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df016-bc2a-47c1-afeb-4394ca7695cb",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfae838-6305-4a48-8a82-2f3c3eb653f5",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97595792-8173-4d0e-ac56-174c3d698d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119c014-b51b-4ba0-ab28-585665c03ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.2\")\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0371e5b-5700-4466-86e3-07e35499200b",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For spark, the data must be a `pyspark DataFrame`. You need to make sure that each time serie is only in one partition (which you can do using `repartitionByRange`, for example) and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc337af2-0952-4f7c-98ad-baa87bb16d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPartitions = 4\n",
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "spark_series = spark.createDataFrame(series).repartitionByRange(numPartitions, 'unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959aec60-ed2e-4538-8d6c-09b0a66bc35d",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `spark`. The current implementations are in `SparkLGBMForecast` and `SparkXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609dee3-f959-4c28-b913-0871f94e2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.spark.lgb import SparkLGBMForecast\n",
    "\n",
    "models = [SparkLGBMForecast()]\n",
    "try:\n",
    "    from xgboost.spark import SparkXGBRegressor\n",
    "    from mlforecast.distributed.models.spark.xgb import SparkXGBForecast\n",
    "    models.append(SparkXGBForecast())\n",
    "except ModuleNotFoundError:  # py < 38\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690336b5-ad1a-4ff2-a42b-fd2bf15870fe",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a458c1-855d-4955-b77b-5dbdb5ecacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    ")\n",
    "fcst.fit(\n",
    "    spark_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33443e25-3a35-4abc-85f1-2aa774d64689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7ebdd-6d6a-4e0d-babf-d7fe11cd09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "test_spark_df = spark.createDataFrame(series)\n",
    "num_partitions_test = 10\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    num_partitions=num_partitions_test,\n",
    ")\n",
    "fcst_np.fit(test_spark_df)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1b654-5641-4b4d-b503-6606f94396cd",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d2230-60f5-47f1-820b-af2ca7311b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6bbd2-9806-4b12-91a2-1b5571ae1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/miniforge3/envs/mlforecast/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>421.606537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>505.575836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>15.462178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>102.123245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>182.308197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast\n",
       "0     id_00 2001-05-15         422.139843        421.606537\n",
       "1     id_00 2001-05-16         497.180212        505.575836\n",
       "2     id_00 2001-05-17          13.062478         15.462178\n",
       "3     id_00 2001-05-18         100.601041        102.123245\n",
       "4     id_00 2001-05-19         180.707848        182.308197"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad24338-2634-4b27-8f73-dc162338dd38",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb396b93-b160-4325-9d5c-bf391ef87db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    spark_series,\n",
    "    n_windows=2,\n",
    "    h=14,\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c735385-7104-4ced-a253-d4a16b8bbb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_21</td>\n",
       "      <td>2001-04-28</td>\n",
       "      <td>92.870945</td>\n",
       "      <td>58.219631</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>58.044008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_04</td>\n",
       "      <td>2001-04-23</td>\n",
       "      <td>114.502043</td>\n",
       "      <td>117.134018</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>118.452839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_18</td>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>82.597659</td>\n",
       "      <td>86.992348</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>80.416969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_20</td>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>230.254435</td>\n",
       "      <td>237.235214</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>230.352460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_23</td>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>426.386288</td>\n",
       "      <td>419.380524</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>432.918548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast     cutoff  \\\n",
       "0     id_21 2001-04-28          92.870945         58.219631 2001-04-16   \n",
       "1     id_04 2001-04-23         114.502043        117.134018 2001-04-16   \n",
       "2     id_18 2001-04-17          82.597659         86.992348 2001-04-16   \n",
       "3     id_20 2001-04-21         230.254435        237.235214 2001-04-16   \n",
       "4     id_23 2001-04-17         426.386288        419.380524 2001-04-16   \n",
       "\n",
       "            y  \n",
       "0   58.044008  \n",
       "1  118.452839  \n",
       "2   80.416969  \n",
       "3  230.352460  \n",
       "4  432.918548  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2f8e2-f8d8-4efb-8114-47eaf8703170",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218f6f9-22d5-4ec1-9f04-3b6b6368ea69",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e192699-ecda-4eb2-8274-fc1246e4d6e8",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d064e-1025-4407-b701-ccad70aa90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.cluster_utils import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753bdd4-73e0-4f96-84f8-1f148d879dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_cluster = Cluster(\n",
    "    initialize_head=True,\n",
    "    head_node_args={\"num_cpus\": 2}\n",
    ")\n",
    "ray.init(address=ray_cluster.address, ignore_reinit_error=True)\n",
    "# add mock node to simulate a cluster\n",
    "mock_node = ray_cluster.add_node(num_cpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b81d4-598d-4eec-820e-72a81177cedb",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For ray, the data must be a `ray DataFrame`. It is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f033849-67d3-469c-9608-d589153890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "# we need noncategory unique_id\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "ray_series = ray.data.from_pandas(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2726794-b6cd-462a-98b4-e8ec4c84ea75",
   "metadata": {},
   "source": [
    "### Models\n",
    "The ray integration allows to include `lightgbm` (`RayLGBMRegressor`), and `xgboost` (`RayXGBRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c023f51-1d0c-4596-a8d7-6f167c4ad257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.ray.lgb import RayLGBMForecast\n",
    "from mlforecast.distributed.models.ray.xgb import RayXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2708a2b-a648-4ce1-8702-ca8a392c8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RayLGBMForecast(),\n",
    "    RayXGBForecast(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d90b92-36d4-4691-98c9-e9b1698d2bd4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0dab0-cd60-4519-a207-c087f193f30f",
   "metadata": {},
   "source": [
    "To control the number of partitions to use using Ray, we have to include `num_partitions` to `DistributedMLForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fd794-b380-40e2-821c-dacdc513bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355afcd8-44ba-44c6-a92d-0f45c6fc9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    num_partitions=num_partitions, # Use num_partitions to reduce overhead\n",
    ")\n",
    "fcst.fit(\n",
    "    ray_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9642b-17ca-4571-9f8a-f42c13a69987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8ad06-2f0c-4041-ac25-9aadac94c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "# In this case we test that the default behavior \n",
    "# for ray datasets works as expected\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst_np.fit(ray_series)\n",
    "# we dont use test_partition_results_size\n",
    "# since the number of objects is different \n",
    "# from the number of partitions\n",
    "test_eq(fa.count(fcst_np.partition_results), 100) # number of series\n",
    "preds_np = fcst_np.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4af13-c04c-4e9b-ab26-92f6d7b9745d",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e16b63-aeec-41d8-acff-ca982d3b952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ee74e-1346-4991-bcf2-5b2a887eb5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>419.180908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>502.074249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>16.981802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>102.311279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>181.406143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast\n",
       "0     id_00 2001-05-15       422.139843      419.180908\n",
       "1     id_00 2001-05-16       497.180212      502.074249\n",
       "2     id_00 2001-05-17        13.062478       16.981802\n",
       "3     id_00 2001-05-18       100.601041      102.311279\n",
       "4     id_00 2001-05-19       180.707848      181.406143"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb901de2-c98e-47fb-81e2-714010114a91",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0ec2a-cc6a-4195-a457-8f6243334d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    ray_series,\n",
    "    n_windows=2,\n",
    "    h=14,\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ecc467-80c7-4c0e-98d6-af77c9fc7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_10</td>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>29.912521</td>\n",
       "      <td>27.272474</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>34.156241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_10</td>\n",
       "      <td>2001-04-18</td>\n",
       "      <td>57.589800</td>\n",
       "      <td>50.432514</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>53.208507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_10</td>\n",
       "      <td>2001-04-19</td>\n",
       "      <td>76.750741</td>\n",
       "      <td>75.065681</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>71.920677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_10</td>\n",
       "      <td>2001-04-20</td>\n",
       "      <td>101.297954</td>\n",
       "      <td>98.846138</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>102.347087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_10</td>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>117.002167</td>\n",
       "      <td>120.924911</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>119.019914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast     cutoff           y\n",
       "0     id_10 2001-04-17        29.912521       27.272474 2001-04-16   34.156241\n",
       "1     id_10 2001-04-18        57.589800       50.432514 2001-04-16   53.208507\n",
       "2     id_10 2001-04-19        76.750741       75.065681 2001-04-16   71.920677\n",
       "3     id_10 2001-04-20       101.297954       98.846138 2001-04-16  102.347087\n",
       "4     id_10 2001-04-21       117.002167      120.924911 2001-04-16  119.019914"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba9328-7183-4744-9089-8ef02d3e9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
