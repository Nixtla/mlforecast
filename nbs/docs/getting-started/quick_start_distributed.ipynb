{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b44ee1-af97-490a-ad62-03b2f804e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693434b-0290-4ffd-88f9-a4267c11b548",
   "metadata": {},
   "source": [
    "# Quick start (distributed)\n",
    "\n",
    "> Minimal example of distributed training with MLForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e9e05-e8b2-433e-9ff2-16e652cf6acb",
   "metadata": {},
   "source": [
    "The `DistributedMLForecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way.\n",
    "\n",
    "The different things that you need to use `DistributedMLForecast` (as opposed to `MLForecast`) are:\n",
    "\n",
    "1. You need to set up a cluster. We currently support dask, ray and spark.\n",
    "2. Your data needs to be a distributed collection (dask, ray or spark dataframe).\n",
    "3. You need to use a model that implements distributed training in your framework of choice, e.g. SynapseML for LightGBM in spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7853f-df6e-4bf2-b2d9-cb3b4c6a0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.distributed import DistributedMLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f930a27-b15f-438a-aab2-ccafc77e09f4",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af70aed-bfb9-4c36-a4c4-cf546f8655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe3454-b2e1-40d0-a623-6ae1fe486536",
   "metadata": {},
   "source": [
    "### Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9868f8-38a5-4a9f-829c-47a10a522fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd61b21-9a22-42dc-ba19-d6de68dc8eba",
   "metadata": {},
   "source": [
    "Here we define a client that connects to a `dask.distributed.LocalCluster`, however it could be any other kind of cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b968e6d-cbc8-499b-8a41-ef12fe4fdd69",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "\n",
    "For dask, the data must be a `dask.dataframe.DataFrame`. You need to make sure that each time serie is only in one partition and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, except that it's a `dask.dataframe.DataFrame` instead of a `pandas.Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acdff6-49c0-4f28-8a2c-1a75e2c1c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_10</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_90</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 5 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               unique_id              ds        y static_0 static_1\n",
       "npartitions=10                                                     \n",
       "id_00             object  datetime64[ns]  float64    int64    int64\n",
       "id_10                ...             ...      ...      ...      ...\n",
       "...                  ...             ...      ...      ...      ...\n",
       "id_90                ...             ...      ...      ...      ...\n",
       "id_99                ...             ...      ...      ...      ...\n",
       "Dask Name: assign, 5 graph layers"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False, min_length=500, max_length=1_000)\n",
    "npartitions = 10\n",
    "partitioned_series = dd.from_pandas(series.set_index('unique_id'), npartitions=npartitions)  # make sure we split by the id_col\n",
    "partitioned_series = partitioned_series.map_partitions(lambda df: df.reset_index())\n",
    "partitioned_series['unique_id'] = partitioned_series['unique_id'].astype(str)  # can't handle categoricals atm\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa4f88-1a4d-4175-a33c-80d34f61f8cc",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `dask`. The current implementations are in `DaskLGBMForecast` and `DaskXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997af98-7a6e-468a-8f22-d7271b85ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.dask.lgb import DaskLGBMForecast\n",
    "from mlforecast.distributed.models.dask.xgb import DaskXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e482699-e3c3-4fef-b081-112c23bff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DaskXGBForecast(random_state=0), DaskLGBMForecast(random_state=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab284f5f-e6d7-4d73-b0b6-efdf0aea581a",
   "metadata": {},
   "source": [
    "### Training\n",
    "Once we have our models we instantiate a `DistributedMLForecast` object defining our features. We can then call `fit` on this object passing our dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5821d-6c04-4fd6-b5d6-9bbfefe9d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    ")\n",
    "fcst.fit(partitioned_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49e861-74ab-42b0-a220-a823e5c7070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import fugue.api as fa\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241e4da-fc38-4744-bb88-e72c77e63ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# function to test the partition_results data\n",
    "# has the right size\n",
    "def test_partition_results_size(fcst_object, expected_n_partitions):\n",
    "    test_eq(\n",
    "        fa.get_num_partitions(fcst_object._partition_results),\n",
    "        expected_n_partitions,\n",
    "    )\n",
    "    test_eq(\n",
    "        fa.count(fcst_object._partition_results),\n",
    "        expected_n_partitions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4219d-4c48-43a1-87c4-58dfb520022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8531-014f-4d0e-a33e-fe8504d164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "num_partitions_test = 4\n",
    "test_dd = dd.from_pandas(series, npartitions=num_partitions_test) # In this case we dont have to specify the column\n",
    "test_dd['unique_id'] = test_dd['unique_id'].astype(str)\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    "    num_partitions=num_partitions_test\n",
    ")\n",
    "fcst_np.fit(test_dd)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2d411-66f8-425a-bcfe-8c5cc28ca324",
   "metadata": {},
   "source": [
    "Once we have our fitted models we can compute the predictions for the next 7 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21511e5a-750b-4a27-8f68-e9ceff5c7536",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58769a05-3961-49c9-9b50-e1b0713d8c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-27</td>\n",
       "      <td>18.819103</td>\n",
       "      <td>17.900281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-28</td>\n",
       "      <td>89.682961</td>\n",
       "      <td>91.353827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-29</td>\n",
       "      <td>167.320984</td>\n",
       "      <td>167.335792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>245.242462</td>\n",
       "      <td>243.613032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>315.341370</td>\n",
       "      <td>313.804709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast\n",
       "0     id_00 2002-09-27        18.819103         17.900281\n",
       "1     id_00 2002-09-28        89.682961         91.353827\n",
       "2     id_00 2002-09-29       167.320984        167.335792\n",
       "3     id_00 2002-09-30       245.242462        243.613032\n",
       "4     id_00 2002-10-01       315.341370        313.804709"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7).compute()\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6f1f2-d22b-48d7-a5e5-77d400cd4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "preds2 = fcst.predict(7).compute()\n",
    "preds3 = fcst.predict(7, new_df=partitioned_series).compute()\n",
    "pd.testing.assert_frame_equal(preds, preds2)\n",
    "pd.testing.assert_frame_equal(preds, preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502aeadd-2fd5-4d16-8dfb-56a77080c072",
   "metadata": {},
   "source": [
    "### Saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10073e2c-c36e-49d2-8996-b90fde11123a",
   "metadata": {},
   "source": [
    "Once you've trained your model you can use the `DistributedMLForecast.save` method to save the artifacts for inference. Keep in mind that if you're on a remote cluster you should set a remote storage like S3 as the destination.\n",
    "\n",
    "mlforecast uses [fsspec](https://filesystem-spec.readthedocs.io/en/latest/) to handle the different filesystems, so if you're using s3 for example you also need to install [s3fs](https://s3fs.readthedocs.io/en/latest/). If you're using pip you can just include the aws extra, e.g. `pip install 'mlforecast[aws,dask]'`, which will install the required dependencies to perform distributed training with dask and saving to S3. If you're using conda you'll have to manually install them (`conda install dask fsspec fugue s3fs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bc64f-9567-40be-a6df-70efc7f4dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define unique name for CI\n",
    "def build_unique_name(engine):\n",
    "    pyver = f'{sys.version_info.major}_{sys.version_info.minor}'\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    sha = repo.head.object.hexsha\n",
    "    return f'{sys.platform}-{pyver}-{engine}-{sha}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb761c-8183-4aab-86b9-84ff3277e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = build_unique_name('dask')\n",
    "save_path = f's3://nixtla-tmp/mlf/{save_dir}'\n",
    "fcst.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7147a8d-5860-4eb8-88b2-78fdc96aa156",
   "metadata": {},
   "source": [
    "Once you've saved your forecast object you can then load it back by specifying the path where it was saved along with an engine, which will be used to perform the distributed computations (in this case the dask client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba10a0-9562-4373-a755-40fff7402e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst2 = DistributedMLForecast.load(save_path, engine=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6ec8a-8a50-4bd6-b16e-af57bd0063d8",
   "metadata": {},
   "source": [
    "We can verify that this object produces the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982ed67-d7be-485b-9d25-82f34ba2fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fa.as_pandas(fcst.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds2 = fa.as_pandas(fcst2.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(preds, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29841c02-b0bc-44cc-a8f3-da31b442584b",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296af9be-4149-4b47-9386-fc92bff65d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ")\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e80450-d582-42bb-8bf4-ff925d5e74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-16</td>\n",
       "      <td>18.710407</td>\n",
       "      <td>17.788198</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>11.878591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-17</td>\n",
       "      <td>93.290802</td>\n",
       "      <td>91.745863</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>75.108162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-18</td>\n",
       "      <td>169.573212</td>\n",
       "      <td>167.333674</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>175.278407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-19</td>\n",
       "      <td>240.957352</td>\n",
       "      <td>240.434233</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>226.062025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-20</td>\n",
       "      <td>305.884064</td>\n",
       "      <td>313.133459</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>318.433401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast     cutoff  \\\n",
       "0     id_00 2002-08-16        18.710407         17.788198 2002-08-15   \n",
       "1     id_00 2002-08-17        93.290802         91.745863 2002-08-15   \n",
       "2     id_00 2002-08-18       169.573212        167.333674 2002-08-15   \n",
       "3     id_00 2002-08-19       240.957352        240.434233 2002-08-15   \n",
       "4     id_00 2002-08-20       305.884064        313.133459 2002-08-15   \n",
       "\n",
       "            y  \n",
       "0   11.878591  \n",
       "1   75.108162  \n",
       "2  175.278407  \n",
       "3  226.062025  \n",
       "4  318.433401  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d27b0-ba00-4141-a50c-ab39385e8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mlforecast.distributed.forecast import WindowInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457500-a299-4eb7-b13f-78412f4d302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# input_size\n",
    "input_size = 100\n",
    "reduced_train = fcst._preprocess(\n",
    "    partitioned_series,\n",
    "    id_col='unique_id',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    dropna=False,\n",
    "    window_info=WindowInfo(\n",
    "        n_windows=1,\n",
    "        window_size=10,\n",
    "        step_size=None,\n",
    "        i_window=0,\n",
    "        input_size=input_size,\n",
    "    ),\n",
    ")\n",
    "assert reduced_train.groupby('unique_id').size().compute().max() == input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cdca0-6368-42d9-bc57-2390e6430b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "cv_res_no_refit = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    "    refit=False\n",
    ")\n",
    "cv_results_df = cv_res.compute()\n",
    "cv_results_no_refit_df = cv_res_no_refit.compute()\n",
    "# test we recover the same \"metadata\"\n",
    "models = ['DaskXGBForecast', 'DaskLGBMForecast']\n",
    "test_eq(\n",
    "    cv_results_no_refit_df.drop(columns=models),\n",
    "    cv_results_df.drop(columns=models)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34651ae-5be4-4e86-b44f-fbd15c4d72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "non_std_series = partitioned_series.copy()\n",
    "non_std_series['ds'] = non_std_series.map_partitions(lambda part: part.groupby('unique_id').cumcount())\n",
    "non_std_series = non_std_series.rename(columns={'ds': 'time', 'y': 'value', 'unique_id': 'some_id'})\n",
    "flow_params = dict(\n",
    "    models=[DaskXGBForecast(random_state=0)],\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst = DistributedMLForecast(freq='D', **flow_params)\n",
    "fcst.fit(partitioned_series)\n",
    "preds = fcst.predict(7).compute()\n",
    "fcst2 = DistributedMLForecast(freq=1, **flow_params)\n",
    "fcst2.preprocess(non_std_series, id_col='some_id', time_col='time', target_col='value')\n",
    "fcst2.models_ = fcst.models_  # distributed training can end up with different fits\n",
    "non_std_preds = fcst2.predict(7).compute()\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds.drop(columns='ds'),\n",
    "    non_std_preds.drop(columns='time').rename(columns={'some_id': 'unique_id'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9b3ae-3859-4989-aa56-85390f63cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df016-bc2a-47c1-afeb-4394ca7695cb",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfae838-6305-4a48-8a82-2f3c3eb653f5",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97595792-8173-4d0e-ac56-174c3d698d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119c014-b51b-4ba0-ab28-585665c03ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.2\")\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0371e5b-5700-4466-86e3-07e35499200b",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For spark, the data must be a `pyspark DataFrame`. You need to make sure that each time serie is only in one partition (which you can do using `repartitionByRange`, for example) and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc337af2-0952-4f7c-98ad-baa87bb16d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPartitions = 4\n",
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "spark_series = spark.createDataFrame(series).repartitionByRange(numPartitions, 'unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959aec60-ed2e-4538-8d6c-09b0a66bc35d",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `spark`. The current implementations are in `SparkLGBMForecast` and `SparkXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609dee3-f959-4c28-b913-0871f94e2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.spark.lgb import SparkLGBMForecast\n",
    "\n",
    "models = [SparkLGBMForecast()]\n",
    "try:\n",
    "    from xgboost.spark import SparkXGBRegressor\n",
    "    from mlforecast.distributed.models.spark.xgb import SparkXGBForecast\n",
    "    models.append(SparkXGBForecast())\n",
    "except ModuleNotFoundError:  # py < 38\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690336b5-ad1a-4ff2-a42b-fd2bf15870fe",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a458c1-855d-4955-b77b-5dbdb5ecacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    ")\n",
    "fcst.fit(\n",
    "    spark_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33443e25-3a35-4abc-85f1-2aa774d64689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7ebdd-6d6a-4e0d-babf-d7fe11cd09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "test_spark_df = spark.createDataFrame(series)\n",
    "num_partitions_test = 10\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    num_partitions=num_partitions_test,\n",
    ")\n",
    "fcst_np.fit(test_spark_df)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1b654-5641-4b4d-b503-6606f94396cd",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d2230-60f5-47f1-820b-af2ca7311b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6bbd2-9806-4b12-91a2-1b5571ae1550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>417.848083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>503.371185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>18.514997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>109.317825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>181.431747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast\n",
       "0     id_00 2001-05-15         422.139843        417.848083\n",
       "1     id_00 2001-05-16         497.180212        503.371185\n",
       "2     id_00 2001-05-17          13.062478         18.514997\n",
       "3     id_00 2001-05-18         100.601041        109.317825\n",
       "4     id_00 2001-05-19         180.707848        181.431747"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577a473-0b27-4a3b-84c5-4f6053ba6f67",
   "metadata": {},
   "source": [
    "### Saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cde59-2758-4f49-936d-789929f80a00",
   "metadata": {},
   "source": [
    "Once you've trained your model you can use the `DistributedMLForecast.save` method to save the artifacts for inference. Keep in mind that if you're on a remote cluster you should set a remote storage like S3 as the destination.\n",
    "\n",
    "mlforecast uses [fsspec](https://filesystem-spec.readthedocs.io/en/latest/) to handle the different filesystems, so if you're using s3 for example you also need to install [s3fs](https://s3fs.readthedocs.io/en/latest/). If you're using pip you can just include the aws extra, e.g. `pip install 'mlforecast[aws,spark]'`, which will install the required dependencies to perform distributed training with spark and saving to S3. If you're using conda you'll have to manually install them (`conda install fsspec fugue pyspark s3fs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bff80-c052-4a24-a225-33b774d7d75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "save_dir = build_unique_name('spark')\n",
    "save_path = f's3://nixtla-tmp/mlf/{save_dir}'\n",
    "fcst.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4a6de-1c34-4112-bb18-2818b808b8eb",
   "metadata": {},
   "source": [
    "Once you've saved your forecast object you can then load it back by specifying the path where it was saved along with an engine, which will be used to perform the distributed computations (in this case the dask client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191d277-ce70-464b-a44f-0332a96ec7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fcst2 = DistributedMLForecast.load(save_path, engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18808439-8531-4cd9-95bc-c28fd2c7987a",
   "metadata": {},
   "source": [
    "We can verify that this object produces the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04005646-d244-48c8-b11c-124a41d9740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds = fa.as_pandas(fcst.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds2 = fa.as_pandas(fcst2.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(preds, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad24338-2634-4b27-8f73-dc162338dd38",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb396b93-b160-4325-9d5c-bf391ef87db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    spark_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c735385-7104-4ced-a253-d4a16b8bbb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_05</td>\n",
       "      <td>2001-04-04</td>\n",
       "      <td>24.826767</td>\n",
       "      <td>29.030163</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>31.499342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_14</td>\n",
       "      <td>2001-04-11</td>\n",
       "      <td>267.395290</td>\n",
       "      <td>266.155212</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>259.974347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_18</td>\n",
       "      <td>2001-04-03</td>\n",
       "      <td>76.951336</td>\n",
       "      <td>107.142570</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>83.135732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_18</td>\n",
       "      <td>2001-04-11</td>\n",
       "      <td>103.118420</td>\n",
       "      <td>103.188408</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>98.877898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2001-04-13</td>\n",
       "      <td>366.696754</td>\n",
       "      <td>383.428070</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>372.730469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast     cutoff  \\\n",
       "0     id_05 2001-04-04          24.826767         29.030163 2001-04-02   \n",
       "1     id_14 2001-04-11         267.395290        266.155212 2001-04-02   \n",
       "2     id_18 2001-04-03          76.951336        107.142570 2001-04-02   \n",
       "3     id_18 2001-04-11         103.118420        103.188408 2001-04-02   \n",
       "4     id_19 2001-04-13         366.696754        383.428070 2001-04-02   \n",
       "\n",
       "            y  \n",
       "0   31.499342  \n",
       "1  259.974347  \n",
       "2   83.135732  \n",
       "3   98.877898  \n",
       "4  372.730469  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2f8e2-f8d8-4efb-8114-47eaf8703170",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218f6f9-22d5-4ec1-9f04-3b6b6368ea69",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e192699-ecda-4eb2-8274-fc1246e4d6e8",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d064e-1025-4407-b701-ccad70aa90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.cluster_utils import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753bdd4-73e0-4f96-84f8-1f148d879dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_cluster = Cluster(\n",
    "    initialize_head=True,\n",
    "    head_node_args={\"num_cpus\": 2}\n",
    ")\n",
    "ray.init(address=ray_cluster.address, ignore_reinit_error=True)\n",
    "# add mock node to simulate a cluster\n",
    "mock_node = ray_cluster.add_node(num_cpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b81d4-598d-4eec-820e-72a81177cedb",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For ray, the data must be a `ray DataFrame`. It is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f033849-67d3-469c-9608-d589153890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "# we need noncategory unique_id\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "ray_series = ray.data.from_pandas(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2726794-b6cd-462a-98b4-e8ec4c84ea75",
   "metadata": {},
   "source": [
    "### Models\n",
    "The ray integration allows to include `lightgbm` (`RayLGBMRegressor`), and `xgboost` (`RayXGBRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c023f51-1d0c-4596-a8d7-6f167c4ad257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.ray.lgb import RayLGBMForecast\n",
    "from mlforecast.distributed.models.ray.xgb import RayXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2708a2b-a648-4ce1-8702-ca8a392c8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RayLGBMForecast(),\n",
    "    RayXGBForecast(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d90b92-36d4-4691-98c9-e9b1698d2bd4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0dab0-cd60-4519-a207-c087f193f30f",
   "metadata": {},
   "source": [
    "To control the number of partitions to use using Ray, we have to include `num_partitions` to `DistributedMLForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fd794-b380-40e2-821c-dacdc513bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355afcd8-44ba-44c6-a92d-0f45c6fc9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    num_partitions=num_partitions, # Use num_partitions to reduce overhead\n",
    ")\n",
    "fcst.fit(\n",
    "    ray_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9642b-17ca-4571-9f8a-f42c13a69987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8ad06-2f0c-4041-ac25-9aadac94c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "# In this case we test that the default behavior \n",
    "# for ray datasets works as expected\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst_np.fit(ray_series)\n",
    "# we dont use test_partition_results_size\n",
    "# since the number of objects is different \n",
    "# from the number of partitions\n",
    "test_eq(fa.count(fcst_np._partition_results), 100) # number of series\n",
    "preds_np = fcst_np.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4af13-c04c-4e9b-ab26-92f6d7b9745d",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e16b63-aeec-41d8-acff-ca982d3b952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ee74e-1346-4991-bcf2-5b2a887eb5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>418.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>502.229492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>18.364956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>102.921730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>183.109436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast\n",
       "0     id_00 2001-05-15       422.139843      418.110107\n",
       "1     id_00 2001-05-16       497.180212      502.229492\n",
       "2     id_00 2001-05-17        13.062478       18.364956\n",
       "3     id_00 2001-05-18       100.601041      102.921730\n",
       "4     id_00 2001-05-19       180.707848      183.109436"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a314c-a920-44a4-9570-a4bdaa0e37b5",
   "metadata": {},
   "source": [
    "### Saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a713dc-dd3d-45dc-9725-52f3f4d2742a",
   "metadata": {},
   "source": [
    "Once you've trained your model you can use the `DistributedMLForecast.save` method to save the artifacts for inference. Keep in mind that if you're on a remote cluster you should set a remote storage like S3 as the destination.\n",
    "\n",
    "mlforecast uses [fsspec](https://filesystem-spec.readthedocs.io/en/latest/) to handle the different filesystems, so if you're using s3 for example you also need to install [s3fs](https://s3fs.readthedocs.io/en/latest/). If you're using pip you can just include the aws extra, e.g. `pip install 'mlforecast[aws,ray]'`, which will install the required dependencies to perform distributed training with ray and saving to S3. If you're using conda you'll have to manually install them (`conda install fsspec fugue ray s3fs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d77aa-8481-40b8-a062-10d45bc1941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = build_unique_name('ray')\n",
    "save_path = f's3://nixtla-tmp/mlf/{save_dir}'\n",
    "fcst.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce44d0-3035-4919-830a-d45a3d47d9b1",
   "metadata": {},
   "source": [
    "Once you've saved your forecast object you can then load it back by specifying the path where it was saved along with an engine, which will be used to perform the distributed computations (in this case the dask client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e75aa-42e4-4c83-93f3-a4fa9a5097ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst2 = DistributedMLForecast.load(save_path, engine='ray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83efc5-0e7c-4345-b86a-624737c28d15",
   "metadata": {},
   "source": [
    "We can verify that this object produces the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a17fcb-4f0f-4551-b9f9-e31ec9bb0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fa.as_pandas(fcst.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds2 = fa.as_pandas(fcst2.predict(10)).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(preds, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb901de2-c98e-47fb-81e2-714010114a91",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0ec2a-cc6a-4195-a457-8f6243334d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    ray_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ecc467-80c7-4c0e-98d6-af77c9fc7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>124.758319</td>\n",
       "      <td>152.856125</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>117.876479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-02</td>\n",
       "      <td>145.041000</td>\n",
       "      <td>177.355331</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>153.394375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-03</td>\n",
       "      <td>178.838681</td>\n",
       "      <td>66.459068</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>175.337772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-04</td>\n",
       "      <td>27.212783</td>\n",
       "      <td>94.735237</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>13.202898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-05</td>\n",
       "      <td>56.624979</td>\n",
       "      <td>125.717896</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>30.203090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast     cutoff           y\n",
       "0     id_01 2001-05-01       124.758319      152.856125 2001-04-30  117.876479\n",
       "1     id_01 2001-05-02       145.041000      177.355331 2001-04-30  153.394375\n",
       "2     id_01 2001-05-03       178.838681       66.459068 2001-04-30  175.337772\n",
       "3     id_01 2001-05-04        27.212783       94.735237 2001-04-30   13.202898\n",
       "4     id_01 2001-05-05        56.624979      125.717896 2001-04-30   30.203090"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba9328-7183-4744-9089-8ef02d3e9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
