{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b44ee1-af97-490a-ad62-03b2f804e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693434b-0290-4ffd-88f9-a4267c11b548",
   "metadata": {},
   "source": [
    "# Quick start (distributed)\n",
    "\n",
    "> Minimal example of distributed training with MLForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e9e05-e8b2-433e-9ff2-16e652cf6acb",
   "metadata": {},
   "source": [
    "The `DistributedMLForecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way.\n",
    "\n",
    "The different things that you need to use `DistributedMLForecast` (as opposed to `MLForecast`) are:\n",
    "\n",
    "1. You need to set up a cluster. We currently support dask, ray and spark.\n",
    "2. Your data needs to be a distributed collection (dask, ray or spark dataframe).\n",
    "3. You need to use a model that implements distributed training in your framework of choice, e.g. SynapseML for LightGBM in spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7853f-df6e-4bf2-b2d9-cb3b4c6a0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.distributed import DistributedMLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f930a27-b15f-438a-aab2-ccafc77e09f4",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af70aed-bfb9-4c36-a4c4-cf546f8655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe3454-b2e1-40d0-a623-6ae1fe486536",
   "metadata": {},
   "source": [
    "### Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9868f8-38a5-4a9f-829c-47a10a522fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd61b21-9a22-42dc-ba19-d6de68dc8eba",
   "metadata": {},
   "source": [
    "Here we define a client that connects to a `dask.distributed.LocalCluster`, however it could be any other kind of cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b968e6d-cbc8-499b-8a41-ef12fe4fdd69",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "\n",
    "For dask, the data must be a `dask.dataframe.DataFrame`. You need to make sure that each time serie is only in one partition and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, except that it's a `dask.dataframe.DataFrame` instead of a `pandas.Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acdff6-49c0-4f28-8a2c-1a75e2c1c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_10</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_90</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 5 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               unique_id              ds        y static_0 static_1\n",
       "npartitions=10                                                     \n",
       "id_00             object  datetime64[ns]  float64    int64    int64\n",
       "id_10                ...             ...      ...      ...      ...\n",
       "...                  ...             ...      ...      ...      ...\n",
       "id_90                ...             ...      ...      ...      ...\n",
       "id_99                ...             ...      ...      ...      ...\n",
       "Dask Name: assign, 5 graph layers"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False, min_length=500, max_length=1_000)\n",
    "npartitions = 10\n",
    "partitioned_series = dd.from_pandas(series.set_index('unique_id'), npartitions=npartitions)  # make sure we split by the id_col\n",
    "partitioned_series = partitioned_series.map_partitions(lambda df: df.reset_index())\n",
    "partitioned_series['unique_id'] = partitioned_series['unique_id'].astype(str)  # can't handle categoricals atm\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa4f88-1a4d-4175-a33c-80d34f61f8cc",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `dask`. The current implementations are in `DaskLGBMForecast` and `DaskXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997af98-7a6e-468a-8f22-d7271b85ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.dask.lgb import DaskLGBMForecast\n",
    "from mlforecast.distributed.models.dask.xgb import DaskXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e482699-e3c3-4fef-b081-112c23bff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DaskXGBForecast(random_state=0), DaskLGBMForecast(random_state=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab284f5f-e6d7-4d73-b0b6-efdf0aea581a",
   "metadata": {},
   "source": [
    "### Training\n",
    "Once we have our models we instantiate a `DistributedMLForecast` object defining our features. We can then call `fit` on this object passing our dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5821d-6c04-4fd6-b5d6-9bbfefe9d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    ")\n",
    "fcst.fit(partitioned_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49e861-74ab-42b0-a220-a823e5c7070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import fugue.api as fa\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241e4da-fc38-4744-bb88-e72c77e63ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# function to test the partition_results data\n",
    "# has the right size\n",
    "def test_partition_results_size(fcst_object, expected_n_partitions):\n",
    "    test_eq(\n",
    "        fa.get_num_partitions(fcst_object.partition_results),\n",
    "        expected_n_partitions,\n",
    "    )\n",
    "    test_eq(\n",
    "        fa.count(fcst_object.partition_results),\n",
    "        expected_n_partitions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4219d-4c48-43a1-87c4-58dfb520022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8531-014f-4d0e-a33e-fe8504d164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "num_partitions_test = 4\n",
    "test_dd = dd.from_pandas(series, npartitions=num_partitions_test) # In this case we dont have to specify the column\n",
    "test_dd['unique_id'] = test_dd['unique_id'].astype(str)\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    engine=client,\n",
    "    num_partitions=num_partitions_test\n",
    ")\n",
    "fcst_np.fit(test_dd)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).compute().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2d411-66f8-425a-bcfe-8c5cc28ca324",
   "metadata": {},
   "source": [
    "Once we have our fitted models we can compute the predictions for the next 7 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21511e5a-750b-4a27-8f68-e9ceff5c7536",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58769a05-3961-49c9-9b50-e1b0713d8c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-27</td>\n",
       "      <td>18.676165</td>\n",
       "      <td>17.691819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-28</td>\n",
       "      <td>90.782455</td>\n",
       "      <td>90.198168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-29</td>\n",
       "      <td>169.503098</td>\n",
       "      <td>163.522410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>241.540359</td>\n",
       "      <td>244.411795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>315.643768</td>\n",
       "      <td>313.694593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast\n",
       "0     id_00 2002-09-27        18.676165         17.691819\n",
       "1     id_00 2002-09-28        90.782455         90.198168\n",
       "2     id_00 2002-09-29       169.503098        163.522410\n",
       "3     id_00 2002-09-30       241.540359        244.411795\n",
       "4     id_00 2002-10-01       315.643768        313.694593"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7)\n",
    "preds.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6f1f2-d22b-48d7-a5e5-77d400cd4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "preds = preds.compute()\n",
    "preds2 = fcst.predict(7).compute()\n",
    "preds3 = fcst.predict(7, new_df=partitioned_series).compute()\n",
    "pd.testing.assert_frame_equal(preds, preds2)\n",
    "pd.testing.assert_frame_equal(preds, preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29841c02-b0bc-44cc-a8f3-da31b442584b",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296af9be-4149-4b47-9386-fc92bff65d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ")\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e80450-d582-42bb-8bf4-ff925d5e74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DaskXGBForecast</th>\n",
       "      <th>DaskLGBMForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-16</td>\n",
       "      <td>19.199099</td>\n",
       "      <td>18.868631</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>11.878591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-17</td>\n",
       "      <td>93.734985</td>\n",
       "      <td>92.715766</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>75.108162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-18</td>\n",
       "      <td>163.924606</td>\n",
       "      <td>167.229730</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>175.278407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-19</td>\n",
       "      <td>245.957672</td>\n",
       "      <td>241.534768</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>226.062025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2002-08-20</td>\n",
       "      <td>309.519073</td>\n",
       "      <td>306.687081</td>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>318.433401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DaskXGBForecast  DaskLGBMForecast     cutoff  \\\n",
       "0     id_00 2002-08-16        19.199099         18.868631 2002-08-15   \n",
       "1     id_00 2002-08-17        93.734985         92.715766 2002-08-15   \n",
       "2     id_00 2002-08-18       163.924606        167.229730 2002-08-15   \n",
       "3     id_00 2002-08-19       245.957672        241.534768 2002-08-15   \n",
       "4     id_00 2002-08-20       309.519073        306.687081 2002-08-15   \n",
       "\n",
       "            y  \n",
       "0   11.878591  \n",
       "1   75.108162  \n",
       "2  175.278407  \n",
       "3  226.062025  \n",
       "4  318.433401  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d27b0-ba00-4141-a50c-ab39385e8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mlforecast.distributed.forecast import WindowInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457500-a299-4eb7-b13f-78412f4d302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# input_size\n",
    "input_size = 100\n",
    "reduced_train = fcst._preprocess(\n",
    "    partitioned_series,\n",
    "    id_col='unique_id',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    dropna=False,\n",
    "    window_info=WindowInfo(\n",
    "        n_windows=1,\n",
    "        window_size=10,\n",
    "        step_size=None,\n",
    "        i_window=0,\n",
    "        input_size=input_size,\n",
    "    ),\n",
    ")\n",
    "assert reduced_train.groupby('unique_id').size().compute().max() == input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cdca0-6368-42d9-bc57-2390e6430b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "cv_res_no_refit = fcst.cross_validation(\n",
    "    partitioned_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    "    refit=False\n",
    ")\n",
    "cv_results_df = cv_res.compute()\n",
    "cv_results_no_refit_df = cv_res_no_refit.compute()\n",
    "# test we recover the same \"metadata\"\n",
    "models = ['DaskXGBForecast', 'DaskLGBMForecast']\n",
    "test_eq(\n",
    "    cv_results_no_refit_df.drop(columns=models),\n",
    "    cv_results_df.drop(columns=models)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34651ae-5be4-4e86-b44f-fbd15c4d72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "non_std_series = partitioned_series.copy()\n",
    "non_std_series['ds'] = non_std_series.map_partitions(lambda part: part.groupby('unique_id').cumcount())\n",
    "non_std_series = non_std_series.rename(columns={'ds': 'time', 'y': 'value', 'unique_id': 'some_id'})\n",
    "flow_params = dict(\n",
    "    models=[DaskXGBForecast(random_state=0)],\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst = DistributedMLForecast(freq='D', **flow_params)\n",
    "fcst.fit(partitioned_series)\n",
    "preds = fcst.predict(7).compute()\n",
    "fcst2 = DistributedMLForecast(freq=1, **flow_params)\n",
    "fcst2.preprocess(non_std_series, id_col='some_id', time_col='time', target_col='value')\n",
    "fcst2.models_ = fcst.models_  # distributed training can end up with different fits\n",
    "non_std_preds = fcst2.predict(7).compute()\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds.drop(columns='ds'),\n",
    "    non_std_preds.drop(columns='time').rename(columns={'some_id': 'unique_id'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9b3ae-3859-4989-aa56-85390f63cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df016-bc2a-47c1-afeb-4394ca7695cb",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfae838-6305-4a48-8a82-2f3c3eb653f5",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97595792-8173-4d0e-ac56-174c3d698d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119c014-b51b-4ba0-ab28-585665c03ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.2\")\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0371e5b-5700-4466-86e3-07e35499200b",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For spark, the data must be a `pyspark DataFrame`. You need to make sure that each time serie is only in one partition (which you can do using `repartitionByRange`, for example) and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc337af2-0952-4f7c-98ad-baa87bb16d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPartitions = 4\n",
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "spark_series = spark.createDataFrame(series).repartitionByRange(numPartitions, 'unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959aec60-ed2e-4538-8d6c-09b0a66bc35d",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `spark`. The current implementations are in `SparkLGBMForecast` and `SparkXGBForecast` which are just wrappers around the native implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609dee3-f959-4c28-b913-0871f94e2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.spark.lgb import SparkLGBMForecast\n",
    "\n",
    "models = [SparkLGBMForecast()]\n",
    "try:\n",
    "    from xgboost.spark import SparkXGBRegressor\n",
    "    from mlforecast.distributed.models.spark.xgb import SparkXGBForecast\n",
    "    models.append(SparkXGBForecast())\n",
    "except ModuleNotFoundError:  # py < 38\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690336b5-ad1a-4ff2-a42b-fd2bf15870fe",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a458c1-855d-4955-b77b-5dbdb5ecacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    ")\n",
    "fcst.fit(\n",
    "    spark_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33443e25-3a35-4abc-85f1-2aa774d64689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7ebdd-6d6a-4e0d-babf-d7fe11cd09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "test_spark_df = spark.createDataFrame(series)\n",
    "num_partitions_test = 10\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    "    num_partitions=num_partitions_test,\n",
    ")\n",
    "fcst_np.fit(test_spark_df)\n",
    "test_partition_results_size(fcst_np, num_partitions_test)\n",
    "preds_np = fcst_np.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).toPandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1b654-5641-4b4d-b503-6606f94396cd",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d2230-60f5-47f1-820b-af2ca7311b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6bbd2-9806-4b12-91a2-1b5571ae1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/miniforge3/envs/mlforecast/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>421.606537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>505.575836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>15.462178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>102.123245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>182.308197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast\n",
       "0     id_00 2001-05-15         422.139843        421.606537\n",
       "1     id_00 2001-05-16         497.180212        505.575836\n",
       "2     id_00 2001-05-17          13.062478         15.462178\n",
       "3     id_00 2001-05-18         100.601041        102.123245\n",
       "4     id_00 2001-05-19         180.707848        182.308197"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad24338-2634-4b27-8f73-dc162338dd38",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb396b93-b160-4325-9d5c-bf391ef87db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    spark_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c735385-7104-4ced-a253-d4a16b8bbb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>SparkLGBMForecast</th>\n",
       "      <th>SparkXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_04</td>\n",
       "      <td>2001-04-03</td>\n",
       "      <td>206.226409</td>\n",
       "      <td>202.242142</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>216.937502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-03</td>\n",
       "      <td>415.538504</td>\n",
       "      <td>420.034576</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>429.217687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-07</td>\n",
       "      <td>180.093252</td>\n",
       "      <td>179.349228</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>192.303211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_12</td>\n",
       "      <td>2001-04-07</td>\n",
       "      <td>143.923572</td>\n",
       "      <td>145.318710</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>155.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2001-04-15</td>\n",
       "      <td>19.385093</td>\n",
       "      <td>74.153099</td>\n",
       "      <td>2001-04-02</td>\n",
       "      <td>14.420419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  SparkLGBMForecast  SparkXGBForecast     cutoff  \\\n",
       "0     id_04 2001-04-03         206.226409        202.242142 2001-04-02   \n",
       "1     id_00 2001-04-03         415.538504        420.034576 2001-04-02   \n",
       "2     id_00 2001-04-07         180.093252        179.349228 2001-04-02   \n",
       "3     id_12 2001-04-07         143.923572        145.318710 2001-04-02   \n",
       "4     id_19 2001-04-15          19.385093         74.153099 2001-04-02   \n",
       "\n",
       "            y  \n",
       "0  216.937502  \n",
       "1  429.217687  \n",
       "2  192.303211  \n",
       "3  155.071484  \n",
       "4   14.420419  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2f8e2-f8d8-4efb-8114-47eaf8703170",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218f6f9-22d5-4ec1-9f04-3b6b6368ea69",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e192699-ecda-4eb2-8274-fc1246e4d6e8",
   "metadata": {},
   "source": [
    "### Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d064e-1025-4407-b701-ccad70aa90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.cluster_utils import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753bdd4-73e0-4f96-84f8-1f148d879dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_cluster = Cluster(\n",
    "    initialize_head=True,\n",
    "    head_node_args={\"num_cpus\": 2}\n",
    ")\n",
    "ray.init(address=ray_cluster.address, ignore_reinit_error=True)\n",
    "# add mock node to simulate a cluster\n",
    "mock_node = ray_cluster.add_node(num_cpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b81d4-598d-4eec-820e-72a81177cedb",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "For ray, the data must be a `ray DataFrame`. It is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `MLForecast`, i.e. it should have at least an id column, a time column and a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f033849-67d3-469c-9608-d589153890df",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "# we need noncategory unique_id\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "ray_series = ray.data.from_pandas(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2726794-b6cd-462a-98b4-e8ec4c84ea75",
   "metadata": {},
   "source": [
    "### Models\n",
    "The ray integration allows to include `lightgbm` (`RayLGBMRegressor`), and `xgboost` (`RayXGBRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c023f51-1d0c-4596-a8d7-6f167c4ad257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.distributed.models.ray.lgb import RayLGBMForecast\n",
    "from mlforecast.distributed.models.ray.xgb import RayXGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2708a2b-a648-4ce1-8702-ca8a392c8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RayLGBMForecast(),\n",
    "    RayXGBForecast(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d90b92-36d4-4691-98c9-e9b1698d2bd4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0dab0-cd60-4519-a207-c087f193f30f",
   "metadata": {},
   "source": [
    "To control the number of partitions to use using Ray, we have to include `num_partitions` to `DistributedMLForecast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fd794-b380-40e2-821c-dacdc513bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355afcd8-44ba-44c6-a92d-0f45c6fc9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = DistributedMLForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    num_partitions=num_partitions, # Use num_partitions to reduce overhead\n",
    ")\n",
    "fcst.fit(\n",
    "    ray_series,\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9642b-17ca-4571-9f8a-f42c13a69987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_partition_results_size(fcst, num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8ad06-2f0c-4041-ac25-9aadac94c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test num_partitions works properly\n",
    "# In this case we test that the default behavior \n",
    "# for ray datasets works as expected\n",
    "fcst_np = DistributedMLForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst_np.fit(ray_series)\n",
    "# we dont use test_partition_results_size\n",
    "# since the number of objects is different \n",
    "# from the number of partitions\n",
    "test_eq(fa.count(fcst_np.partition_results), 100) # number of series\n",
    "preds_np = fcst_np.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "preds = fcst.predict(7).to_pandas().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds[['unique_id', 'ds']], \n",
    "    preds_np[['unique_id', 'ds']], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4af13-c04c-4e9b-ab26-92f6d7b9745d",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e16b63-aeec-41d8-acff-ca982d3b952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(14).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ee74e-1346-4991-bcf2-5b2a887eb5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>422.139843</td>\n",
       "      <td>419.180908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>497.180212</td>\n",
       "      <td>502.074249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.062478</td>\n",
       "      <td>16.981802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>100.601041</td>\n",
       "      <td>102.311279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>180.707848</td>\n",
       "      <td>181.406143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast\n",
       "0     id_00 2001-05-15       422.139843      419.180908\n",
       "1     id_00 2001-05-16       497.180212      502.074249\n",
       "2     id_00 2001-05-17        13.062478       16.981802\n",
       "3     id_00 2001-05-18       100.601041      102.311279\n",
       "4     id_00 2001-05-19       180.707848      181.406143"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb901de2-c98e-47fb-81e2-714010114a91",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0ec2a-cc6a-4195-a457-8f6243334d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(\n",
    "    ray_series,\n",
    "    n_windows=3,\n",
    "    h=14,\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ecc467-80c7-4c0e-98d6-af77c9fc7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RayLGBMForecast</th>\n",
       "      <th>RayXGBForecast</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>124.758319</td>\n",
       "      <td>122.131401</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>117.876479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-02</td>\n",
       "      <td>145.041000</td>\n",
       "      <td>149.217972</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>153.394375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-03</td>\n",
       "      <td>178.838681</td>\n",
       "      <td>178.600784</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>175.337772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-04</td>\n",
       "      <td>27.212783</td>\n",
       "      <td>10.926006</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>13.202898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_01</td>\n",
       "      <td>2001-05-05</td>\n",
       "      <td>56.624979</td>\n",
       "      <td>38.081158</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>30.203090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  RayLGBMForecast  RayXGBForecast     cutoff           y\n",
       "0     id_01 2001-05-01       124.758319      122.131401 2001-04-30  117.876479\n",
       "1     id_01 2001-05-02       145.041000      149.217972 2001-04-30  153.394375\n",
       "2     id_01 2001-05-03       178.838681      178.600784 2001-04-30  175.337772\n",
       "3     id_01 2001-05-04        27.212783       10.926006 2001-04-30   13.202898\n",
       "4     id_01 2001-05-05        56.624979       38.081158 2001-04-30   30.203090"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba9328-7183-4744-9089-8ef02d3e9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
