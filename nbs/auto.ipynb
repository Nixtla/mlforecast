{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceffd55-8df5-46ca-bc53-b7fc9e2e6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ae2b-2754-40eb-a649-0667f6dc87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b2082-4138-4d54-8e10-9daa3747768c",
   "metadata": {},
   "source": [
    "# Auto\n",
    "Automatic model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30d1be-fb7e-457d-9ac2-9923636ff9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import utilsforecast.processing as ufp\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from utilsforecast.compat import DataFrame\n",
    "from utilsforecast.losses import smape\n",
    "from utilsforecast.validation import validate_freq\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.core import Freq, _get_model_name, _name_models\n",
    "from mlforecast.lag_transforms import ExponentiallyWeightedMean, RollingMean\n",
    "from mlforecast.optimization import _TrialToConfig, mlforecast_objective\n",
    "from mlforecast.target_transforms import Differences, LocalStandardScaler, GlobalSklearnTransformer\n",
    "from mlforecast.utils import PredictionIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cbbcb-b4df-4998-801b-75bebdc9f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def lightgbm_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'bagging_freq': 1,\n",
    "        'learning_rate': 0.05,\n",
    "        'verbosity': -1,        \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 1000, log=True),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 4096, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'objective': trial.suggest_categorical('objective', ['l1', 'l2']),\n",
    "    }\n",
    "\n",
    "def xgboost_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_float('bagging_freq', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'min_data_in_leaf': trial.suggest_float('min_data_in_leaf', 1, 100),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 10),\n",
    "    }\n",
    "    \n",
    "def catboost_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'silent': True,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'depth': trial.suggest_int('depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "        'min_data_in_leaf': trial.suggest_float('min_data_in_leaf', 1, 100),\n",
    "    }\n",
    "    \n",
    "def linear_regression_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False])\n",
    "    }\n",
    "    \n",
    "def ridge_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'alpha': trial.suggest_float('alpha', 0.001, 10.0)\n",
    "    }\n",
    "    \n",
    "def lasso_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'alpha': trial.suggest_float('alpha', 0.001, 10.0)\n",
    "    }\n",
    "    \n",
    "def elastic_net_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'alpha': trial.suggest_float('alpha', 0.001, 10.0),\n",
    "        'l1_ratio': trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "    }\n",
    "\n",
    "def random_forest_space(trial: optuna.Trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 1.0),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['squared_error', 'absolute_error']),\n",
    "    }\n",
    "\n",
    "class AutoModel:\n",
    "    \"\"\"Structure to hold a model and its search space\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BaseEstimator\n",
    "        scikit-learn compatible regressor\n",
    "    config : callable \n",
    "        function that takes an optuna trial and produces a configuration\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BaseEstimator,\n",
    "        config: _TrialToConfig,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'AutoModel(model={_get_model_name(self.model)})'\n",
    "\n",
    "class AutoLightGBM(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from mlforecast.compat import LGBMRegressor\n",
    "        super().__init__(\n",
    "            LGBMRegressor(),\n",
    "            config if config is not None else lightgbm_space,\n",
    "        )\n",
    "\n",
    "class AutoXGBoost(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from mlforecast.compat import XGBRegressor\n",
    "        super().__init__(\n",
    "            XGBRegressor(),\n",
    "            config if config is not None else xgboost_space,\n",
    "        )\n",
    "\n",
    "class AutoCatboost(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from mlforecast.compat import CatBoostRegressor\n",
    "        super().__init__(\n",
    "            CatBoostRegressor(),\n",
    "            config if config is not None else catboost_space,\n",
    "        )\n",
    "\n",
    "class AutoLinearRegression(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        super().__init__(\n",
    "            LinearRegression(),\n",
    "            config if config is not None else linear_regression_space,\n",
    "        )\n",
    "\n",
    "class AutoRidge(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from sklearn.linear_model import Ridge\n",
    "        super().__init__(\n",
    "            Ridge(),\n",
    "            config if config is not None else ridge_space,\n",
    "        )\n",
    "\n",
    "class AutoLasso(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from sklearn.linear_model import Lasso\n",
    "        super().__init__(\n",
    "            Lasso(),\n",
    "            config if config is not None else lasso_space,\n",
    "        )\n",
    "\n",
    "class AutoElasticNet(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from sklearn.linear_model import ElasticNet\n",
    "        super().__init__(\n",
    "            ElasticNet(),\n",
    "            config if config is not None else elastic_net_space,\n",
    "        )\n",
    "\n",
    "class AutoRandomForest(AutoModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Optional[_TrialToConfig] = None,\n",
    "    ):\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        super().__init__(\n",
    "            RandomForestRegressor(),\n",
    "            config if config is not None else random_forest_space,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2819ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f3693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L114){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoModel\n",
       "\n",
       ">      AutoModel (model:sklearn.base.BaseEstimator,\n",
       ">                 config:Callable[[optuna.trial._trial.Trial],Dict[str,Any]])\n",
       "\n",
       "*Structure to hold a model and its search space*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| model | BaseEstimator | scikit-learn compatible regressor |\n",
       "| config | Callable | function that takes an optuna trial and produces a configuration |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L114){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoModel\n",
       "\n",
       ">      AutoModel (model:sklearn.base.BaseEstimator,\n",
       ">                 config:Callable[[optuna.trial._trial.Trial],Dict[str,Any]])\n",
       "\n",
       "*Structure to hold a model and its search space*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| model | BaseEstimator | scikit-learn compatible regressor |\n",
       "| config | Callable | function that takes an optuna trial and produces a configuration |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cb2d6-4507-4f21-9ea8-9c90ce63de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AutoMLForecast:\n",
    "    \"\"\"Hyperparameter optimization helper\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list or dict\n",
    "        Auto models to be optimized.\n",
    "    freq : str or int\n",
    "        pandas' or polars' offset alias or integer denoting the frequency of the series.\n",
    "    season_length : int, optional (default=None)\n",
    "        Length of the seasonal period. This is used for producing the feature space.\n",
    "        Only required if `init_config` is None.\n",
    "    init_config : callable, optional (default=None)\n",
    "        Function that takes an optuna trial and produces a configuration passed to the MLForecast constructor.\n",
    "    fit_config : callable, optional (default=None)\n",
    "        Function that takes an optuna trial and produces a configuration passed to the MLForecast fit method.\n",
    "    num_threads : int (default=1)\n",
    "        Number of threads to use when computing the features.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        models: Union[List[AutoModel], Dict[str, AutoModel]],\n",
    "        freq: Freq,\n",
    "        season_length: Optional[int] = None,\n",
    "        init_config: Optional[_TrialToConfig] = None,\n",
    "        fit_config: Optional[_TrialToConfig] = None,\n",
    "        num_threads: int = 1,\n",
    "    ):\n",
    "        self.freq = freq\n",
    "        if season_length is None and init_config is None:\n",
    "            raise ValueError(\n",
    "                '`season_length` is required when `init_config` is not provided.'\n",
    "            )\n",
    "        if init_config is not None and not callable(init_config):\n",
    "            raise ValueError('`init_config` must be a function.')\n",
    "        if season_length is not None and init_config is not None:\n",
    "            warnings.warn(\n",
    "                '`season_length` is not used when `init_config` is provided.'\n",
    "            )\n",
    "        self.init_config = init_config\n",
    "        self.season_length = season_length\n",
    "        if fit_config is not None:\n",
    "            if not callable(fit_config):\n",
    "                raise ValueError('`fit_config` must be a function.')\n",
    "            self.fit_config = fit_config\n",
    "        else:\n",
    "            self.fit_config = lambda trial: {}  # noqa: ARG005\n",
    "        self.num_threads = num_threads\n",
    "        if isinstance(models, list):\n",
    "            model_names = _name_models([_get_model_name(m) for m in models])\n",
    "            models_with_names = dict(zip(model_names, models))\n",
    "        else:\n",
    "            models_with_names = models\n",
    "        self.models = models_with_names\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'AutoMLForecast(models={self.models})'\n",
    "\n",
    "    def _seasonality_based_config(\n",
    "        self,\n",
    "        h: int,\n",
    "        min_samples: int,\n",
    "        min_value: float,\n",
    "    ) -> _TrialToConfig:\n",
    "        assert self.season_length is not None\n",
    "        # target transforms  \n",
    "        candidate_targ_tfms: List[Any] = [\n",
    "            None,\n",
    "            [LocalStandardScaler()],\n",
    "            [Differences([1]), LocalStandardScaler()],\n",
    "        ]\n",
    "        log1p_tfm = GlobalSklearnTransformer(\n",
    "            FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\n",
    "        )\n",
    "        if min_value >= 0:\n",
    "            candidate_targ_tfms.extend(\n",
    "                [\n",
    "                    [log1p_tfm, LocalStandardScaler()],\n",
    "                    [log1p_tfm, Differences([1]), LocalStandardScaler()],\n",
    "                ]\n",
    "            )\n",
    "        # we leave two seasonal periods for the features and model\n",
    "        if self.season_length > 1 and min_samples > 3 * self.season_length + 1:\n",
    "            candidate_targ_tfms.append([Differences([1, self.season_length]), LocalStandardScaler()])\n",
    "            if min_value >= 0:\n",
    "                candidate_targ_tfms.append(\n",
    "                    [log1p_tfm, Differences([1, self.season_length]), LocalStandardScaler()],\n",
    "                )\n",
    "\n",
    "        # lags\n",
    "        candidate_lags = [None, [self.season_length]]\n",
    "        seasonality2extra_candidate_lags = {\n",
    "            7: [\n",
    "                [7, 14],\n",
    "                [7, 28],\n",
    "            ],\n",
    "            12: [range(1, 13)],\n",
    "            24: [\n",
    "                range(1, 25),\n",
    "                range(24, 24 * 7 + 1, 24),\n",
    "            ],\n",
    "            52: [\n",
    "                range(4, 53, 4),\n",
    "            ]\n",
    "        }\n",
    "        if self.season_length in seasonality2extra_candidate_lags:\n",
    "            candidate_lags.extend(\n",
    "                seasonality2extra_candidate_lags[self.season_length]  # type: ignore\n",
    "            )\n",
    "        if h >= 2 * self.season_length:\n",
    "            candidate_lags.extend(\n",
    "                [\n",
    "                    range(self.season_length, h + 1, self.season_length),  # type: ignore\n",
    "                    [h],\n",
    "                    [self.season_length, h],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # lag transforms\n",
    "        candidate_lag_tfms = [None, {1: [ExponentiallyWeightedMean(0.9)]}]\n",
    "        if self.season_length > 1:\n",
    "            candidate_lag_tfms.append(\n",
    "                {\n",
    "                    1: [ExponentiallyWeightedMean(0.9)],\n",
    "                    self.season_length: [\n",
    "                        RollingMean(window_size=self.season_length, min_samples=1),\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        if self.season_length != h:\n",
    "            candidate_lag_tfms.append(\n",
    "                {\n",
    "                    1: [ExponentiallyWeightedMean(0.9)],\n",
    "                    self.season_length: [\n",
    "                        RollingMean(window_size=self.season_length, min_samples=1),\n",
    "                    ],\n",
    "                    h: [\n",
    "                        RollingMean(window_size=self.season_length, min_samples=1),\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # date features\n",
    "        seasonality2date_features = {\n",
    "            1: ['year'],\n",
    "            4: ['quarter', 'year'],\n",
    "            7: ['weekday', 'month', 'year'],\n",
    "            12: ['month', 'year'],\n",
    "            24: ['hour', 'weekday', 'month', 'year'],\n",
    "            52: ['week', 'year'],\n",
    "            60: ['weekday', 'hour', 'second'],\n",
    "        }\n",
    "        candidate_date_features = seasonality2date_features.get(self.season_length, [])\n",
    "        if isinstance(self.freq, int):\n",
    "            candidate_date_features = []\n",
    "\n",
    "        def config(trial):\n",
    "            # target transforms\n",
    "            targ_tfms_idx = trial.suggest_categorical(\n",
    "                'target_transforms_idx', range(len(candidate_targ_tfms))\n",
    "            )\n",
    "            target_transforms = candidate_targ_tfms[targ_tfms_idx]\n",
    "    \n",
    "            # lags\n",
    "            lags_idx = trial.suggest_categorical('lags_idx', range(len(candidate_lags)))\n",
    "            lags = candidate_lags[lags_idx]\n",
    "    \n",
    "            # lag transforms\n",
    "            if candidate_lag_tfms:\n",
    "                lag_tfms_idx = trial.suggest_categorical(\n",
    "                    'lag_transforms_idx', range(len(candidate_lag_tfms))\n",
    "                )\n",
    "                lag_transforms = candidate_lag_tfms[lag_tfms_idx]\n",
    "            else:\n",
    "                lag_transforms = None\n",
    "\n",
    "            # date features\n",
    "            if candidate_date_features:\n",
    "                use_date_features = trial.suggest_int('use_date_features', 0, 1)\n",
    "                if use_date_features:\n",
    "                    date_features = candidate_date_features\n",
    "                else:\n",
    "                    date_features = None        \n",
    "            else:\n",
    "                date_features = None\n",
    "            \n",
    "            return {\n",
    "                'lags': lags,\n",
    "                'target_transforms': target_transforms,\n",
    "                'lag_transforms': lag_transforms,\n",
    "                'date_features': date_features,            \n",
    "            }\n",
    "\n",
    "        return config\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        df: DataFrame,\n",
    "        n_windows: int,\n",
    "        h: int,\n",
    "        num_samples: int,\n",
    "        step_size: Optional[int] = None,\n",
    "        input_size: Optional[int] = None,\n",
    "        refit: Union[bool, int] = False,\n",
    "        loss: Optional[Callable[[DataFrame, DataFrame], float]] = None,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "        study_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        optimize_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        fitted: bool = False,\n",
    "        prediction_intervals: Optional[PredictionIntervals] = None,\n",
    "    ) -> 'AutoMLForecast':\n",
    "        \"\"\"Carry out the optimization process.\n",
    "        Each model is optimized independently and the best one is trained on all data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas or polars DataFrame\n",
    "            Series data in long format.\n",
    "        n_windows : int\n",
    "            Number of windows to evaluate.\n",
    "        h : int\n",
    "            Forecast horizon.\n",
    "        num_samples : int\n",
    "            Number of trials to run\n",
    "        step_size : int, optional (default=None)\n",
    "            Step size between each cross validation window. If None it will be equal to `h`.\n",
    "        input_size : int, optional (default=None)\n",
    "            Maximum training samples per serie in each window. If None, will use an expanding window.\n",
    "        refit : bool or int (default=False)\n",
    "            Retrain model for each cross validation window.\n",
    "            If False, the models are trained at the beginning and then used to predict each window.\n",
    "            If positive int, the models are retrained every `refit` windows.\n",
    "        loss : callable, optional (default=None)\n",
    "            Function that takes the validation and train dataframes and produces a float.\n",
    "            If `None` will use the average SMAPE across series.\n",
    "        id_col : str (default='unique_id')\n",
    "            Column that identifies each serie.\n",
    "        time_col : str (default='ds')\n",
    "            Column that identifies each timestep, its values can be timestamps or integers.\n",
    "        target_col : str (default='y')\n",
    "            Column that contains the target.        \n",
    "        study_kwargs : dict, optional (default=None)\n",
    "            Keyword arguments to be passed to the optuna.Study constructor.\n",
    "        optimize_kwargs : dict, optional (default=None)\n",
    "            Keyword arguments to be passed to the optuna.Study.optimize method.\n",
    "        fitted : bool (default=False)\n",
    "            Whether to compute the fitted values when retraining the best model.\n",
    "        prediction_intervals : \n",
    "            Configuration to calibrate prediction intervals when retraining the best model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        AutoMLForecast\n",
    "            object with best models and optimization results\n",
    "        \"\"\"\n",
    "        validate_freq(df[time_col], self.freq)\n",
    "        if self.init_config is not None:\n",
    "            init_config = self.init_config\n",
    "        else:\n",
    "            min_size = ufp.counts_by_id(df, id_col)['counts'].min()\n",
    "            min_train_size = min_size - n_windows * h\n",
    "            init_config = self._seasonality_based_config(\n",
    "                h=h,\n",
    "                min_samples=min_train_size,\n",
    "                min_value=df[target_col].min(),\n",
    "            )\n",
    "\n",
    "        if loss is None:\n",
    "            def loss(df, train_df):  # noqa: ARG001\n",
    "                return smape(\n",
    "                    df,\n",
    "                    models=['model'],\n",
    "                    id_col=id_col,\n",
    "                    target_col=target_col,\n",
    "                )['model'].mean()\n",
    "        if study_kwargs is None:\n",
    "            study_kwargs = {}\n",
    "        if 'sampler' not in study_kwargs:\n",
    "            # for reproducibility\n",
    "            study_kwargs['sampler'] = optuna.samplers.TPESampler(seed=0)\n",
    "        if optimize_kwargs is None:\n",
    "            optimize_kwargs = {}\n",
    "\n",
    "        self.results_ = {}\n",
    "        self.models_ = {}\n",
    "        for name, auto_model in self.models.items():\n",
    "            def config_fn(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "                return {\n",
    "                    'model_params': auto_model.config(trial),\n",
    "                    'mlf_init_params': {\n",
    "                        **init_config(trial),\n",
    "                        'num_threads': self.num_threads,\n",
    "                    },\n",
    "                    'mlf_fit_params': self.fit_config(trial)\n",
    "                }\n",
    "\n",
    "            objective = mlforecast_objective(\n",
    "                df=df,\n",
    "                config_fn=config_fn,\n",
    "                loss=loss,\n",
    "                model=auto_model.model,\n",
    "                freq=self.freq,\n",
    "                n_windows=n_windows,\n",
    "                h=h,\n",
    "                step_size=step_size,\n",
    "                input_size=input_size,\n",
    "                refit=refit,\n",
    "                id_col=id_col,\n",
    "                time_col=time_col,\n",
    "                target_col=target_col,\n",
    "            )\n",
    "            study = optuna.create_study(direction='minimize', **study_kwargs)\n",
    "            study.optimize(objective, n_trials=num_samples, **optimize_kwargs)\n",
    "            self.results_[name] = study\n",
    "            best_config = study.best_trial.user_attrs['config']\n",
    "            for arg in (\n",
    "                'fitted', 'prediction_intervals', 'id_col', 'time_col', 'target_col'\n",
    "            ):\n",
    "                best_config['mlf_fit_params'].pop(arg, None)\n",
    "            best_model = clone(auto_model.model)\n",
    "            best_model.set_params(**best_config['model_params'])\n",
    "            self.models_[name] = MLForecast(\n",
    "                models={name: best_model},\n",
    "                freq=self.freq,\n",
    "                **best_config['mlf_init_params']\n",
    "            )\n",
    "            self.models_[name].fit(\n",
    "                df,\n",
    "                fitted=fitted,\n",
    "                prediction_intervals=prediction_intervals,\n",
    "                id_col=id_col,\n",
    "                time_col=time_col,\n",
    "                target_col=target_col,\n",
    "                **best_config['mlf_fit_params'],\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        h: int,\n",
    "        X_df: Optional[DataFrame] = None,\n",
    "        level: Optional[List[Union[int, float]]] = None,\n",
    "    ) -> DataFrame:\n",
    "        \"\"\"\"Compute forecasts\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            Number of periods to predict.\n",
    "        X_df : pandas or polars DataFrame, optional (default=None)\n",
    "            Dataframe with the future exogenous features. Should have the id column and the time column.\n",
    "        level : list of ints or floats, optional (default=None)\n",
    "            Confidence levels between 0 and 100 for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas or polars DataFrame\n",
    "            Predictions for each serie and timestep, with one column per model.\n",
    "        \"\"\"\n",
    "        all_preds = None\n",
    "        for name, model in self.models_.items():\n",
    "            preds = model.predict(h=h, X_df=X_df, level=level)\n",
    "            if all_preds is None:\n",
    "                all_preds = preds\n",
    "            else:\n",
    "                model_cols = [c for c in preds.columns if c not in all_preds.columns]\n",
    "                all_preds = ufp.horizontal_concat([all_preds, preds[model_cols]])\n",
    "        return all_preds\n",
    "\n",
    "    def save(self, path: Union[str, Path]) -> None:\n",
    "        \"\"\"Save AutoMLForecast objects\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str or pathlib.Path\n",
    "            Directory where artifacts will be stored.\"\"\"\n",
    "        for name, model in self.models_.items():\n",
    "            model.save(f'{path}/{name}')\n",
    "\n",
    "    def forecast_fitted_values(\n",
    "        self,\n",
    "        level: Optional[List[Union[int, float]]] = None,\n",
    "    ) -> DataFrame:\n",
    "        \"\"\"Access in-sample predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        level : list of ints or floats, optional (default=None)\n",
    "            Confidence levels between 0 and 100 for prediction intervals.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas or polars DataFrame\n",
    "            Dataframe with predictions for the training set\n",
    "        \"\"\"\n",
    "        fitted_vals = None\n",
    "        for name, model in self.models_.items():\n",
    "            model_fitted = model.forecast_fitted_values(level=level)\n",
    "            if fitted_vals is None:\n",
    "                fitted_vals = model_fitted\n",
    "            else:\n",
    "                fitted_vals = ufp.join(\n",
    "                    fitted_vals,\n",
    "                    ufp.drop_columns(model_fitted, model.ts.target_col),\n",
    "                    on=[model.ts.id_col, model.ts.time_col],\n",
    "                    how='inner',\n",
    "                )\n",
    "        return fitted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e311237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L241){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast\n",
       "\n",
       ">      AutoMLForecast\n",
       ">                      (models:Union[List[__main__.AutoModel],Dict[str,__main__.\n",
       ">                      AutoModel]], freq:Union[int,str],\n",
       ">                      season_length:Optional[int]=None, init_config:Optional[Ca\n",
       ">                      llable[[optuna.trial._trial.Trial],Dict[str,Any]]]=None, \n",
       ">                      fit_config:Optional[Callable[[optuna.trial._trial.Trial],\n",
       ">                      Dict[str,Any]]]=None, num_threads:int=1)\n",
       "\n",
       "*Hyperparameter optimization helper*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| models | Union |  | Auto models to be optimized. |\n",
       "| freq | Union |  | pandas' or polars' offset alias or integer denoting the frequency of the series. |\n",
       "| season_length | Optional | None | Length of the seasonal period. This is used for producing the feature space.<br>Only required if `init_config` is None. |\n",
       "| init_config | Optional | None | Function that takes an optuna trial and produces a configuration passed to the MLForecast constructor. |\n",
       "| fit_config | Optional | None | Function that takes an optuna trial and produces a configuration passed to the MLForecast fit method. |\n",
       "| num_threads | int | 1 | Number of threads to use when computing the features. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L241){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast\n",
       "\n",
       ">      AutoMLForecast\n",
       ">                      (models:Union[List[__main__.AutoModel],Dict[str,__main__.\n",
       ">                      AutoModel]], freq:Union[int,str],\n",
       ">                      season_length:Optional[int]=None, init_config:Optional[Ca\n",
       ">                      llable[[optuna.trial._trial.Trial],Dict[str,Any]]]=None, \n",
       ">                      fit_config:Optional[Callable[[optuna.trial._trial.Trial],\n",
       ">                      Dict[str,Any]]]=None, num_threads:int=1)\n",
       "\n",
       "*Hyperparameter optimization helper*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| models | Union |  | Auto models to be optimized. |\n",
       "| freq | Union |  | pandas' or polars' offset alias or integer denoting the frequency of the series. |\n",
       "| season_length | Optional | None | Length of the seasonal period. This is used for producing the feature space.<br>Only required if `init_config` is None. |\n",
       "| init_config | Optional | None | Function that takes an optuna trial and produces a configuration passed to the MLForecast constructor. |\n",
       "| fit_config | Optional | None | Function that takes an optuna trial and produces a configuration passed to the MLForecast fit method. |\n",
       "| num_threads | int | 1 | Number of threads to use when computing the features. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoMLForecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff37fb-7697-4cc7-90ed-6091a9d48817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.fit\n",
       "\n",
       ">      AutoMLForecast.fit\n",
       ">                          (df:Union[pandas.core.frame.DataFrame,polars.datafram\n",
       ">                          e.frame.DataFrame], n_windows:int, h:int,\n",
       ">                          num_samples:int, step_size:Optional[int]=None,\n",
       ">                          input_size:Optional[int]=None,\n",
       ">                          refit:Union[bool,int]=False, loss:Optional[Callable[[\n",
       ">                          Union[pandas.core.frame.DataFrame,polars.dataframe.fr\n",
       ">                          ame.DataFrame],Union[pandas.core.frame.DataFrame,pola\n",
       ">                          rs.dataframe.frame.DataFrame]],float]]=None,\n",
       ">                          id_col:str='unique_id', time_col:str='ds',\n",
       ">                          target_col:str='y',\n",
       ">                          study_kwargs:Optional[Dict[str,Any]]=None,\n",
       ">                          optimize_kwargs:Optional[Dict[str,Any]]=None,\n",
       ">                          fitted:bool=False, prediction_intervals:Optional[mlfo\n",
       ">                          recast.utils.PredictionIntervals]=None)\n",
       "\n",
       "*Carry out the optimization process.\n",
       "Each model is optimized independently and the best one is trained on all data*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | Series data in long format. |\n",
       "| n_windows | int |  | Number of windows to evaluate. |\n",
       "| h | int |  | Forecast horizon. |\n",
       "| num_samples | int |  | Number of trials to run |\n",
       "| step_size | Optional | None | Step size between each cross validation window. If None it will be equal to `h`. |\n",
       "| input_size | Optional | None | Maximum training samples per serie in each window. If None, will use an expanding window. |\n",
       "| refit | Union | False | Retrain model for each cross validation window.<br>If False, the models are trained at the beginning and then used to predict each window.<br>If positive int, the models are retrained every `refit` windows. |\n",
       "| loss | Optional | None | Function that takes the validation and train dataframes and produces a float.<br>If `None` will use the average SMAPE across series. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target.         |\n",
       "| study_kwargs | Optional | None | Keyword arguments to be passed to the optuna.Study constructor. |\n",
       "| optimize_kwargs | Optional | None | Keyword arguments to be passed to the optuna.Study.optimize method. |\n",
       "| fitted | bool | False | Whether to compute the fitted values when retraining the best model. |\n",
       "| prediction_intervals | Optional | None | Configuration to calibrate prediction intervals when retraining the best model. |\n",
       "| **Returns** | **AutoMLForecast** |  | **object with best models and optimization results** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.fit\n",
       "\n",
       ">      AutoMLForecast.fit\n",
       ">                          (df:Union[pandas.core.frame.DataFrame,polars.datafram\n",
       ">                          e.frame.DataFrame], n_windows:int, h:int,\n",
       ">                          num_samples:int, step_size:Optional[int]=None,\n",
       ">                          input_size:Optional[int]=None,\n",
       ">                          refit:Union[bool,int]=False, loss:Optional[Callable[[\n",
       ">                          Union[pandas.core.frame.DataFrame,polars.dataframe.fr\n",
       ">                          ame.DataFrame],Union[pandas.core.frame.DataFrame,pola\n",
       ">                          rs.dataframe.frame.DataFrame]],float]]=None,\n",
       ">                          id_col:str='unique_id', time_col:str='ds',\n",
       ">                          target_col:str='y',\n",
       ">                          study_kwargs:Optional[Dict[str,Any]]=None,\n",
       ">                          optimize_kwargs:Optional[Dict[str,Any]]=None,\n",
       ">                          fitted:bool=False, prediction_intervals:Optional[mlfo\n",
       ">                          recast.utils.PredictionIntervals]=None)\n",
       "\n",
       "*Carry out the optimization process.\n",
       "Each model is optimized independently and the best one is trained on all data*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | Series data in long format. |\n",
       "| n_windows | int |  | Number of windows to evaluate. |\n",
       "| h | int |  | Forecast horizon. |\n",
       "| num_samples | int |  | Number of trials to run |\n",
       "| step_size | Optional | None | Step size between each cross validation window. If None it will be equal to `h`. |\n",
       "| input_size | Optional | None | Maximum training samples per serie in each window. If None, will use an expanding window. |\n",
       "| refit | Union | False | Retrain model for each cross validation window.<br>If False, the models are trained at the beginning and then used to predict each window.<br>If positive int, the models are retrained every `refit` windows. |\n",
       "| loss | Optional | None | Function that takes the validation and train dataframes and produces a float.<br>If `None` will use the average SMAPE across series. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target.         |\n",
       "| study_kwargs | Optional | None | Keyword arguments to be passed to the optuna.Study constructor. |\n",
       "| optimize_kwargs | Optional | None | Keyword arguments to be passed to the optuna.Study.optimize method. |\n",
       "| fitted | bool | False | Whether to compute the fitted values when retraining the best model. |\n",
       "| prediction_intervals | Optional | None | Configuration to calibrate prediction intervals when retraining the best model. |\n",
       "| **Returns** | **AutoMLForecast** |  | **object with best models and optimization results** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoMLForecast.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f8ce3-021d-43bc-bef0-1ae057e6bde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L592){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.predict\n",
       "\n",
       ">      AutoMLForecast.predict (h:int, X_df:Union[pandas.core.frame.DataFrame,pol\n",
       ">                              ars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                              level:Optional[List[Union[int,float]]]=None)\n",
       "\n",
       "*\"Compute forecasts*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| h | int |  | Number of periods to predict. |\n",
       "| X_df | Union | None | Dataframe with the future exogenous features. Should have the id column and the time column. |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| **Returns** | **Union** |  | **Predictions for each serie and timestep, with one column per model.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L592){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.predict\n",
       "\n",
       ">      AutoMLForecast.predict (h:int, X_df:Union[pandas.core.frame.DataFrame,pol\n",
       ">                              ars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                              level:Optional[List[Union[int,float]]]=None)\n",
       "\n",
       "*\"Compute forecasts*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| h | int |  | Number of periods to predict. |\n",
       "| X_df | Union | None | Dataframe with the future exogenous features. Should have the id column and the time column. |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| **Returns** | **Union** |  | **Predictions for each serie and timestep, with one column per model.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoMLForecast.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2283bcc-38f6-4631-853c-e3c6e520e02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L624){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.save\n",
       "\n",
       ">      AutoMLForecast.save (path:Union[str,pathlib.Path])\n",
       "\n",
       "*Save AutoMLForecast objects*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | Union | Directory where artifacts will be stored. |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L624){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.save\n",
       "\n",
       ">      AutoMLForecast.save (path:Union[str,pathlib.Path])\n",
       "\n",
       "*Save AutoMLForecast objects*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | Union | Directory where artifacts will be stored. |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoMLForecast.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9ac56-7e1f-43aa-86e4-bc4765430254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L634){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.forecast_fitted_values\n",
       "\n",
       ">      AutoMLForecast.forecast_fitted_values\n",
       ">                                             (level:Optional[List[Union[int,flo\n",
       ">                                             at]]]=None)\n",
       "\n",
       "*Access in-sample predictions.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| **Returns** | **Union** |  | **Dataframe with predictions for the training set** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/mlforecast/blob/main/mlforecast/auto.py#L634){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AutoMLForecast.forecast_fitted_values\n",
       "\n",
       ">      AutoMLForecast.forecast_fitted_values\n",
       ">                                             (level:Optional[List[Union[int,flo\n",
       ">                                             at]]]=None)\n",
       "\n",
       "*Access in-sample predictions.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| level | Optional | None | Confidence levels between 0 and 100 for prediction intervals. |\n",
       "| **Returns** | **Union** |  | **Dataframe with predictions for the training set** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AutoMLForecast.forecast_fitted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa7b02-4b05-4027-87d3-1e0a9e3d5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from datasetsforecast.m4 import M4, M4Evaluation, M4Info\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de63a9-11e7-4fe0-ae8d-a3e91a7a5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(group):\n",
    "    df, *_ = M4.load(directory='data', group=group)\n",
    "    df['ds'] = df['ds'].astype('int')\n",
    "    horizon = M4Info[group].horizon\n",
    "    valid = df.groupby('unique_id').tail(horizon).copy()\n",
    "    train = df.drop(valid.index).reset_index(drop=True)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        [('encoder', OneHotEncoder(), ['unique_id'])],\n",
    "        remainder='passthrough',\n",
    "    ),\n",
    "    Ridge()\n",
    ")\n",
    "auto_ridge = AutoModel(ridge_pipeline, lambda trial: {f'ridge__{k}': v for k, v in ridge_space(trial).items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2aa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>lgb</th>\n",
       "      <th>lgb-lo-80</th>\n",
       "      <th>lgb-hi-80</th>\n",
       "      <th>ridge</th>\n",
       "      <th>ridge-lo-80</th>\n",
       "      <th>ridge-hi-80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1</td>\n",
       "      <td>2180</td>\n",
       "      <td>35529.435224</td>\n",
       "      <td>35061.835362</td>\n",
       "      <td>35997.035086</td>\n",
       "      <td>36110.921202</td>\n",
       "      <td>35880.445097</td>\n",
       "      <td>36341.397307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W1</td>\n",
       "      <td>2181</td>\n",
       "      <td>35521.764894</td>\n",
       "      <td>34973.035617</td>\n",
       "      <td>36070.494171</td>\n",
       "      <td>36195.175757</td>\n",
       "      <td>36051.013811</td>\n",
       "      <td>36339.337702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1</td>\n",
       "      <td>2182</td>\n",
       "      <td>35537.417268</td>\n",
       "      <td>34960.050939</td>\n",
       "      <td>36114.783596</td>\n",
       "      <td>36107.528852</td>\n",
       "      <td>35784.062169</td>\n",
       "      <td>36430.995536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W1</td>\n",
       "      <td>2183</td>\n",
       "      <td>35538.058206</td>\n",
       "      <td>34823.640706</td>\n",
       "      <td>36252.475705</td>\n",
       "      <td>36027.139248</td>\n",
       "      <td>35612.635725</td>\n",
       "      <td>36441.642771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1</td>\n",
       "      <td>2184</td>\n",
       "      <td>35614.611211</td>\n",
       "      <td>34627.023739</td>\n",
       "      <td>36602.198683</td>\n",
       "      <td>36092.858489</td>\n",
       "      <td>35389.690977</td>\n",
       "      <td>36796.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>W99</td>\n",
       "      <td>2292</td>\n",
       "      <td>15071.536978</td>\n",
       "      <td>14484.617399</td>\n",
       "      <td>15658.456557</td>\n",
       "      <td>15319.146221</td>\n",
       "      <td>14869.410567</td>\n",
       "      <td>15768.881875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>W99</td>\n",
       "      <td>2293</td>\n",
       "      <td>15058.145278</td>\n",
       "      <td>14229.686322</td>\n",
       "      <td>15886.604234</td>\n",
       "      <td>15299.549555</td>\n",
       "      <td>14584.269352</td>\n",
       "      <td>16014.829758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>W99</td>\n",
       "      <td>2294</td>\n",
       "      <td>15042.493434</td>\n",
       "      <td>14096.380636</td>\n",
       "      <td>15988.606232</td>\n",
       "      <td>15271.744712</td>\n",
       "      <td>14365.349338</td>\n",
       "      <td>16178.140086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>W99</td>\n",
       "      <td>2295</td>\n",
       "      <td>15042.144846</td>\n",
       "      <td>14037.053904</td>\n",
       "      <td>16047.235787</td>\n",
       "      <td>15250.070504</td>\n",
       "      <td>14403.428791</td>\n",
       "      <td>16096.712216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>W99</td>\n",
       "      <td>2296</td>\n",
       "      <td>15038.729044</td>\n",
       "      <td>13944.821480</td>\n",
       "      <td>16132.636609</td>\n",
       "      <td>15232.127800</td>\n",
       "      <td>14325.059776</td>\n",
       "      <td>16139.195824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4667 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id    ds           lgb     lgb-lo-80     lgb-hi-80         ridge  \\\n",
       "0           W1  2180  35529.435224  35061.835362  35997.035086  36110.921202   \n",
       "1           W1  2181  35521.764894  34973.035617  36070.494171  36195.175757   \n",
       "2           W1  2182  35537.417268  34960.050939  36114.783596  36107.528852   \n",
       "3           W1  2183  35538.058206  34823.640706  36252.475705  36027.139248   \n",
       "4           W1  2184  35614.611211  34627.023739  36602.198683  36092.858489   \n",
       "...        ...   ...           ...           ...           ...           ...   \n",
       "4662       W99  2292  15071.536978  14484.617399  15658.456557  15319.146221   \n",
       "4663       W99  2293  15058.145278  14229.686322  15886.604234  15299.549555   \n",
       "4664       W99  2294  15042.493434  14096.380636  15988.606232  15271.744712   \n",
       "4665       W99  2295  15042.144846  14037.053904  16047.235787  15250.070504   \n",
       "4666       W99  2296  15038.729044  13944.821480  16132.636609  15232.127800   \n",
       "\n",
       "       ridge-lo-80   ridge-hi-80  \n",
       "0     35880.445097  36341.397307  \n",
       "1     36051.013811  36339.337702  \n",
       "2     35784.062169  36430.995536  \n",
       "3     35612.635725  36441.642771  \n",
       "4     35389.690977  36796.026000  \n",
       "...            ...           ...  \n",
       "4662  14869.410567  15768.881875  \n",
       "4663  14584.269352  16014.829758  \n",
       "4664  14365.349338  16178.140086  \n",
       "4665  14403.428791  16096.712216  \n",
       "4666  14325.059776  16139.195824  \n",
       "\n",
       "[4667 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "group = 'Weekly'\n",
    "train, valid = train_valid_split(group)\n",
    "train['unique_id'] = train['unique_id'].astype('category')\n",
    "valid['unique_id'] = valid['unique_id'].astype(train['unique_id'].dtype)\n",
    "info = M4Info[group]\n",
    "h = info.horizon\n",
    "season_length = info.seasonality\n",
    "auto_mlf = AutoMLForecast(\n",
    "    freq=1,\n",
    "    season_length=season_length,\n",
    "    models={\n",
    "        'lgb': AutoLightGBM(),\n",
    "        'ridge': auto_ridge,\n",
    "    },\n",
    "    fit_config=lambda trial: {'static_features': ['unique_id']},\n",
    "    num_threads=2,\n",
    ")\n",
    "auto_mlf.fit(\n",
    "    df=train,\n",
    "    n_windows=2,\n",
    "    h=h,\n",
    "    num_samples=2,\n",
    "    optimize_kwargs={'timeout': 60},\n",
    "    fitted=True,\n",
    "    prediction_intervals=PredictionIntervals(n_windows=2, h=h),\n",
    ")\n",
    "auto_mlf.predict(h, level=[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df947f3e-af97-4bd4-83e1-b864f04f9c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>lgb</th>\n",
       "      <th>lgb-lo-95</th>\n",
       "      <th>lgb-hi-95</th>\n",
       "      <th>ridge</th>\n",
       "      <th>ridge-lo-95</th>\n",
       "      <th>ridge-hi-95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1</td>\n",
       "      <td>15</td>\n",
       "      <td>1071.06</td>\n",
       "      <td>1060.584344</td>\n",
       "      <td>599.618355</td>\n",
       "      <td>1521.550334</td>\n",
       "      <td>1076.990151</td>\n",
       "      <td>556.535492</td>\n",
       "      <td>1597.444810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W1</td>\n",
       "      <td>16</td>\n",
       "      <td>1073.73</td>\n",
       "      <td>1072.669242</td>\n",
       "      <td>611.703252</td>\n",
       "      <td>1533.635232</td>\n",
       "      <td>1083.633276</td>\n",
       "      <td>563.178617</td>\n",
       "      <td>1604.087936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1</td>\n",
       "      <td>17</td>\n",
       "      <td>1066.97</td>\n",
       "      <td>1072.452128</td>\n",
       "      <td>611.486139</td>\n",
       "      <td>1533.418118</td>\n",
       "      <td>1084.724311</td>\n",
       "      <td>564.269652</td>\n",
       "      <td>1605.178970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W1</td>\n",
       "      <td>18</td>\n",
       "      <td>1066.17</td>\n",
       "      <td>1065.837828</td>\n",
       "      <td>604.871838</td>\n",
       "      <td>1526.803818</td>\n",
       "      <td>1080.127197</td>\n",
       "      <td>559.672538</td>\n",
       "      <td>1600.581856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1</td>\n",
       "      <td>19</td>\n",
       "      <td>1064.43</td>\n",
       "      <td>1065.214681</td>\n",
       "      <td>604.248691</td>\n",
       "      <td>1526.180671</td>\n",
       "      <td>1080.636826</td>\n",
       "      <td>560.182167</td>\n",
       "      <td>1601.091485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361881</th>\n",
       "      <td>W99</td>\n",
       "      <td>2279</td>\n",
       "      <td>15738.54</td>\n",
       "      <td>15887.661228</td>\n",
       "      <td>15721.237195</td>\n",
       "      <td>16054.085261</td>\n",
       "      <td>15927.918181</td>\n",
       "      <td>15723.222760</td>\n",
       "      <td>16132.613603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361882</th>\n",
       "      <td>W99</td>\n",
       "      <td>2280</td>\n",
       "      <td>15388.13</td>\n",
       "      <td>15755.943789</td>\n",
       "      <td>15589.519756</td>\n",
       "      <td>15922.367823</td>\n",
       "      <td>15841.599064</td>\n",
       "      <td>15636.903642</td>\n",
       "      <td>16046.294485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361883</th>\n",
       "      <td>W99</td>\n",
       "      <td>2281</td>\n",
       "      <td>15187.62</td>\n",
       "      <td>15432.224701</td>\n",
       "      <td>15265.800668</td>\n",
       "      <td>15598.648735</td>\n",
       "      <td>15584.462232</td>\n",
       "      <td>15379.766811</td>\n",
       "      <td>15789.157654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361884</th>\n",
       "      <td>W99</td>\n",
       "      <td>2282</td>\n",
       "      <td>15172.27</td>\n",
       "      <td>15177.040831</td>\n",
       "      <td>15010.616797</td>\n",
       "      <td>15343.464864</td>\n",
       "      <td>15396.243223</td>\n",
       "      <td>15191.547801</td>\n",
       "      <td>15600.938644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361885</th>\n",
       "      <td>W99</td>\n",
       "      <td>2283</td>\n",
       "      <td>15101.03</td>\n",
       "      <td>15162.090803</td>\n",
       "      <td>14995.666770</td>\n",
       "      <td>15328.514836</td>\n",
       "      <td>15335.982465</td>\n",
       "      <td>15131.287044</td>\n",
       "      <td>15540.677887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361886 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id    ds         y           lgb     lgb-lo-95     lgb-hi-95  \\\n",
       "0             W1    15   1071.06   1060.584344    599.618355   1521.550334   \n",
       "1             W1    16   1073.73   1072.669242    611.703252   1533.635232   \n",
       "2             W1    17   1066.97   1072.452128    611.486139   1533.418118   \n",
       "3             W1    18   1066.17   1065.837828    604.871838   1526.803818   \n",
       "4             W1    19   1064.43   1065.214681    604.248691   1526.180671   \n",
       "...          ...   ...       ...           ...           ...           ...   \n",
       "361881       W99  2279  15738.54  15887.661228  15721.237195  16054.085261   \n",
       "361882       W99  2280  15388.13  15755.943789  15589.519756  15922.367823   \n",
       "361883       W99  2281  15187.62  15432.224701  15265.800668  15598.648735   \n",
       "361884       W99  2282  15172.27  15177.040831  15010.616797  15343.464864   \n",
       "361885       W99  2283  15101.03  15162.090803  14995.666770  15328.514836   \n",
       "\n",
       "               ridge   ridge-lo-95   ridge-hi-95  \n",
       "0        1076.990151    556.535492   1597.444810  \n",
       "1        1083.633276    563.178617   1604.087936  \n",
       "2        1084.724311    564.269652   1605.178970  \n",
       "3        1080.127197    559.672538   1600.581856  \n",
       "4        1080.636826    560.182167   1601.091485  \n",
       "...              ...           ...           ...  \n",
       "361881  15927.918181  15723.222760  16132.613603  \n",
       "361882  15841.599064  15636.903642  16046.294485  \n",
       "361883  15584.462232  15379.766811  15789.157654  \n",
       "361884  15396.243223  15191.547801  15600.938644  \n",
       "361885  15335.982465  15131.287044  15540.677887  \n",
       "\n",
       "[361886 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mlf.forecast_fitted_values(level=[95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191b2e9-3bdc-4cb4-8507-972aea171098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_fail, test_warns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa9a09-ebb7-4545-8661-390ce4f3e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test season_length\n",
    "test_fail(\n",
    "    lambda: AutoMLForecast(\n",
    "        freq=1,\n",
    "        season_length=None,\n",
    "        init_config=None,\n",
    "        models=[AutoLightGBM()],\n",
    "    ),\n",
    "    contains='`season_length` is required'\n",
    ")\n",
    "test_warns(\n",
    "    lambda: AutoMLForecast(\n",
    "        freq=1,\n",
    "        season_length=1,\n",
    "        init_config=lambda: {},\n",
    "        models=[AutoLightGBM()],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8179b53-02a0-4c46-b325-6c19a39c9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ef02b-d88d-4e6f-a770-ddcf38dadb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_667, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>unique_id</th><th>ds</th><th>ridge</th><th>ridge-lo-80</th><th>ridge-hi-80</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;W1&quot;</td><td>2180</td><td>35046.096663</td><td>34046.69521</td><td>36045.498116</td></tr><tr><td>&quot;W1&quot;</td><td>2181</td><td>34743.269216</td><td>33325.847975</td><td>36160.690457</td></tr><tr><td>&quot;W1&quot;</td><td>2182</td><td>34489.591086</td><td>32591.254559</td><td>36387.927614</td></tr><tr><td>&quot;W1&quot;</td><td>2183</td><td>34270.768179</td><td>32076.507727</td><td>36465.02863</td></tr><tr><td>&quot;W1&quot;</td><td>2184</td><td>34124.021857</td><td>31352.454121</td><td>36895.589593</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;W99&quot;</td><td>2292</td><td>14719.457096</td><td>13983.308582</td><td>15455.605609</td></tr><tr><td>&quot;W99&quot;</td><td>2293</td><td>14631.552077</td><td>13928.874336</td><td>15334.229818</td></tr><tr><td>&quot;W99&quot;</td><td>2294</td><td>14532.905239</td><td>13642.840118</td><td>15422.97036</td></tr><tr><td>&quot;W99&quot;</td><td>2295</td><td>14446.065443</td><td>13665.088667</td><td>15227.04222</td></tr><tr><td>&quot;W99&quot;</td><td>2296</td><td>14363.049604</td><td>13654.220051</td><td>15071.879157</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_667, 5)\n",
       "\n",
       " unique_id  ds    ridge         ridge-lo-80   ridge-hi-80  \n",
       " ---        ---   ---           ---           ---          \n",
       " str        i64   f64           f64           f64          \n",
       "\n",
       " W1         2180  35046.096663  34046.69521   36045.498116 \n",
       " W1         2181  34743.269216  33325.847975  36160.690457 \n",
       " W1         2182  34489.591086  32591.254559  36387.927614 \n",
       " W1         2183  34270.768179  32076.507727  36465.02863  \n",
       " W1         2184  34124.021857  31352.454121  36895.589593 \n",
       "                                                      \n",
       " W99        2292  14719.457096  13983.308582  15455.605609 \n",
       " W99        2293  14631.552077  13928.874336  15334.229818 \n",
       " W99        2294  14532.905239  13642.840118  15422.97036  \n",
       " W99        2295  14446.065443  13665.088667  15227.04222  \n",
       " W99        2296  14363.049604  13654.220051  15071.879157 \n",
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| polars\n",
    "train_pl = pl.from_pandas(train.astype({'unique_id': 'str'}))\n",
    "auto_mlf = AutoMLForecast(\n",
    "    freq=1,\n",
    "    season_length=season_length,\n",
    "    models={'ridge': AutoRidge()},\n",
    "    num_threads=2,\n",
    ")\n",
    "auto_mlf.fit(\n",
    "    df=train_pl,\n",
    "    n_windows=2,\n",
    "    h=h,\n",
    "    num_samples=2,\n",
    "    optimize_kwargs={'timeout': 60},\n",
    "    fitted=True,\n",
    "    prediction_intervals=PredictionIntervals(n_windows=2, h=h),\n",
    ")\n",
    "auto_mlf.predict(h, level=[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487ff11-100e-49c6-9a71-763bba147c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (362_245, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>unique_id</th><th>ds</th><th>y</th><th>ridge</th><th>ridge-lo-95</th><th>ridge-hi-95</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;W1&quot;</td><td>14</td><td>1061.96</td><td>1249.326428</td><td>488.765249</td><td>2009.887607</td></tr><tr><td>&quot;W1&quot;</td><td>15</td><td>1071.06</td><td>1246.067836</td><td>485.506657</td><td>2006.629015</td></tr><tr><td>&quot;W1&quot;</td><td>16</td><td>1073.73</td><td>1254.027897</td><td>493.466718</td><td>2014.589076</td></tr><tr><td>&quot;W1&quot;</td><td>17</td><td>1066.97</td><td>1254.475948</td><td>493.914769</td><td>2015.037126</td></tr><tr><td>&quot;W1&quot;</td><td>18</td><td>1066.17</td><td>1248.306754</td><td>487.745575</td><td>2008.867933</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;W99&quot;</td><td>2279</td><td>15738.54</td><td>15754.558812</td><td>15411.968645</td><td>16097.148979</td></tr><tr><td>&quot;W99&quot;</td><td>2280</td><td>15388.13</td><td>15655.780865</td><td>15313.190698</td><td>15998.371032</td></tr><tr><td>&quot;W99&quot;</td><td>2281</td><td>15187.62</td><td>15367.498468</td><td>15024.908301</td><td>15710.088635</td></tr><tr><td>&quot;W99&quot;</td><td>2282</td><td>15172.27</td><td>15172.591423</td><td>14830.001256</td><td>15515.18159</td></tr><tr><td>&quot;W99&quot;</td><td>2283</td><td>15101.03</td><td>15141.032886</td><td>14798.44272</td><td>15483.623053</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (362_245, 6)\n",
       "\n",
       " unique_id  ds    y         ridge         ridge-lo-95   ridge-hi-95  \n",
       " ---        ---   ---       ---           ---           ---          \n",
       " str        i64   f64       f64           f64           f64          \n",
       "\n",
       " W1         14    1061.96   1249.326428   488.765249    2009.887607  \n",
       " W1         15    1071.06   1246.067836   485.506657    2006.629015  \n",
       " W1         16    1073.73   1254.027897   493.466718    2014.589076  \n",
       " W1         17    1066.97   1254.475948   493.914769    2015.037126  \n",
       " W1         18    1066.17   1248.306754   487.745575    2008.867933  \n",
       "                                                               \n",
       " W99        2279  15738.54  15754.558812  15411.968645  16097.148979 \n",
       " W99        2280  15388.13  15655.780865  15313.190698  15998.371032 \n",
       " W99        2281  15187.62  15367.498468  15024.908301  15710.088635 \n",
       " W99        2282  15172.27  15172.591423  14830.001256  15515.18159  \n",
       " W99        2283  15101.03  15141.032886  14798.44272   15483.623053 \n",
       ""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| polars\n",
    "auto_mlf.forecast_fitted_values(level=[95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe2c18-d3df-41f2-a3b8-1cf73ef9765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "auto_mlf2 = AutoMLForecast(\n",
    "    freq=1,\n",
    "    season_length=season_length,\n",
    "    models={'ridge': AutoRidge()},\n",
    "    num_threads=2,\n",
    ")\n",
    "auto_mlf2.fit(\n",
    "    df=train_pl,\n",
    "    n_windows=2,\n",
    "    h=h,\n",
    "    step_size=1,\n",
    "    num_samples=2,\n",
    "    optimize_kwargs={'timeout': 60},\n",
    "    fitted=True,\n",
    "    prediction_intervals=PredictionIntervals(n_windows=2, h=h),\n",
    ")\n",
    "metric_step_h = auto_mlf.results_['ridge'].best_trial.value\n",
    "metric_step_1 = auto_mlf2.results_['ridge'].best_trial.value\n",
    "assert abs(metric_step_h / metric_step_1 - 1) > 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c00fd0-ebee-4d40-b2aa-dc7ae98ee94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# default loss with non standard names\n",
    "auto_mlf = AutoMLForecast(\n",
    "    freq=1,\n",
    "    season_length=season_length,\n",
    "    models={'ridge': AutoRidge()},\n",
    ")\n",
    "fit_kwargs = dict(\n",
    "    n_windows=2,\n",
    "    h=h,\n",
    "    step_size=1,\n",
    "    num_samples=2,\n",
    "    optimize_kwargs={'timeout': 60},    \n",
    ")\n",
    "preds = auto_mlf.fit(df=train, **fit_kwargs).predict(5)\n",
    "\n",
    "train2 = train.rename(columns={'unique_id': 'id', 'ds': 'time', 'y': 'target'})\n",
    "preds2 = auto_mlf.fit(\n",
    "    df=train2,\n",
    "    id_col='id',\n",
    "    time_col='time',\n",
    "    target_col='target',\n",
    "    **fit_kwargs,\n",
    ").predict(5)\n",
    "pd.testing.assert_frame_equal(\n",
    "    preds,\n",
    "    preds2.rename(columns={'id': 'unique_id', 'time': 'ds'}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf14191-370e-41b9-a322-2c9b0a7a5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# using input_size\n",
    "fit_kwargs = dict(\n",
    "    n_windows=3,\n",
    "    h=h,\n",
    "    num_samples=5,\n",
    "    optimize_kwargs={'timeout': 60},    \n",
    ")\n",
    "\n",
    "start = time.perf_counter()\n",
    "auto_mlf.fit(df=train, **fit_kwargs)\n",
    "no_limit = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "auto_mlf.fit(df=train, input_size=50, **fit_kwargs)\n",
    "with_limit = time.perf_counter() - start\n",
    "\n",
    "assert with_limit < no_limit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
