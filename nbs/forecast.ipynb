{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa33fa-816f-463f-9215-9559b0ddd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20376798-3d26-4c74-9e52-d5b657b7768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccedaf1-56c9-4aaf-af7b-fe049df299ad",
   "metadata": {},
   "source": [
    "# Forecast\n",
    "\n",
    "> Full pipeline encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b089a52-e06d-49b1-9328-793cffe56045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import RegressorMixin, clone\n",
    "\n",
    "from mlforecast.core import TimeSeries\n",
    "from mlforecast.utils import backtest_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07073d89-e33c-41d6-9bd3-a6daa07fef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import warnings\n",
    "\n",
    "from nbdev import show_doc\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "set_config(display='text')\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823ab21-fabd-40aa-81fc-c8be0e7b12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Forecast:\n",
    "    \"\"\"Full pipeline encapsulation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        models: Union[RegressorMixin, List[RegressorMixin]],  # model or list of models that follow the scikit-learn API\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[Union[str, Callable]] = [],  # list of names of pandas date attributes or functions to use as features, e.g. dayofweek\n",
    "        differences: Optional[List[int]] = None,  # differences to apply to the series before fitting\n",
    "        num_threads: int = 1,  # number of threads to use when computing lag features\n",
    "    ):\n",
    "        if not isinstance(models, list):\n",
    "            models = [clone(models)]\n",
    "        self.models = [clone(m) for m in models]\n",
    "        self.ts = TimeSeries(freq, lags, lag_transforms, date_features, differences, num_threads)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f'Forecast(models=[{\", \".join(m.__class__.__name__ for m in self.models)}], '\n",
    "            f'freq={self.freq}, '\n",
    "            f'lag_features={list(self.ts.transforms.keys())}, '\n",
    "            f'date_features={self.ts.date_features}, '\n",
    "            f'num_threads={self.ts.num_threads})'\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def freq(self):\n",
    "        return self.ts.freq\n",
    "\n",
    "    def preprocess(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # dataframe with the series' data\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates    \n",
    "    ) -> pd.DataFrame:\n",
    "        return self.ts.fit_transform(data, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # dataframe with the series' data\n",
    "        id_col: str = 'index',  # column that identifies each serie. If 'index', the index is taken as the identifier of each serie\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "    ) -> 'Forecast':\n",
    "        \"\"\"Preprocesses `data` and fits `models` using it.\"\"\"\n",
    "        series_df = self.preprocess(data, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "        X, y = series_df.drop(columns=[time_col, target_col]), series_df[target_col].values\n",
    "        del series_df\n",
    "        self.models_ = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            self.models_.append(clone(model).fit(X, y))\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Compute the predictions for the next `horizon` steps.\n",
    "        \n",
    "        `predict_fn(model, new_x, dynamic_dfs, features_order, **predict_fn_kwargs)` is called in every timestep, where:\n",
    "        `model` is the trained model.\n",
    "        `new_x` is a dataframe with the same format as the input plus the computed features.\n",
    "        `dynamic_dfs` is a list containing the dynamic dataframes.\n",
    "        `features_order` is the list of column names that were used in the training step.\n",
    "        \"\"\"\n",
    "        return self.ts.predict(\n",
    "            self.models_, horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs\n",
    "        )\n",
    "\n",
    "    def cross_validation(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates        \n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ):\n",
    "        \"\"\"Creates `n_windows` splits of `window_size` from `data`, trains the model\n",
    "        on the training set, predicts the window and merges the actuals and the predictions\n",
    "        in a dataframe.\n",
    "\n",
    "        Returns a dataframe containing the datestamps, actual values, train ends and predictions.\"\"\"\n",
    "        results = []\n",
    "        self.cv_models_ = []\n",
    "        if id_col != 'index':\n",
    "            data = data.set_index(id_col)\n",
    "        \n",
    "        if np.issubdtype(data[time_col].dtype.type, np.integer):\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = self.freq\n",
    "\n",
    "        for train_end, train, valid in backtest_splits(data, n_windows, window_size, freq, time_col, target_col):\n",
    "            self.fit(train, 'index', time_col, target_col, static_features, dropna, keep_last_n)\n",
    "            self.cv_models_.append(self.models_)\n",
    "            y_pred = self.predict(\n",
    "                window_size, dynamic_dfs, predict_fn, **predict_fn_kwargs\n",
    "            )\n",
    "            y_pred = y_pred.set_index(time_col, append=True)\n",
    "            result = valid.set_index(time_col, append=True)[[target_col]].copy()\n",
    "            result = result.join(y_pred).reset_index(time_col)\n",
    "            result['cutoff'] = train_end            \n",
    "            results.append(result)\n",
    "\n",
    "        out = pd.concat(results)\n",
    "        out = out[[time_col, 'cutoff', target_col, *y_pred.columns]]\n",
    "        if id_col != 'index':\n",
    "            out = out.reset_index()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7c92c-2ba9-4885-bbc1-8e4a4f67f0d9",
   "metadata": {},
   "source": [
    "The `Forecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing the predictions). It tries to mimic the scikit-learn API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ec811-8876-4daa-84a2-2ebe0559a02b",
   "metadata": {},
   "source": [
    "## Example\n",
    "This shows an example with simulated data, for a real world example you can check the [M5 example](https://www.kaggle.com/lemuz90/m5-mlforecast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3032775-f610-4091-a750-73219d904c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb46457-6c08-420c-9a2e-ab0ae54dd41c",
   "metadata": {},
   "source": [
    "In order to forecast some time series you need a dataframe with at least three columns:\n",
    "\n",
    "* `id_col`: contains the identifier for each time serie (can also be the index).\n",
    "* `time_col`: contains the timestamps.\n",
    "* `target_col`: contains the series values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938e585-461e-464e-9a4b-4299a59f5272",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c776bb-b87b-4c01-a67a-ff95a055b5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>3.981198</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-06</td>\n",
       "      <td>10.327401</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-07</td>\n",
       "      <td>17.657474</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-08</td>\n",
       "      <td>25.898790</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-09</td>\n",
       "      <td>34.494040</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-10</td>\n",
       "      <td>45.340051</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>3.022948</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>10.131371</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-13</td>\n",
       "      <td>14.572434</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-14</td>\n",
       "      <td>22.816357</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27003 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds          y  static_0  static_1\n",
       "unique_id                                          \n",
       "id_00     2000-10-05   3.981198        79        45\n",
       "id_00     2000-10-06  10.327401        79        45\n",
       "id_00     2000-10-07  17.657474        79        45\n",
       "id_00     2000-10-08  25.898790        79        45\n",
       "id_00     2000-10-09  34.494040        79        45\n",
       "...              ...        ...       ...       ...\n",
       "id_99     2001-05-10  45.340051        69        35\n",
       "id_99     2001-05-11   3.022948        69        35\n",
       "id_99     2001-05-12  10.131371        69        35\n",
       "id_99     2001-05-13  14.572434        69        35\n",
       "id_99     2001-05-14  22.816357        69        35\n",
       "\n",
       "[27003 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, equal_ends=True, n_static_features=2, static_as_categorical=False)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89b3af-839e-43d4-9d09-ead84bedeed6",
   "metadata": {},
   "source": [
    "Whatever extra columns you have, like `static_0` and `static_1` here are considered to be static and are replicated when constructing the features for the next datestamp. You can disable this by passing `static_features` to `Forecast.preprocess` or `Forecast.fit` , which will only keep the columns you define there as static. Keep in mind that they will still be used for training, so you'll have to provide them to `Forecast.predict` through the `dynamic_dfs` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929f996-45a0-4d48-9af3-9ba4607362e2",
   "metadata": {},
   "source": [
    "### Creating the Forecast object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632163b-f049-4467-9635-7483982777b2",
   "metadata": {},
   "source": [
    "The models can be any scikit-learn compatible regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebf59f-0fb7-45ff-b355-127952413245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forecast(models=[LGBMRegressor, XGBRegressor], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=['dayofweek', 'month'], num_threads=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    lgb.LGBMRegressor(n_jobs=1, random_state=0),\n",
    "    xgb.XGBRegressor(n_jobs=1, random_state=0)\n",
    "]\n",
    "\n",
    "fcst = Forecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=2,\n",
    ")\n",
    "fcst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc538a8-97a1-4c5a-903e-9933188bdce0",
   "metadata": {},
   "source": [
    "Here where we say that:\n",
    "\n",
    "* Our series have daily frequency.\n",
    "* We want to use lag 7 as a feature\n",
    "* We want the lag transformations to be:\n",
    "   * expanding mean of the lag 1\n",
    "   * rolling mean of the lag 7 over a window of size 14\n",
    "* We want to use dayofweek and month as date features.\n",
    "* We want to perform the preprocessing and the forecasting steps using 2 threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b27ed8-c611-40ea-85cf-f97a2c56518f",
   "metadata": {},
   "source": [
    "From this point we have two options:\n",
    "\n",
    "1. Preprocess the data and fit our models using all of it.\n",
    "2. Preprocess the data and get it back as a dataframe to do some custom splitting or adding additional features, then training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00984e9a-3dbe-471f-98c7-a7ee82441575",
   "metadata": {},
   "source": [
    "#### 1. Using all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d42544-91a7-4c08-a190-925343e3c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Forecast.fit\n",
       "\n",
       ">      Forecast.fit (data:pandas.core.frame.DataFrame, id_col:str='index',\n",
       ">                    time_col:str='ds', target_col:str='y',\n",
       ">                    static_features:Optional[List[str]]=None, dropna:bool=True,\n",
       ">                    keep_last_n:Optional[int]=None)\n",
       "\n",
       "Preprocesses `data` and fits `models` using it.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | dataframe with the series' data |\n",
       "| id_col | str | index | column that identifies each serie. If 'index', the index is taken as the identifier of each serie |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| **Returns** | **Forecast** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Forecast.fit\n",
       "\n",
       ">      Forecast.fit (data:pandas.core.frame.DataFrame, id_col:str='index',\n",
       ">                    time_col:str='ds', target_col:str='y',\n",
       ">                    static_features:Optional[List[str]]=None, dropna:bool=True,\n",
       ">                    keep_last_n:Optional[int]=None)\n",
       "\n",
       "Preprocesses `data` and fits `models` using it.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | dataframe with the series' data |\n",
       "| id_col | str | index | column that identifies each serie. If 'index', the index is taken as the identifier of each serie |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| **Returns** | **Forecast** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Forecast.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd38e85-4369-4711-b104-fd2ee4e6e8fb",
   "metadata": {},
   "source": [
    "Calling `fit` on our data performs the preprocessing and uses all the data to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6a43b-8bcf-4ea4-95fb-0f1460521f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forecast(models=[LGBMRegressor, XGBRegressor], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=['dayofweek', 'month'], num_threads=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.fit(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41259cfa-6d22-4e57-b666-b50e3facf508",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc813d-9ab9-4905-9864-442c09bba7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Forecast.predict\n",
       "\n",
       ">      Forecast.predict (horizon:int,\n",
       ">                        dynamic_dfs:Optional[List[pandas.core.frame.DataFrame]]\n",
       ">                        =None, predict_fn:Optional[Callable]=None,\n",
       ">                        **predict_fn_kwargs)\n",
       "\n",
       "Compute the predictions for the next `horizon` steps.\n",
       "\n",
       "`predict_fn(model, new_x, dynamic_dfs, features_order, **predict_fn_kwargs)` is called in every timestep, where:\n",
       "`model` is the trained model.\n",
       "`new_x` is a dataframe with the same format as the input plus the computed features.\n",
       "`dynamic_dfs` is a list containing the dynamic dataframes.\n",
       "`features_order` is the list of column names that were used in the training step.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| horizon | int |  | number of periods to predict in the future |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None | future values for dynamic features |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None | custom function to compute predictions |\n",
       "| predict_fn_kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  | **additional arguments passed to predict_fn** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Forecast.predict\n",
       "\n",
       ">      Forecast.predict (horizon:int,\n",
       ">                        dynamic_dfs:Optional[List[pandas.core.frame.DataFrame]]\n",
       ">                        =None, predict_fn:Optional[Callable]=None,\n",
       ">                        **predict_fn_kwargs)\n",
       "\n",
       "Compute the predictions for the next `horizon` steps.\n",
       "\n",
       "`predict_fn(model, new_x, dynamic_dfs, features_order, **predict_fn_kwargs)` is called in every timestep, where:\n",
       "`model` is the trained model.\n",
       "`new_x` is a dataframe with the same format as the input plus the computed features.\n",
       "`dynamic_dfs` is a list containing the dynamic dataframes.\n",
       "`features_order` is the list of column names that were used in the training step.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| horizon | int |  | number of periods to predict in the future |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None | future values for dynamic features |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None | custom function to compute predictions |\n",
       "| predict_fn_kwargs |  |  |  |\n",
       "| **Returns** | **DataFrame** |  | **additional arguments passed to predict_fn** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Forecast.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e47c2-eea4-4359-8557-7a1ae4c11752",
   "metadata": {},
   "source": [
    "Once we have trained our models, we can compute the forecasts for the next 7 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c6766-35f8-4379-81cf-8e60718e9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>42.144818</td>\n",
       "      <td>42.934929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>49.965606</td>\n",
       "      <td>51.280045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2.133553</td>\n",
       "      <td>1.858219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>10.288427</td>\n",
       "      <td>9.754323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>18.616018</td>\n",
       "      <td>17.950321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>44.348196</td>\n",
       "      <td>43.529274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>1.947602</td>\n",
       "      <td>1.856401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>9.033580</td>\n",
       "      <td>8.921874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>15.220238</td>\n",
       "      <td>15.316792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>22.896340</td>\n",
       "      <td>22.143908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor  XGBRegressor\n",
       "unique_id                                        \n",
       "id_00     2001-05-15      42.144818     42.934929\n",
       "id_00     2001-05-16      49.965606     51.280045\n",
       "id_00     2001-05-17       2.133553      1.858219\n",
       "id_00     2001-05-18      10.288427      9.754323\n",
       "id_00     2001-05-19      18.616018     17.950321\n",
       "...              ...            ...           ...\n",
       "id_99     2001-05-17      44.348196     43.529274\n",
       "id_99     2001-05-18       1.947602      1.856401\n",
       "id_99     2001-05-19       9.033580      8.921874\n",
       "id_99     2001-05-20      15.220238     15.316792\n",
       "id_99     2001-05-21      22.896340     22.143908\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.predict(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe74b7-f0a3-4105-a11e-6da5b09ab7fe",
   "metadata": {},
   "source": [
    "This uses each prediction as the next value of the target and updates all features accordingly. The static features were propagated and the date features were computed using each new timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63b809-a70a-4067-891a-4fe3d6375069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "preds = fcst.predict(7)\n",
    "preds2 = fcst.predict(7)\n",
    "\n",
    "pd.testing.assert_frame_equal(preds, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab2fd6-cc7f-47e3-8a87-e0ec21590385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "non_std_series = series.copy()\n",
    "non_std_series['ds'] = non_std_series.groupby('unique_id').cumcount()\n",
    "non_std_series = non_std_series.reset_index().rename(columns={'unique_id': 'some_id', 'ds': 'time', 'y': 'value'})\n",
    "flow_params = dict(\n",
    "    models=models,\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    num_threads=2,\n",
    ")\n",
    "fcst = Forecast(**flow_params)\n",
    "non_std_preds = fcst.fit(non_std_series, id_col='some_id', time_col='time', target_col='value').predict(7)\n",
    "non_std_preds.index.name = 'unique_id'\n",
    "fcst = Forecast(freq='D', **flow_params)\n",
    "preds = fcst.fit(series).predict(7)\n",
    "pd.testing.assert_frame_equal(preds.drop(columns='ds'), non_std_preds.drop(columns='time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1ea5b-73ed-4e5b-8e5d-7333b6c8ae14",
   "metadata": {},
   "source": [
    "#### 2. Preprocess and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662a990-8c9f-4d19-b42c-e03c97164296",
   "metadata": {},
   "source": [
    "If we only want to perform the preprocessing step we call `preprocess` with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21260f3-bd8f-4143-bb60-deb9ca0d46e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Forecast.preprocess\n",
       "\n",
       ">      Forecast.preprocess (data:pandas.core.frame.DataFrame,\n",
       ">                           id_col:str='index', time_col:str='ds',\n",
       ">                           target_col:str='y',\n",
       ">                           static_features:Optional[List[str]]=None,\n",
       ">                           dropna:bool=True, keep_last_n:Optional[int]=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | dataframe with the series' data |\n",
       "| id_col | str | index | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Forecast.preprocess\n",
       "\n",
       ">      Forecast.preprocess (data:pandas.core.frame.DataFrame,\n",
       ">                           id_col:str='index', time_col:str='ds',\n",
       ">                           target_col:str='y',\n",
       ">                           static_features:Optional[List[str]]=None,\n",
       ">                           dropna:bool=True, keep_last_n:Optional[int]=None)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | dataframe with the series' data |\n",
       "| id_col | str | index | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Forecast.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1ce17-4daa-413a-b30c-d989e681d33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "      <th>lag-7</th>\n",
       "      <th>expanding_mean_lag-1</th>\n",
       "      <th>rolling_mean_lag-7_window_size-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-25</td>\n",
       "      <td>49.766844</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>50.694639</td>\n",
       "      <td>25.001367</td>\n",
       "      <td>26.320060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-26</td>\n",
       "      <td>3.918347</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>3.887780</td>\n",
       "      <td>26.180675</td>\n",
       "      <td>26.313387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>9.437778</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>11.512774</td>\n",
       "      <td>25.168751</td>\n",
       "      <td>26.398056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>17.923574</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>18.038498</td>\n",
       "      <td>24.484796</td>\n",
       "      <td>26.425272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>26.754645</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>24.222859</td>\n",
       "      <td>24.211411</td>\n",
       "      <td>26.305563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds          y  static_0  static_1      lag-7  \\\n",
       "unique_id                                                        \n",
       "id_00     2000-10-25  49.766844        79        45  50.694639   \n",
       "id_00     2000-10-26   3.918347        79        45   3.887780   \n",
       "id_00     2000-10-27   9.437778        79        45  11.512774   \n",
       "id_00     2000-10-28  17.923574        79        45  18.038498   \n",
       "id_00     2000-10-29  26.754645        79        45  24.222859   \n",
       "\n",
       "           expanding_mean_lag-1  rolling_mean_lag-7_window_size-14  \n",
       "unique_id                                                           \n",
       "id_00                 25.001367                          26.320060  \n",
       "id_00                 26.180675                          26.313387  \n",
       "id_00                 25.168751                          26.398056  \n",
       "id_00                 24.484796                          26.425272  \n",
       "id_00                 24.211411                          26.305563  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = fcst.preprocess(series)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebc74f-3210-4b7e-b248-a0fbfdcfd1e8",
   "metadata": {},
   "source": [
    "This is useful if we want to inspect the data the models will be trained on, adding additional features or performing some custom train-valid split. Here we perform an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f5c87-735d-4591-abbd-b8e9bc4256f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "train_mask = np.random.rand(features_df.shape[0]) < 0.8\n",
    "train, valid = features_df[train_mask], features_df[~train_mask]\n",
    "X_train, y_train = train.drop(columns=['ds', 'y']), train.y\n",
    "X_valid, y_valid = valid.drop(columns=['ds', 'y']), valid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f85d476-5096-4915-b267-13ff87f194bf",
   "metadata": {},
   "source": [
    "If we do this we must \"manually\" train our models and store them in the `models_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ff93a-3c2f-4d2d-b318-b20330c6f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = models[0].fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_names=['train', 'valid'],\n",
    "    eval_metric='rmse',\n",
    "    verbose=0\n",
    ")\n",
    "fcst.models_ = [fitted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cad330-09f6-4de1-a398-7c93434f73c2",
   "metadata": {},
   "source": [
    "We can see the RMSE by iteration for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e47494-b1c9-4685-b56a-87c0385b9604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.41</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.08</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.88</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.81</td>\n",
       "      <td>9.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.84</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train  valid\n",
       "0   13.41  13.40\n",
       "1   12.08  12.07\n",
       "2   10.88  10.88\n",
       "3    9.81   9.81\n",
       "4    8.84   8.84\n",
       "..    ...    ...\n",
       "95   0.93   0.99\n",
       "96   0.93   0.99\n",
       "97   0.93   0.99\n",
       "98   0.93   0.99\n",
       "99   0.93   0.99\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    k: np.round(fcst.models_[0].evals_result_[k]['rmse'], 2)\n",
    "    for k in ('train', 'valid')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942738d-13a3-4641-8706-cd9578709ec0",
   "metadata": {},
   "source": [
    "### Dynamic features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d333e-2fba-434c-b366-2e2285b6a235",
   "metadata": {},
   "source": [
    "By default the predict method repeats the static features and updates the transformations and the date features. If you have dynamic features like prices or a calendar with holidays you can pass them as a list to the `dynamic_dfs` argument of `Forecast.predict`, which will call `pd.DataFrame.merge` on each of them in order.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "Suppose that we have a `product_id` column and we have a catalog for prices based on that `product_id` and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d6354-e95e-444c-af11-18f273ee2d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-06-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>99</td>\n",
       "      <td>0.223520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>99</td>\n",
       "      <td>0.446104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20182</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>99</td>\n",
       "      <td>0.044783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20183</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>99</td>\n",
       "      <td>0.483216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20184</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>99</td>\n",
       "      <td>0.799660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ds  product_id     price\n",
       "0     2000-06-09           1  0.548814\n",
       "1     2000-06-10           1  0.715189\n",
       "2     2000-06-11           1  0.602763\n",
       "3     2000-06-12           1  0.544883\n",
       "4     2000-06-13           1  0.423655\n",
       "...          ...         ...       ...\n",
       "20180 2001-05-17          99  0.223520\n",
       "20181 2001-05-18          99  0.446104\n",
       "20182 2001-05-19          99  0.044783\n",
       "20183 2001-05-20          99  0.483216\n",
       "20184 2001-05-21          99  0.799660\n",
       "\n",
       "[20185 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_series = series.rename(columns={'static_1': 'product_id'})\n",
    "prices_catalog = generate_prices_for_series(dynamic_series)\n",
    "prices_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c34b7c-9cb9-4f20-af01-6b0e18b7ded2",
   "metadata": {},
   "source": [
    "And you have already merged these prices into your series dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc453901-10d1-441f-af31-0ee52a3d58f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>3.981198</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.570826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-06</td>\n",
       "      <td>10.327401</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.260562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-07</td>\n",
       "      <td>17.657474</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.274048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-08</td>\n",
       "      <td>25.898790</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.433878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-09</td>\n",
       "      <td>34.494040</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-10</td>\n",
       "      <td>45.340051</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.792152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>3.022948</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.782687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>10.131371</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.019463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-13</td>\n",
       "      <td>14.572434</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.190413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-14</td>\n",
       "      <td>22.816357</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.653394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27003 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds          y  static_0  product_id     price\n",
       "unique_id                                                      \n",
       "id_00     2000-10-05   3.981198        79          45  0.570826\n",
       "id_00     2000-10-06  10.327401        79          45  0.260562\n",
       "id_00     2000-10-07  17.657474        79          45  0.274048\n",
       "id_00     2000-10-08  25.898790        79          45  0.433878\n",
       "id_00     2000-10-09  34.494040        79          45  0.653738\n",
       "...              ...        ...       ...         ...       ...\n",
       "id_99     2001-05-10  45.340051        69          35  0.792152\n",
       "id_99     2001-05-11   3.022948        69          35  0.782687\n",
       "id_99     2001-05-12  10.131371        69          35  0.019463\n",
       "id_99     2001-05-13  14.572434        69          35  0.190413\n",
       "id_99     2001-05-14  22.816357        69          35  0.653394\n",
       "\n",
       "[27003 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_with_prices = dynamic_series.reset_index().merge(prices_catalog, how='left')\n",
    "series_with_prices.set_index('unique_id', inplace=True)\n",
    "series_with_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83710575-1276-4eeb-8cca-64165eee7154",
   "metadata": {},
   "source": [
    "This dataframe will be passed to `Forecast.fit` (or `Forecast.preprocess`), however since the price is dynamic we have to tell that method that only `static_0` and `product_id` are static and we'll have to update `price` in every timestep, which basically involves merging the updated features with the prices catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51961753-215f-4a0c-b5d5-a2678d63a4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forecast(models=[LGBMRegressor, XGBRegressor], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=[], num_threads=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.fit(series_with_prices, static_features=['static_0', 'product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9c1c9-3a86-4fbd-a493-31c3d05c0011",
   "metadata": {},
   "source": [
    "The features used for training are stored in `Forecast.ts.features_order_`, as you can see `price` was used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c160114-073e-483a-9c27-638487674b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['static_0',\n",
       " 'product_id',\n",
       " 'price',\n",
       " 'lag-7',\n",
       " 'expanding_mean_lag-1',\n",
       " 'rolling_mean_lag-7_window_size-14']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.ts.features_order_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304b47d-5c16-4cae-ba4f-3f6364d8a4ad",
   "metadata": {},
   "source": [
    "So in order to update the price in each timestep we just call `Forecast.predict` with our forecast horizon and pass the prices catalog as a dynamic dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e071906-3d80-4fa5-9b55-55c90f338985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>42.829567</td>\n",
       "      <td>42.621590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>49.946924</td>\n",
       "      <td>50.820297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2.186703</td>\n",
       "      <td>1.502528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>10.267976</td>\n",
       "      <td>9.736752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>18.666022</td>\n",
       "      <td>18.227610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>44.410242</td>\n",
       "      <td>43.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>2.002115</td>\n",
       "      <td>1.789129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>9.074003</td>\n",
       "      <td>9.035077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>15.102148</td>\n",
       "      <td>15.341413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>22.925604</td>\n",
       "      <td>22.799040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor  XGBRegressor\n",
       "unique_id                                        \n",
       "id_00     2001-05-15      42.829567     42.621590\n",
       "id_00     2001-05-16      49.946924     50.820297\n",
       "id_00     2001-05-17       2.186703      1.502528\n",
       "id_00     2001-05-18      10.267976      9.736752\n",
       "id_00     2001-05-19      18.666022     18.227610\n",
       "...              ...            ...           ...\n",
       "id_99     2001-05-17      44.410242     43.474300\n",
       "id_99     2001-05-18       2.002115      1.789129\n",
       "id_99     2001-05-19       9.074003      9.035077\n",
       "id_99     2001-05-20      15.102148     15.341413\n",
       "id_99     2001-05-21      22.925604     22.799040\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7, dynamic_dfs=[prices_catalog])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fb8b4-f0a3-4012-a410-05972fe61ef1",
   "metadata": {},
   "source": [
    "### Custom predictions\n",
    "As you may have noticed `Forecast.predict` can take a `predict_fn` and `predict_fn_kwargs`. By default the predict method repeats the static features and updates the transformations and the date features. If you have dynamic features you can pass them as a list to `Forecast.predict` in the `dynamic_dfs` argument. However, if you want to do something else, you can define your own function which will take:\n",
    "\n",
    "* The trained model.\n",
    "* The updated features (static + transformations + date features).\n",
    "* A list of dataframes with the dynamic features.\n",
    "* The order of the features the model was trained on.\n",
    "* Additional keyword arguments passed to `Forecast.predict`.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "Suppose that we want to scale our predictions so that our series are updated with these scaled values. We can achieve that with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3f96f-4bea-4e29-84af-caa370b19c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_predict_fn(\n",
    "    model,\n",
    "    new_x,\n",
    "    dynamic_dfs,\n",
    "    features_order,\n",
    "    scale_factor,\n",
    ") -> np.ndarray:\n",
    "    new_x = new_x[features_order]\n",
    "    predictions = model.predict(new_x)\n",
    "    return scale_factor * predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a252b2-b83c-49d0-bc59-6d4ae7f637fb",
   "metadata": {},
   "source": [
    "And now we just pass this function to `Forecast.predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c58c7-2c30-4fba-89ae-d43a11ea6115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>46.298462</td>\n",
       "      <td>47.070534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>54.772835</td>\n",
       "      <td>55.468819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_01</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>12.808338</td>\n",
       "      <td>12.969510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_01</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>16.426544</td>\n",
       "      <td>16.559385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_02</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>16.339826</td>\n",
       "      <td>16.399563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_97</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>38.865211</td>\n",
       "      <td>39.316402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_98</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>8.268328</td>\n",
       "      <td>8.267344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_98</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>10.476819</td>\n",
       "      <td>10.496795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>32.602098</td>\n",
       "      <td>32.453793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>40.852826</td>\n",
       "      <td>40.701611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor  XGBRegressor\n",
       "unique_id                                        \n",
       "id_00     2001-05-15      46.298462     47.070534\n",
       "id_00     2001-05-16      54.772835     55.468819\n",
       "id_01     2001-05-15      12.808338     12.969510\n",
       "id_01     2001-05-16      16.426544     16.559385\n",
       "id_02     2001-05-15      16.339826     16.399563\n",
       "...              ...            ...           ...\n",
       "id_97     2001-05-16      38.865211     39.316402\n",
       "id_98     2001-05-15       8.268328      8.267344\n",
       "id_98     2001-05-16      10.476819     10.496795\n",
       "id_99     2001-05-15      32.602098     32.453793\n",
       "id_99     2001-05-16      40.852826     40.701611\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = Forecast(models, freq='D', lags=[7])\n",
    "fcst.fit(series)\n",
    "\n",
    "scale_factor = 1.1\n",
    "preds = fcst.predict(2, predict_fn=scaling_predict_fn, scale_factor=scale_factor)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f15e85-4cfe-4f04-b6bb-5f794dd12390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "fcst.ts._predict_setup()\n",
    "\n",
    "for attr in ('head', 'tail'):\n",
    "    new_x = fcst.ts._update_features().drop(columns='ds')\n",
    "    original_preds = fcst.models_[0].predict(new_x)\n",
    "    \n",
    "    expected = scale_factor * original_preds\n",
    "    actual = getattr(preds.groupby('unique_id')[models[0].__class__.__name__], attr)(1).values\n",
    "    np.testing.assert_equal(expected, actual)\n",
    "    \n",
    "    fcst.ts._update_y(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7b0dd-d3e2-44c0-a25c-500e9ceaaa3d",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "If we would like to know how good our forecast will be for a specific model and set of features then we can perform cross validation. What cross validation does is take our data and split it in two parts, where the first part is used for training and the second one for validation. Since the data is time dependant we usually take the last *x* observations from our data as the validation set.\n",
    "\n",
    "This process is implemented in `Forecast.cross_validation`, which takes our data and performs the process described above for `n_windows` times where each window is of size `window_size`. For example, if we have 100 samples and we want to perform 2 backtests each of size 14, the splits will be as follows:\n",
    "\n",
    "1. Train: 1 to 72. Validation: 73 to 86.\n",
    "2. Train: 1 to 86. Validation: 87 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65bc38-7a1b-4f52-ace2-677fa9c3561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Forecast.cross_validation\n",
       "\n",
       ">      Forecast.cross_validation (data:pandas.core.frame.DataFrame,\n",
       ">                                 n_windows:int, window_size:int,\n",
       ">                                 id_col:str='index', time_col:str='ds',\n",
       ">                                 target_col:str='y',\n",
       ">                                 static_features:Optional[List[str]]=None,\n",
       ">                                 dropna:bool=True,\n",
       ">                                 keep_last_n:Optional[int]=None, dynamic_dfs:Op\n",
       ">                                 tional[List[pandas.core.frame.DataFrame]]=None\n",
       ">                                 , predict_fn:Optional[Callable]=None,\n",
       ">                                 **predict_fn_kwargs)\n",
       "\n",
       "Creates `n_windows` splits of `window_size` from `data`, trains the model\n",
       "on the training set, predicts the window and merges the actuals and the predictions\n",
       "in a dataframe.\n",
       "\n",
       "Returns a dataframe containing the datestamps, actual values, train ends and predictions.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | time series |\n",
       "| n_windows | int |  | number of windows to evaluate |\n",
       "| window_size | int |  | test size in each window |\n",
       "| id_col | str | index | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None | future values for dynamic features |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None | custom function to compute predictions |\n",
       "| predict_fn_kwargs |  |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Forecast.cross_validation\n",
       "\n",
       ">      Forecast.cross_validation (data:pandas.core.frame.DataFrame,\n",
       ">                                 n_windows:int, window_size:int,\n",
       ">                                 id_col:str='index', time_col:str='ds',\n",
       ">                                 target_col:str='y',\n",
       ">                                 static_features:Optional[List[str]]=None,\n",
       ">                                 dropna:bool=True,\n",
       ">                                 keep_last_n:Optional[int]=None, dynamic_dfs:Op\n",
       ">                                 tional[List[pandas.core.frame.DataFrame]]=None\n",
       ">                                 , predict_fn:Optional[Callable]=None,\n",
       ">                                 **predict_fn_kwargs)\n",
       "\n",
       "Creates `n_windows` splits of `window_size` from `data`, trains the model\n",
       "on the training set, predicts the window and merges the actuals and the predictions\n",
       "in a dataframe.\n",
       "\n",
       "Returns a dataframe containing the datestamps, actual values, train ends and predictions.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  | time series |\n",
       "| n_windows | int |  | number of windows to evaluate |\n",
       "| window_size | int |  | test size in each window |\n",
       "| id_col | str | index | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None | column names of the features that don't change in time |\n",
       "| dropna | bool | True | drop rows with missing values created by lags |\n",
       "| keep_last_n | typing.Optional[int] | None | keep only this many observations of each serie for computing the updates |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None | future values for dynamic features |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None | custom function to compute predictions |\n",
       "| predict_fn_kwargs |  |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Forecast.cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c0057-9245-4a67-bb4d-836f17030e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>40.499332</td>\n",
       "      <td>41.412064</td>\n",
       "      <td>41.445278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-04-18</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>50.888323</td>\n",
       "      <td>49.478838</td>\n",
       "      <td>49.127155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-04-19</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>0.121812</td>\n",
       "      <td>2.051727</td>\n",
       "      <td>2.088633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-04-20</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>10.987977</td>\n",
       "      <td>10.017578</td>\n",
       "      <td>10.022248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>2001-04-16</td>\n",
       "      <td>16.370385</td>\n",
       "      <td>18.710617</td>\n",
       "      <td>18.389297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds     cutoff          y  LGBMRegressor  XGBRegressor\n",
       "unique_id                                                              \n",
       "id_00     2001-04-17 2001-04-16  40.499332      41.412064     41.445278\n",
       "id_00     2001-04-18 2001-04-16  50.888323      49.478838     49.127155\n",
       "id_00     2001-04-19 2001-04-16   0.121812       2.051727      2.088633\n",
       "id_00     2001-04-20 2001-04-16  10.987977      10.017578     10.022248\n",
       "id_00     2001-04-21 2001-04-16  16.370385      18.710617     18.389297"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_windows = 2\n",
    "window_size = 14\n",
    "\n",
    "backtest_results = fcst.cross_validation(series, n_windows, window_size)\n",
    "backtest_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc20827-e4db-4c14-aba5-66177d903614",
   "metadata": {},
   "source": [
    "We can aggregate these by date to get a rough estimate of how our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0f301-474c-4abe-9e50-d52458fb19e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-04-17</th>\n",
       "      <td>16.123231</td>\n",
       "      <td>16.208721</td>\n",
       "      <td>16.171181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-18</th>\n",
       "      <td>15.213920</td>\n",
       "      <td>15.131302</td>\n",
       "      <td>15.151584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-19</th>\n",
       "      <td>16.985699</td>\n",
       "      <td>17.130627</td>\n",
       "      <td>17.121136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-20</th>\n",
       "      <td>18.068340</td>\n",
       "      <td>18.032494</td>\n",
       "      <td>18.075195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-21</th>\n",
       "      <td>18.200609</td>\n",
       "      <td>18.094151</td>\n",
       "      <td>18.183397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    y  LGBMRegressor  XGBRegressor\n",
       "ds                                                \n",
       "2001-04-17  16.123231      16.208721     16.171181\n",
       "2001-04-18  15.213920      15.131302     15.151584\n",
       "2001-04-19  16.985699      17.130627     17.121136\n",
       "2001-04-20  18.068340      18.032494     18.075195\n",
       "2001-04-21  18.200609      18.094151     18.183397"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = backtest_results.groupby('ds').mean()\n",
    "agg_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cedc05-c9e8-4c9a-a6dd-a78118f635e8",
   "metadata": {},
   "source": [
    "We can also compute the error for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb0d33-96eb-428d-8671-538ce0385fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBMRegressor': 0.92, 'XGBRegressor': 0.88}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{model: np.round(mean_squared_error(backtest_results['y'], backtest_results[model]), 2)\n",
    " for model in backtest_results.columns.drop(['ds', 'y', 'cutoff'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ca7ea-b275-4bc6-8ee7-3a41a46f3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "fcst = Forecast(lgb.LGBMRegressor(), freq='D', lags=[7, 14])\n",
    "backtest_results = fcst.cross_validation(\n",
    "    non_std_series,\n",
    "    n_windows,\n",
    "    window_size,\n",
    "    id_col='some_id',\n",
    "    time_col='time',\n",
    "    target_col='value',\n",
    "    static_features=['static_0', 'static_1'],\n",
    ")\n",
    "renamer = {'some_id': 'unique_id', 'time': 'ds', 'value': 'y'}\n",
    "backtest_results = backtest_results.rename(columns=renamer).set_index('unique_id')\n",
    "renamed = non_std_series.rename(columns=renamer).set_index('unique_id')\n",
    "manual_results = []\n",
    "for cutoff, train, valid in backtest_splits(renamed, n_windows, window_size, 1):\n",
    "    fcst.fit(train, static_features=['static_0', 'static_1'])\n",
    "    pred = fcst.predict(window_size)\n",
    "    res = valid[['ds', 'y']].copy()\n",
    "    res['cutoff'] = cutoff\n",
    "    res = res[['ds', 'cutoff', 'y']].copy()\n",
    "    manual_results.append(res.merge(pred, on=['unique_id', 'ds'], how='left'))\n",
    "manual_results = pd.concat(manual_results)\n",
    "pd.testing.assert_frame_equal(backtest_results, manual_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
