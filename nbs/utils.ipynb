{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import random\n",
    "from itertools import chain\n",
    "from math import ceil, log10\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "from fastcore.test import test_eq, test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_daily_series(\n",
    "    n_series: int, \n",
    "    min_length: int = 50,\n",
    "    max_length: int = 500,\n",
    "    n_static_features: int = 0,\n",
    "    equal_ends: bool = False,\n",
    "    static_as_categorical: bool = True,\n",
    "    seed: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generates `n_series` of different lengths in the interval [`min_length`, `max_length`].\n",
    "    \n",
    "    If `n_static_features > 0`, then each serie gets static features with random values.\n",
    "    If `equal_ends == True` then all series end at the same date.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    series_lengths = rng.randint(min_length, max_length + 1, n_series)\n",
    "    total_length = series_lengths.sum()\n",
    "    n_digits = ceil(log10(n_series))\n",
    "    \n",
    "    dates = pd.date_range('2000-01-01', periods=max_length, freq='D').values\n",
    "    uids = [\n",
    "        [f'id_{i:0{n_digits}}'] * serie_length\n",
    "        for i, serie_length in enumerate(series_lengths)\n",
    "    ]\n",
    "    if equal_ends:\n",
    "        ds = [dates[-serie_length:] for serie_length in series_lengths]\n",
    "    else:\n",
    "        ds = [dates[:serie_length] for serie_length in series_lengths]\n",
    "    y = np.arange(total_length) % 7 + rng.rand(total_length) * 0.5\n",
    "    series = pd.DataFrame(\n",
    "        {\n",
    "            'unique_id': list(chain.from_iterable(uids)),\n",
    "            'ds': list(chain.from_iterable(ds)),\n",
    "            'y': y,\n",
    "        }\n",
    "    )\n",
    "    for i in range(n_static_features):\n",
    "        static_values = np.repeat(rng.randint(0, 100, n_series), series_lengths)\n",
    "        series[f'static_{i}'] = static_values\n",
    "        if static_as_categorical:\n",
    "            series[f'static_{i}'] = series[f'static_{i}'].astype('category')\n",
    "        if i == 0:\n",
    "            series['y'] = series['y'] * (1 + static_values)\n",
    "    series['unique_id'] = series['unique_id'].astype('category')\n",
    "    series['unique_id'] = series['unique_id'].cat.as_ordered()\n",
    "    series = series.set_index('unique_id')\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 20 series with lengths between 100 and 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.395863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.264447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.284022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>3.462798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>4.035518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-11</td>\n",
       "      <td>0.309275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-12</td>\n",
       "      <td>1.189464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-13</td>\n",
       "      <td>2.325032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>3.333198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-15</td>\n",
       "      <td>4.306117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12451 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds         y\n",
       "unique_id                     \n",
       "id_00     2000-01-01  0.395863\n",
       "id_00     2000-01-02  1.264447\n",
       "id_00     2000-01-03  2.284022\n",
       "id_00     2000-01-04  3.462798\n",
       "id_00     2000-01-05  4.035518\n",
       "...              ...       ...\n",
       "id_19     2002-03-11  0.309275\n",
       "id_19     2002-03-12  1.189464\n",
       "id_19     2002-03-13  2.325032\n",
       "id_19     2002-03-14  3.333198\n",
       "id_19     2002-03-15  4.306117\n",
       "\n",
       "[12451 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_series = 20\n",
    "min_length = 100\n",
    "max_length = 1000\n",
    "\n",
    "series = generate_daily_series(n_series, min_length, max_length)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_sizes = series.groupby('unique_id').size()\n",
    "assert series_sizes.size == n_series\n",
    "assert series_sizes.min() >= min_length\n",
    "assert series_sizes.max() <= max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add static features to each serie (these can be things like product_id or store_id). Only the first static feature (`static_0`) is relevant to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>7.521388</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>24.024502</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>43.396423</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>65.793168</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>76.674843</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-11</td>\n",
       "      <td>27.834771</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-12</td>\n",
       "      <td>107.051746</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-13</td>\n",
       "      <td>209.252845</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>299.987801</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_19</th>\n",
       "      <td>2002-03-15</td>\n",
       "      <td>387.550536</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12451 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds           y static_0 static_1\n",
       "unique_id                                         \n",
       "id_00     2000-01-01    7.521388       18       10\n",
       "id_00     2000-01-02   24.024502       18       10\n",
       "id_00     2000-01-03   43.396423       18       10\n",
       "id_00     2000-01-04   65.793168       18       10\n",
       "id_00     2000-01-05   76.674843       18       10\n",
       "...              ...         ...      ...      ...\n",
       "id_19     2002-03-11   27.834771       89       42\n",
       "id_19     2002-03-12  107.051746       89       42\n",
       "id_19     2002-03-13  209.252845       89       42\n",
       "id_19     2002-03-14  299.987801       89       42\n",
       "id_19     2002-03-15  387.550536       89       42\n",
       "\n",
       "[12451 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_static_features = 2\n",
    "\n",
    "series_with_statics = generate_daily_series(n_series, min_length, max_length, n_static_features)\n",
    "series_with_statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_static_features):\n",
    "    assert all(series_with_statics.groupby('unique_id')[f'static_{i}'].nunique() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `equal_ends=False` (the default) then every serie has a different end date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert series_with_statics.groupby('unique_id')['ds'].max().nunique() > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have all of them end at the same date by specifying `equal_ends=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_equal_ends = generate_daily_series(n_series, min_length, max_length, equal_ends=True)\n",
    "\n",
    "assert series_equal_ends.groupby('unique_id')['ds'].max().nunique() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_prices_for_series(series: pd.DataFrame, horizon: int = 7, seed: int = 0) -> pd.DataFrame:\n",
    "    rng = np.random.RandomState(0)\n",
    "    unique_last_dates = series.groupby('unique_id')['ds'].max().nunique()\n",
    "    if unique_last_dates > 1:\n",
    "        raise ValueError('series must have equal ends.')\n",
    "    if 'product_id' not in series:\n",
    "        raise ValueError('series must have a product_id column.')\n",
    "    day_offset = pd.tseries.frequencies.Day()\n",
    "    starts_ends = series.groupby('product_id')['ds'].agg([min, max])\n",
    "    dfs = []\n",
    "    for idx, (start, end) in starts_ends.iterrows():\n",
    "        product_df = pd.DataFrame(\n",
    "            {\n",
    "                'product_id': idx,\n",
    "                'price': rng.rand((end - start).days + 1 + horizon),\n",
    "            },\n",
    "            index=pd.date_range(start, end + horizon * day_offset, name='ds'),\n",
    "        )\n",
    "        dfs.append(product_df)\n",
    "    prices_catalog = pd.concat(dfs).reset_index()\n",
    "    return prices_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-07</td>\n",
       "      <td>9</td>\n",
       "      <td>0.548814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-08</td>\n",
       "      <td>9</td>\n",
       "      <td>0.715189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-09</td>\n",
       "      <td>9</td>\n",
       "      <td>0.602763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.423655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>93</td>\n",
       "      <td>0.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>93</td>\n",
       "      <td>0.909013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>93</td>\n",
       "      <td>0.904419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>93</td>\n",
       "      <td>0.327888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>93</td>\n",
       "      <td>0.971973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds  product_id     price\n",
       "0    2000-05-07           9  0.548814\n",
       "1    2000-05-08           9  0.715189\n",
       "2    2000-05-09           9  0.602763\n",
       "3    2000-05-10           9  0.544883\n",
       "4    2000-05-11           9  0.423655\n",
       "...         ...         ...       ...\n",
       "4263 2001-05-17          93  0.800781\n",
       "4264 2001-05-18          93  0.909013\n",
       "4265 2001-05-19          93  0.904419\n",
       "4266 2001-05-20          93  0.327888\n",
       "4267 2001-05-21          93  0.971973\n",
       "\n",
       "[4268 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_for_prices = generate_daily_series(20, n_static_features=2, equal_ends=True)\n",
    "series_for_prices.rename(columns={'static_1': 'product_id'}, inplace=True)\n",
    "prices_catalog = generate_prices_for_series(series_for_prices, horizon=7)\n",
    "prices_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(set(prices_catalog['product_id']), set(series_for_prices['product_id']))\n",
    "test_fail(lambda: generate_prices_for_series(series_equal_ends), contains='product_id')\n",
    "test_fail(lambda: generate_prices_for_series(series), contains='equal ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def data_indptr_from_sorted_df(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    grouped = df.groupby('unique_id')\n",
    "    sizes = grouped.size().values\n",
    "    indptr = np.append(0, sizes.cumsum())\n",
    "    data = df['y'].values\n",
    "    return data, indptr\n",
    "\n",
    "def ensure_sorted(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.set_index('ds', append=True)\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "    return df.reset_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _split_info(data: pd.DataFrame, offset: int, window_size: int, freq: Union[pd.offsets.BaseOffset, int]):\n",
    "    # TODO: try computing this once and passing it to this fn\n",
    "    last_dates = data.groupby('unique_id')['ds'].transform('max')\n",
    "    train_ends = last_dates - offset * freq\n",
    "    valid_ends = train_ends + window_size * freq\n",
    "    valid_mask = data['ds'].gt(train_ends) & data['ds'].le(valid_ends)\n",
    "    return pd.DataFrame({'train_end': train_ends, 'is_valid': valid_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def backtest_splits(data, n_windows: int, window_size: int, freq: Union[pd.offsets.BaseOffset, int]):\n",
    "    for i in range(n_windows):\n",
    "        offset = (n_windows - i) * window_size\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            splits = _split_info(data, offset, window_size, freq)\n",
    "        else:\n",
    "            meta = _split_info(data.head(), offset, window_size, freq)\n",
    "            splits = data.map_partitions(\n",
    "                _split_info,\n",
    "                offset=offset,\n",
    "                window_size=window_size,\n",
    "                freq=freq,\n",
    "                meta=meta,\n",
    "            )\n",
    "        train_mask = data['ds'].le(splits['train_end'])\n",
    "        train, valid = data[train_mask], data[splits['is_valid']]\n",
    "        yield splits.loc[splits['is_valid'], 'train_end'], train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "n_windows = 3\n",
    "window_size = 14\n",
    "max_dates = series.groupby('unique_id')['ds'].max()\n",
    "day_offset = pd.offsets.Day()\n",
    "series_ddf = dd.from_pandas(series, npartitions=2)\n",
    "\n",
    "for df in (series, series_ddf):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        permuted_df = df.sample(frac=1.)\n",
    "    else:\n",
    "        permuted_df = df.map_partitions(lambda part: part.sample(frac=1.), meta=df)    \n",
    "    splits = backtest_splits(df, n_windows, window_size, pd.offsets.Day())\n",
    "    splits_on_permuted = list(backtest_splits(permuted_df, n_windows, window_size, pd.offsets.Day()))\n",
    "    for window, (_, train, valid) in enumerate(splits):\n",
    "        expected_max_train_dates = max_dates - day_offset * (n_windows - window) * window_size\n",
    "        max_train_dates = train.groupby('unique_id')['ds'].max()\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            max_train_dates = max_train_dates.compute()\n",
    "        pd.testing.assert_series_equal(max_train_dates, expected_max_train_dates)\n",
    "\n",
    "        expected_min_valid_dates = expected_max_train_dates + day_offset\n",
    "        min_valid_dates = valid.groupby('unique_id')['ds'].min()\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            min_valid_dates = min_valid_dates.compute()\n",
    "        pd.testing.assert_series_equal(min_valid_dates, expected_min_valid_dates)\n",
    "\n",
    "        expected_max_valid_dates = expected_max_train_dates + day_offset * window_size\n",
    "        max_valid_dates = valid.groupby('unique_id')['ds'].max()\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            max_valid_dates = max_valid_dates.compute()\n",
    "        pd.testing.assert_series_equal(max_valid_dates, expected_max_valid_dates)\n",
    "\n",
    "        if window == n_windows - 1:\n",
    "            pd.testing.assert_series_equal(max_valid_dates, max_dates)\n",
    "            \n",
    "        _, permuted_train, permuted_valid = splits_on_permuted[window]            \n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            train = train.compute()\n",
    "            valid = valid.compute()\n",
    "            permuted_train = permuted_train.compute()\n",
    "            permuted_valid = permuted_valid.compute()\n",
    "        pd.testing.assert_frame_equal(train, permuted_train.sort_values(['unique_id', 'ds']))\n",
    "        pd.testing.assert_frame_equal(valid, permuted_valid.sort_values(['unique_id', 'ds']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
