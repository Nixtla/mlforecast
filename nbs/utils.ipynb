{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import reprlib\n",
    "import warnings\n",
    "from math import ceil, log10\n",
    "from typing import Generator, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utilsforecast.compat import DataFrame, Series, pl\n",
    "from utilsforecast.data import generate_series\n",
    "from utilsforecast.processing import (\n",
    "    DataFrameProcessor,\n",
    "    filter_with_mask,\n",
    "    group_by,\n",
    "    offset_dates,\n",
    "    take_rows,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_fail\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_daily_series(\n",
    "    n_series: int, \n",
    "    min_length: int = 50,\n",
    "    max_length: int = 500,\n",
    "    n_static_features: int = 0,\n",
    "    equal_ends: bool = False,\n",
    "    static_as_categorical: bool = True,\n",
    "    with_trend: bool = False,\n",
    "    seed: int = 0,\n",
    "    engine: str = 'pandas',\n",
    ") -> DataFrame:\n",
    "    \"\"\"Generate Synthetic Panel Series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_series : int\n",
    "        Number of series for synthetic panel.\n",
    "    min_length : int (default=50)\n",
    "        Minimum length of synthetic panel's series.\n",
    "    max_length : int (default=500)\n",
    "        Maximum length of synthetic panel's series.\n",
    "    n_static_features : int (default=0)\n",
    "        Number of static exogenous variables for synthetic panel's series.\n",
    "    equal_ends : bool (default=False)\n",
    "        Series should end in the same date stamp `ds`.\n",
    "    static_as_categorical : bool (default=True)\n",
    "        Static features should have a categorical data type.        \n",
    "    with_trend : bool (default=False)\n",
    "        Series should have a (positive) trend.\n",
    "    seed : int (default=0)\n",
    "        Random seed used for generating the data.\n",
    "    engine : str (default='pandas')\n",
    "        Output Dataframe type.        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas or polars DataFrame\n",
    "        Synthetic panel with columns [`unique_id`, `ds`, `y`] and exogenous features.\n",
    "    \"\"\"\n",
    "    series = generate_series(\n",
    "        n_series=n_series,\n",
    "        freq='D',\n",
    "        min_length=min_length,\n",
    "        max_length=max_length,\n",
    "        n_static_features=n_static_features,\n",
    "        equal_ends=equal_ends,\n",
    "        static_as_categorical=static_as_categorical,        \n",
    "        with_trend=with_trend,\n",
    "        seed=seed,\n",
    "        engine=engine,\n",
    "    )\n",
    "    n_digits = ceil(log10(n_series))\n",
    "    \n",
    "    def int_id_to_str(uid):\n",
    "        return f'id_{uid:0{n_digits}}'    \n",
    "\n",
    "    if engine == 'pandas':\n",
    "        series['unique_id'] = series['unique_id'].map(int_id_to_str).astype('category')\n",
    "    else:\n",
    "        import polars as pl\n",
    "\n",
    "        series = series.with_columns(pl.col('unique_id').map_elements(int_id_to_str).cast(pl.Categorical))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### generate_daily_series\n",
       "\n",
       ">      generate_daily_series (n_series:int, min_length:int=50,\n",
       ">                             max_length:int=500, n_static_features:int=0,\n",
       ">                             equal_ends:bool=False,\n",
       ">                             static_as_categorical:bool=True,\n",
       ">                             with_trend:bool=False, seed:int=0,\n",
       ">                             engine:str='pandas')\n",
       "\n",
       "Generate Synthetic Panel Series.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_series | int |  | Number of series for synthetic panel. |\n",
       "| min_length | int | 50 | Minimum length of synthetic panel's series. |\n",
       "| max_length | int | 500 | Maximum length of synthetic panel's series. |\n",
       "| n_static_features | int | 0 | Number of static exogenous variables for synthetic panel's series. |\n",
       "| equal_ends | bool | False | Series should end in the same date stamp `ds`. |\n",
       "| static_as_categorical | bool | True | Static features should have a categorical data type.         |\n",
       "| with_trend | bool | False | Series should have a (positive) trend. |\n",
       "| seed | int | 0 | Random seed used for generating the data. |\n",
       "| engine | str | pandas | Output Dataframe type.         |\n",
       "| **Returns** | **Union** |  | **Synthetic panel with columns [`unique_id`, `ds`, `y`] and exogenous features.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### generate_daily_series\n",
       "\n",
       ">      generate_daily_series (n_series:int, min_length:int=50,\n",
       ">                             max_length:int=500, n_static_features:int=0,\n",
       ">                             equal_ends:bool=False,\n",
       ">                             static_as_categorical:bool=True,\n",
       ">                             with_trend:bool=False, seed:int=0,\n",
       ">                             engine:str='pandas')\n",
       "\n",
       "Generate Synthetic Panel Series.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_series | int |  | Number of series for synthetic panel. |\n",
       "| min_length | int | 50 | Minimum length of synthetic panel's series. |\n",
       "| max_length | int | 500 | Maximum length of synthetic panel's series. |\n",
       "| n_static_features | int | 0 | Number of static exogenous variables for synthetic panel's series. |\n",
       "| equal_ends | bool | False | Series should end in the same date stamp `ds`. |\n",
       "| static_as_categorical | bool | True | Static features should have a categorical data type.         |\n",
       "| with_trend | bool | False | Series should have a (positive) trend. |\n",
       "| seed | int | 0 | Random seed used for generating the data. |\n",
       "| engine | str | pandas | Output Dataframe type.         |\n",
       "| **Returns** | **Union** |  | **Synthetic panel with columns [`unique_id`, `ds`, `y`] and exogenous features.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(generate_daily_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 20 series with lengths between 100 and 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.395863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.264447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.284022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>3.462798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>4.035518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12446</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-11</td>\n",
       "      <td>0.309275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-12</td>\n",
       "      <td>1.189464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-13</td>\n",
       "      <td>2.325032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>3.333198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-15</td>\n",
       "      <td>4.306117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12451 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds         y\n",
       "0         id_00 2000-01-01  0.395863\n",
       "1         id_00 2000-01-02  1.264447\n",
       "2         id_00 2000-01-03  2.284022\n",
       "3         id_00 2000-01-04  3.462798\n",
       "4         id_00 2000-01-05  4.035518\n",
       "...         ...        ...       ...\n",
       "12446     id_19 2002-03-11  0.309275\n",
       "12447     id_19 2002-03-12  1.189464\n",
       "12448     id_19 2002-03-13  2.325032\n",
       "12449     id_19 2002-03-14  3.333198\n",
       "12450     id_19 2002-03-15  4.306117\n",
       "\n",
       "[12451 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_series = 20\n",
    "min_length = 100\n",
    "max_length = 1000\n",
    "\n",
    "series = generate_daily_series(n_series, min_length, max_length)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add static features to each serie (these can be things like product_id or store_id). Only the first static feature (`static_0`) is relevant to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>7.521388</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>24.024502</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>43.396423</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>65.793168</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>76.674843</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12446</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-11</td>\n",
       "      <td>27.834771</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-12</td>\n",
       "      <td>107.051746</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-13</td>\n",
       "      <td>209.252845</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-14</td>\n",
       "      <td>299.987801</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>id_19</td>\n",
       "      <td>2002-03-15</td>\n",
       "      <td>387.550536</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12451 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds           y static_0 static_1\n",
       "0         id_00 2000-01-01    7.521388       18       10\n",
       "1         id_00 2000-01-02   24.024502       18       10\n",
       "2         id_00 2000-01-03   43.396423       18       10\n",
       "3         id_00 2000-01-04   65.793168       18       10\n",
       "4         id_00 2000-01-05   76.674843       18       10\n",
       "...         ...        ...         ...      ...      ...\n",
       "12446     id_19 2002-03-11   27.834771       89       42\n",
       "12447     id_19 2002-03-12  107.051746       89       42\n",
       "12448     id_19 2002-03-13  209.252845       89       42\n",
       "12449     id_19 2002-03-14  299.987801       89       42\n",
       "12450     id_19 2002-03-15  387.550536       89       42\n",
       "\n",
       "[12451 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_static_features = 2\n",
    "\n",
    "series_with_statics = generate_daily_series(n_series, min_length, max_length, n_static_features)\n",
    "series_with_statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_static_features):\n",
    "    assert all(series_with_statics.groupby('unique_id')[f'static_{i}'].nunique() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `equal_ends=False` (the default) then every serie has a different end date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert series_with_statics.groupby('unique_id')['ds'].max().nunique() > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have all of them end at the same date by specifying `equal_ends=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_equal_ends = generate_daily_series(n_series, min_length, max_length, equal_ends=True)\n",
    "\n",
    "assert series_equal_ends.groupby('unique_id')['ds'].max().nunique() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_prices_for_series(series: pd.DataFrame, horizon: int = 7, seed: int = 0) -> pd.DataFrame:\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_last_dates = series.groupby('unique_id')['ds'].max().nunique()\n",
    "    if unique_last_dates > 1:\n",
    "        raise ValueError('series must have equal ends.')\n",
    "    day_offset = pd.tseries.frequencies.Day()\n",
    "    starts_ends = series.groupby('unique_id')['ds'].agg([min, max])\n",
    "    dfs = []\n",
    "    for idx, (start, end) in starts_ends.iterrows():\n",
    "        product_df = pd.DataFrame(\n",
    "            {\n",
    "                'unique_id': idx,\n",
    "                'price': rng.rand((end - start).days + 1 + horizon),\n",
    "            },\n",
    "            index=pd.date_range(start, end + horizon * day_offset, name='ds'),\n",
    "        )\n",
    "        dfs.append(product_df)\n",
    "    prices_catalog = pd.concat(dfs).reset_index()\n",
    "    return prices_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>id_00</td>\n",
       "      <td>0.548814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-10-06</td>\n",
       "      <td>id_00</td>\n",
       "      <td>0.715189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-10-07</td>\n",
       "      <td>id_00</td>\n",
       "      <td>0.602763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-10-08</td>\n",
       "      <td>id_00</td>\n",
       "      <td>0.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-10-09</td>\n",
       "      <td>id_00</td>\n",
       "      <td>0.423655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>id_19</td>\n",
       "      <td>0.288027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>id_19</td>\n",
       "      <td>0.846305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>id_19</td>\n",
       "      <td>0.791284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>id_19</td>\n",
       "      <td>0.578636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>id_19</td>\n",
       "      <td>0.288589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds unique_id     price\n",
       "0    2000-10-05     id_00  0.548814\n",
       "1    2000-10-06     id_00  0.715189\n",
       "2    2000-10-07     id_00  0.602763\n",
       "3    2000-10-08     id_00  0.544883\n",
       "4    2000-10-09     id_00  0.423655\n",
       "...         ...       ...       ...\n",
       "5009 2001-05-17     id_19  0.288027\n",
       "5010 2001-05-18     id_19  0.846305\n",
       "5011 2001-05-19     id_19  0.791284\n",
       "5012 2001-05-20     id_19  0.578636\n",
       "5013 2001-05-21     id_19  0.288589\n",
       "\n",
       "[5014 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_for_prices = generate_daily_series(20, n_static_features=2, equal_ends=True)\n",
    "series_for_prices.rename(columns={'static_1': 'product_id'}, inplace=True)\n",
    "prices_catalog = generate_prices_for_series(series_for_prices, horizon=7)\n",
    "prices_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(set(prices_catalog['unique_id']), set(series_for_prices['unique_id']))\n",
    "test_fail(lambda: generate_prices_for_series(series), contains='equal ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def single_split(\n",
    "    df: DataFrame,\n",
    "    i_window: int,    \n",
    "    n_windows: int,\n",
    "    h: int,\n",
    "    id_col: str,\n",
    "    time_col: str,\n",
    "    freq: Union[pd.offsets.BaseOffset, int],\n",
    "    max_dates: Series,  \n",
    "    step_size: Optional[int] = None,\n",
    "    input_size: Optional[int] = None,\n",
    ") -> Tuple[DataFrame, Series, Series]:\n",
    "    if step_size is None:\n",
    "        step_size = h\n",
    "    test_size = h + step_size * (n_windows - 1)\n",
    "    offset = test_size - i_window * step_size\n",
    "    train_ends = offset_dates(max_dates, freq, -offset)\n",
    "    valid_ends = offset_dates(train_ends, freq, h)\n",
    "    train_mask = df[time_col].le(train_ends)\n",
    "    valid_mask = df[time_col].gt(train_ends) & df[time_col].le(valid_ends)    \n",
    "    if input_size is not None:\n",
    "        train_starts = offset_dates(train_ends, freq, -input_size)\n",
    "        train_mask &= df[time_col].gt(train_starts)\n",
    "    train_sizes = group_by(train_mask, df[id_col], maintain_order=True).sum()\n",
    "    if isinstance(train_sizes, pd.Series):\n",
    "        train_sizes = train_sizes.reset_index()\n",
    "    zeros_mask = train_sizes[time_col].eq(0)   \n",
    "    if zeros_mask.all():\n",
    "        raise ValueError(\n",
    "            'All series are too short for the cross validation settings, '\n",
    "            f'at least {offset + 1} samples are required.\\n'\n",
    "            'Please reduce `n_windows` or `h`.'\n",
    "        )\n",
    "    elif zeros_mask.any():\n",
    "        ids = filter_with_mask(train_sizes[id_col], zeros_mask)\n",
    "        warnings.warn(\n",
    "            'The following series are too short for the window '\n",
    "            f'and will be dropped: {reprlib.repr(list(ids))}'\n",
    "        )\n",
    "        isin_attr = 'isin' if isinstance(df, pd.DataFrame) else 'is_in'\n",
    "        dropped_ids = getattr(df[id_col], isin_attr)(ids)\n",
    "        valid_mask &= ~dropped_ids\n",
    "    proc = DataFrameProcessor(id_col, '', '')\n",
    "    last_idx_per_serie = proc.counts_by_id(df)['counts'].to_numpy().cumsum() - 1\n",
    "    cutoff_dates = take_rows(train_ends, last_idx_per_serie)\n",
    "    if isinstance(cutoff_dates, pd.Series):\n",
    "        cutoff_dates = cutoff_dates.reset_index()[time_col]\n",
    "    cutoffs = type(df)({\n",
    "        id_col: train_sizes[id_col],\n",
    "        'cutoff': cutoff_dates,\n",
    "    })\n",
    "    return cutoffs, train_mask, valid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def backtest_splits(\n",
    "    df: DataFrame,\n",
    "    n_windows: int,\n",
    "    h: int,\n",
    "    id_col: str,\n",
    "    time_col: str,\n",
    "    freq: Union[pd.offsets.BaseOffset, int],\n",
    "    step_size: Optional[int] = None,\n",
    "    input_size: Optional[int] = None,\n",
    ") -> Generator[Tuple[DataFrame, DataFrame, DataFrame], None, None]:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        max_dates = df.groupby(id_col, observed=True)[time_col].transform('max')\n",
    "    else:\n",
    "        max_dates = df.select(pl.col(time_col).max().over(id_col))[time_col]\n",
    "    for i in range(n_windows):\n",
    "        cutoffs, train_mask, valid_mask = single_split(\n",
    "            df,\n",
    "            i_window=i,\n",
    "            n_windows=n_windows,\n",
    "            h=h,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            freq=freq,\n",
    "            max_dates=max_dates,\n",
    "            step_size=step_size,\n",
    "            input_size=input_size,\n",
    "        )\n",
    "        train = filter_with_mask(df, train_mask)\n",
    "        valid = filter_with_mask(df, valid_mask)\n",
    "        yield cutoffs, train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "short_series = generate_daily_series(100, max_length=50)\n",
    "backtest_results = list(\n",
    "    backtest_splits(\n",
    "        short_series,\n",
    "        n_windows=1,\n",
    "        h=49,\n",
    "        id_col='unique_id',\n",
    "        time_col='ds',\n",
    "        freq=pd.offsets.Day(),\n",
    "    )\n",
    ")[0]\n",
    "test_fail(\n",
    "    lambda: list(\n",
    "        backtest_splits(\n",
    "            short_series,\n",
    "            n_windows=1,\n",
    "            h=50,\n",
    "            id_col='unique_id',\n",
    "            time_col='ds',\n",
    "            freq=pd.offsets.Day(),\n",
    "        )\n",
    "    ),\n",
    "    contains='at least 51 samples are required'\n",
    ")\n",
    "some_short_series = generate_daily_series(100, min_length=20, max_length=100)\n",
    "with warnings.catch_warnings(record=True) as issued_warnings:\n",
    "    warnings.simplefilter('always', UserWarning)\n",
    "    splits = list(\n",
    "        backtest_splits(\n",
    "            some_short_series,\n",
    "            n_windows=1,\n",
    "            h=50,\n",
    "            id_col='unique_id',\n",
    "            time_col='ds',\n",
    "            freq=pd.offsets.Day(),\n",
    "        )\n",
    "    )\n",
    "    assert any('will be dropped' in str(w.message) for w in issued_warnings)\n",
    "short_series_int = short_series.copy()\n",
    "short_series_int['ds'] = short_series.groupby('unique_id').transform('cumcount')\n",
    "backtest_int_results = list(\n",
    "    backtest_splits(\n",
    "        short_series_int,\n",
    "        n_windows=1,\n",
    "        h=40,\n",
    "        id_col='unique_id',\n",
    "        time_col='ds',\n",
    "        freq=1\n",
    "    )\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "max_dates = series.groupby('unique_id')['ds'].max()\n",
    "day_offset = pd.offsets.Day()\n",
    "\n",
    "def test_backtest_splits(df, n_windows, h, step_size, input_size):\n",
    "    common_kwargs = dict(\n",
    "        n_windows=n_windows,\n",
    "        h=h,\n",
    "        id_col='unique_id',\n",
    "        time_col='ds',\n",
    "        freq=pd.offsets.Day(), \n",
    "        step_size=step_size,\n",
    "        input_size=input_size,        \n",
    "    )\n",
    "    permuted_df = df.sample(frac=1.0)\n",
    "    splits = backtest_splits(df, **common_kwargs)\n",
    "    splits_on_permuted = list(backtest_splits(permuted_df, **common_kwargs))\n",
    "    if step_size is None:\n",
    "        step_size = h\n",
    "    test_size = h + step_size * (n_windows - 1)\n",
    "    for window, (cutoffs, train, valid) in enumerate(splits):\n",
    "        offset = test_size - window * step_size\n",
    "        expected_max_train_dates = max_dates - day_offset * offset\n",
    "        max_train_dates = train.groupby('unique_id')['ds'].max()\n",
    "        pd.testing.assert_series_equal(max_train_dates, expected_max_train_dates)\n",
    "        pd.testing.assert_frame_equal(cutoffs, max_train_dates.rename('cutoff').reset_index())\n",
    "        \n",
    "        if input_size is not None:\n",
    "            expected_min_train_dates = expected_max_train_dates - day_offset * (input_size - 1)\n",
    "            min_train_dates = train.groupby('unique_id')['ds'].min()\n",
    "            pd.testing.assert_series_equal(min_train_dates, expected_min_train_dates)\n",
    "\n",
    "        expected_min_valid_dates = expected_max_train_dates + day_offset\n",
    "        min_valid_dates = valid.groupby('unique_id')['ds'].min()\n",
    "        pd.testing.assert_series_equal(min_valid_dates, expected_min_valid_dates)\n",
    "\n",
    "        expected_max_valid_dates = expected_max_train_dates + day_offset * h\n",
    "        max_valid_dates = valid.groupby('unique_id')['ds'].max()\n",
    "        pd.testing.assert_series_equal(max_valid_dates, expected_max_valid_dates)\n",
    "\n",
    "        if window == n_windows - 1:\n",
    "            pd.testing.assert_series_equal(max_valid_dates, max_dates)\n",
    "\n",
    "        _, permuted_train, permuted_valid = splits_on_permuted[window]            \n",
    "        pd.testing.assert_frame_equal(train, permuted_train.sort_values(['unique_id', 'ds']))\n",
    "    pd.testing.assert_frame_equal(valid, permuted_valid.sort_values(['unique_id', 'ds']))\n",
    "\n",
    "for step_size in (None, 1, 2):\n",
    "    for input_size in (None, 4):\n",
    "        test_backtest_splits(series, n_windows=3, h=14, step_size=step_size, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PredictionIntervals:\n",
    "    \"\"\"Class for storing prediction intervals metadata information.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_windows: int = 2,\n",
    "        h: int = 1,\n",
    "        method: str = 'conformal_distribution',\n",
    "    ):\n",
    "        if n_windows < 2:\n",
    "            raise ValueError('You need at least two windows to compute conformal intervals')\n",
    "        allowed_methods = ['conformal_error', 'conformal_distribution']            \n",
    "        if method not in allowed_methods:\n",
    "            raise ValueError(f'method must be one of {allowed_methods}')\n",
    "        self.n_windows = n_windows\n",
    "        self.h = h\n",
    "        self.method = method\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PredictionIntervals(n_windows={self.n_windows}, h={self.h}, method='{self.method}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _ensure_shallow_copy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    from packaging.version import Version\n",
    "    \n",
    "    if Version(pd.__version__) < Version(\"1.4\"):\n",
    "        # https://github.com/pandas-dev/pandas/pull/43406\n",
    "        df = df.copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class _ShortSeriesException(Exception):\n",
    "    def __init__(self, idxs):\n",
    "        self.idxs = idxs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
