{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddd9d1-7e77-41bb-b31e-4c772d56f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4dba5-efb3-4faf-9e06-7f538f26b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp distributed.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71c521-3dc2-4c2f-ba64-c81fc8c32995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3f741-f46c-4d58-b254-01881e498175",
   "metadata": {},
   "source": [
    "# Distributed core\n",
    "\n",
    "> Building blocks for the distributed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58158d-ca82-4802-bd21-79d436fa2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import operator\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, Future, default_client, futures_of, wait\n",
    "\n",
    "from mlforecast.core import preprocessing_flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa57b6-784e-44de-b18c-515db33ba7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nbdev import *\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd35b6-c60d-4223-9442-bcf69cb334bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def distributed_preprocess(data: dd.DataFrame,\n",
    "                           config: Dict,\n",
    "                           client: Optional[Client] = None,\n",
    "                           flow: Callable = preprocessing_flow) -> Tuple[List[Future], dd.DataFrame]:\n",
    "    \"\"\"Applies `flow(partition, **config)` to every partition of `data`.\n",
    "    \n",
    "    Returns futures pointing to the `TimeSeries` objects generated from each partition\n",
    "    and a dask dataframe for training a distributed model.\"\"\"\n",
    "    client = client or default_client()\n",
    "    \n",
    "    data = client.persist(data)\n",
    "    wait(data)\n",
    "    partition_futures = futures_of(data)\n",
    "    results_futures = client.map(flow, partition_futures, **config)\n",
    "    \n",
    "    # pure is here in case we modify in-place one of the TimeSeries and want to recompute it.\n",
    "    ts_futures = client.map(operator.itemgetter(0), results_futures, pure=False)\n",
    "    \n",
    "    df_futures = client.map(operator.itemgetter(1), results_futures)\n",
    "    meta = client.submit(lambda x: x.head(), df_futures[0]).result()\n",
    "    train_ddf = dd.from_delayed(df_futures, meta=meta)\n",
    "    \n",
    "    return ts_futures, train_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32daa170-0df5-4288-99a5-43fbd7b3e790",
   "metadata": {},
   "source": [
    "The `distributed_preprocess` takes a `dask.dataframe` and applies the preprocessing function (`preprocessing_flow` by default) to each partition independently, generating as many `TimeSeries` objects as there are partitions in the dataframe and another `dask.dataframe` with the features included in order to perform distributed training using `dask`.\n",
    "\n",
    "It is recommended that you have as many partitions as you have workers, so each worker performs one preprocessing task (optionally using multi-threading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf1831-da17-4ef4-a6ed-e3328f919ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a3dee-9251-4030-b999-ebad235980c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(100, n_static_features=2)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52b4be-a2a0-4c52-9dd9-c97138e41efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_series = dd.from_pandas(series, npartitions=2)\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763abd7-80b8-4a59-9979-197c27471793",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    freq='D',\n",
    "    lags=[7, 14],\n",
    "    lag_transforms={\n",
    "        7: [(rolling_mean, 7)],\n",
    "        14: [(rolling_mean, 7)],\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    num_threads=2,\n",
    "    keep_last_n=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad1a7a-65bf-451e-a71a-ad99a64871d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_futures, train_ddf = distributed_preprocess(partitioned_series, config)\n",
    "\n",
    "local_ts, local_df = preprocessing_flow(series, **config)\n",
    "assert train_ddf.compute().equals(local_df)\n",
    "next_feats_futures = client.map(lambda x: x.update_features(), ts_futures)\n",
    "next_feats = pd.concat(client.gather(next_feats_futures))\n",
    "assert next_feats.equals(local_ts.update_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8d9fb-68f4-4343-889c-f2e8796bd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
