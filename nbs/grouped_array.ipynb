{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2247f-be0c-4a71-bf79-d260988e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp grouped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088aa3-7a4e-4c29-98fe-940277d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import TYPE_CHECKING, Callable, Tuple, Union\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from window_ops.shift import shift_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b959e47-a72b-4316-8349-6fd61a03c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@njit(nogil=True)\n",
    "def _transform_series(data, indptr, updates_only, lag, func, *args) -> np.ndarray:\n",
    "    \"\"\"Shifts every group in `data` by `lag` and computes `func(shifted, *args)`.\n",
    "    \n",
    "    If `updates_only=True` only last value of the transformation for each group is returned, \n",
    "    otherwise the full transformation is returned\"\"\"\n",
    "    n_series = len(indptr) - 1\n",
    "    if updates_only:\n",
    "        out = np.empty_like(data[:n_series])\n",
    "        for i in range(n_series):\n",
    "            lagged = shift_array(data[indptr[i] : indptr[i + 1]], lag)\n",
    "            out[i] = func(lagged, *args)[-1]        \n",
    "    else:\n",
    "        out = np.empty_like(data)\n",
    "        for i in range(n_series):\n",
    "            lagged = shift_array(data[indptr[i] : indptr[i + 1]], lag)\n",
    "            out[indptr[i] : indptr[i + 1]] = func(lagged, *args)\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def _diff(x, lag):\n",
    "    y = x.copy()\n",
    "    for i in range(lag):\n",
    "        y[i] = np.nan\n",
    "    for i in range(lag, x.size):\n",
    "        y[i] = x[i] - x[i - lag]\n",
    "    return y\n",
    "\n",
    "\n",
    "@njit\n",
    "def _apply_difference(data, indptr, new_data, new_indptr, d):\n",
    "    n_series = len(indptr) - 1\n",
    "    for i in range(n_series):\n",
    "        new_data[new_indptr[i] : new_indptr[i+1]] = data[indptr[i + 1] - d : indptr[i + 1]]\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        data[sl] = _diff(data[sl], d)\n",
    "\n",
    "@njit\n",
    "def _restore_difference(preds, data, indptr, d):\n",
    "    n_series = len(indptr) - 1\n",
    "    h = len(preds) // n_series\n",
    "    for i in range(n_series):\n",
    "        s = data[indptr[i] : indptr[i + 1]]\n",
    "        for j in range(min(h, d)):\n",
    "            preds[i * h + j] += s[j]\n",
    "        for j in range(d, h):\n",
    "            preds[i * h + j] += preds[i * h + j - d]\n",
    "\n",
    "\n",
    "@njit\n",
    "def _expand_target(data, indptr, max_horizon):\n",
    "    out = np.empty((data.size, max_horizon), dtype=data.dtype)\n",
    "    n_series = len(indptr) - 1\n",
    "    n = 0\n",
    "    for i in range(n_series):\n",
    "        serie = data[indptr[i] : indptr[i+1]]\n",
    "        for j in range(serie.size):\n",
    "            upper = min(serie.size - j, max_horizon)\n",
    "            for k in range(upper):\n",
    "                out[n, k] = serie[j + k]\n",
    "            for k in range(upper, max_horizon):\n",
    "                out[n, k] = np.nan\n",
    "            n += 1\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def _append_one(data: np.ndarray, indptr: np.ndarray, new: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Append each value of new to each group in data formed by indptr.\"\"\"\n",
    "    n_series = len(indptr) - 1\n",
    "    new_data = np.empty(data.size + new.size, dtype=data.dtype)\n",
    "    new_indptr = indptr.copy()\n",
    "    new_indptr[1:] += np.arange(1, n_series + 1)\n",
    "    for i in range(n_series):\n",
    "        prev_slice = slice(indptr[i], indptr[i + 1])\n",
    "        new_slice = slice(new_indptr[i], new_indptr[i + 1] - 1)\n",
    "        new_data[new_slice] = data[prev_slice]\n",
    "        new_data[new_indptr[i + 1] - 1] = new[i]\n",
    "    return new_data, new_indptr\n",
    "\n",
    "@njit\n",
    "def _append_several(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    new_sizes: np.ndarray,\n",
    "    new_values: np.ndarray,\n",
    "    new_groups: np.ndarray,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    new_data = np.empty(data.size + new_values.size, dtype=data.dtype)\n",
    "    new_indptr = np.empty(new_sizes.size + 1, dtype=indptr.dtype)\n",
    "    new_indptr[0] = 0\n",
    "    old_indptr_idx = 0\n",
    "    new_vals_idx = 0\n",
    "    for i, is_new in enumerate(new_groups):\n",
    "        new_size = new_sizes[i]\n",
    "        if is_new:\n",
    "            old_size = 0\n",
    "        else:\n",
    "            prev_slice = slice(indptr[old_indptr_idx], indptr[old_indptr_idx + 1])\n",
    "            old_indptr_idx += 1             \n",
    "            old_size = prev_slice.stop - prev_slice.start           \n",
    "            new_size += old_size\n",
    "            new_data[new_indptr[i] : new_indptr[i] + old_size] = data[prev_slice] \n",
    "        new_indptr[i + 1] = new_indptr[i] + new_size\n",
    "        new_data[new_indptr[i] + old_size : new_indptr[i + 1]] = new_values[new_vals_idx : new_vals_idx + new_sizes[i]]\n",
    "        new_vals_idx += new_sizes[i]\n",
    "    return new_data, new_indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c285b-96db-489b-a2b7-41ae5fb6b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data = np.arange(5)\n",
    "indptr = np.array([0, 2, 5])\n",
    "new_sizes = np.array([0, 2, 1])\n",
    "new_values = np.array([6, 7, 5])\n",
    "new_groups = np.array([False, True, False])\n",
    "new_data, new_indptr = _append_several(data, indptr, new_sizes, new_values, new_groups)\n",
    "np.testing.assert_equal(\n",
    "    new_data,\n",
    "    np.array([0, 1, 6, 7, 2, 3, 4, 5]),\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    new_indptr,\n",
    "    np.array([0, 2, 4, 8]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e355953-167a-48d4-9306-0299c913028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GroupedArray:\n",
    "    \"\"\"Array made up of different groups. Can be thought of (and iterated) as a list of arrays.\n",
    "    \n",
    "    All the data is stored in a single 1d array `data`.\n",
    "    The indices for the group boundaries are stored in another 1d array `indptr`.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: np.ndarray, indptr: np.ndarray):\n",
    "        self.data = data\n",
    "        self.indptr = indptr\n",
    "        self.ngroups = len(indptr) - 1\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.ngroups\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        return self.data[self.indptr[idx] : self.indptr[idx + 1]]   \n",
    "\n",
    "    def __setitem__(self, idx: int, vals: np.ndarray):\n",
    "        if self[idx].size != vals.size:\n",
    "            raise ValueError(f'vals must be of size {self[idx].size}')\n",
    "        self[idx][:] = vals\n",
    "        \n",
    "    def take(self, idxs: np.ndarray) -> 'GroupedArray':\n",
    "        ranges = [\n",
    "            range(self.indptr[i], self.indptr[i + 1]) for i in idxs\n",
    "        ]\n",
    "        items = [self.data[rng] for rng in ranges]\n",
    "        sizes = np.array([item.size for item in items])\n",
    "        data = np.hstack(items)\n",
    "        indptr = np.append(0, sizes.cumsum())\n",
    "        return GroupedArray(data, indptr)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_sorted_df(cls, df: 'pd.DataFrame', id_col: str, target_col: str) -> 'GroupedArray':\n",
    "        sizes = df.groupby(id_col, observed=True).size().values\n",
    "        indptr = np.append(0, sizes.cumsum())\n",
    "        data = df[target_col].values.copy()\n",
    "        if data.dtype not in (np.float32, np.float64):\n",
    "            # since all transformations generate nulls, we need a float dtype\n",
    "            data = data.astype(np.float32)        \n",
    "        return cls(data, indptr)\n",
    "    \n",
    "    def transform_series(\n",
    "        self,\n",
    "        updates_only: bool,\n",
    "        lag: int,\n",
    "        func: Callable,\n",
    "        *args\n",
    "    ) -> np.ndarray:\n",
    "        return _transform_series(self.data, self.indptr, updates_only, lag, func, *args)\n",
    "\n",
    "    def restore_difference(self, preds: np.ndarray, d: int):\n",
    "        _restore_difference(preds, self.data, self.indptr, d)\n",
    "        \n",
    "    def expand_target(self, max_horizon: int) -> np.ndarray:\n",
    "        return _expand_target(self.data, self.indptr, max_horizon)\n",
    "        \n",
    "    def take_from_groups(self, idx: Union[int, slice]) -> 'GroupedArray':\n",
    "        \"\"\"Takes `idx` from each group in the array.\"\"\"\n",
    "        ranges = [\n",
    "            range(self.indptr[i], self.indptr[i + 1])[idx] for i in range(self.ngroups)\n",
    "        ]\n",
    "        items = [self.data[rng] for rng in ranges]\n",
    "        sizes = np.array([item.size for item in items])\n",
    "        data = np.hstack(items)\n",
    "        indptr = np.append(0, sizes.cumsum())\n",
    "        return GroupedArray(data, indptr)\n",
    "        \n",
    "    def append(self, new: np.ndarray) -> 'GroupedArray':\n",
    "        \"\"\"Appends each element of `new` to each existing group. Returns a copy.\"\"\"\n",
    "        if new.size != self.ngroups:\n",
    "            raise ValueError(f'new must be of size {self.ngroups}')\n",
    "        new_data, new_indptr = _append_one(self.data, self.indptr, new)\n",
    "        return GroupedArray(new_data, new_indptr)\n",
    "    \n",
    "    def append_several(\n",
    "        self, new_sizes: np.ndarray, new_values: np.ndarray, new_groups: np.ndarray\n",
    "    ) -> 'GroupedArray':\n",
    "        new_data, new_indptr = _append_several(\n",
    "            self.data, self.indptr, new_sizes, new_values, new_groups\n",
    "        )\n",
    "        return GroupedArray(new_data, new_indptr)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(ndata={self.data.size}, ngroups={self.ngroups})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ee445-0915-41e7-a0f8-fc8c5ffefffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd409c-b1da-493d-ad6a-add2d81ac38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `GroupedArray` is used internally for storing the series values and performing transformations.\n",
    "data = np.arange(10, dtype=np.float32)\n",
    "indptr = np.array([0, 2, 10])  # group 1: [0, 1], group 2: [2..9]\n",
    "ga = GroupedArray(data, indptr)\n",
    "test_eq(len(ga), 2)\n",
    "test_eq(str(ga), 'GroupedArray(ndata=10, ngroups=2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cb087-2999-4813-a906-297a1c790801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the groups\n",
    "ga_iter = iter(ga)\n",
    "np.testing.assert_equal(next(ga_iter), np.array([0, 1]))\n",
    "np.testing.assert_equal(next(ga_iter), np.arange(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d459b35-c452-4619-b088-4a111dc55f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last two observations from every group\n",
    "last_2 = ga.take_from_groups(slice(-2, None))\n",
    "np.testing.assert_equal(last_2.data, np.array([0, 1, 8, 9]))\n",
    "np.testing.assert_equal(last_2.indptr, np.array([0, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3da09-33ef-4026-95c8-ed8d05f87e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last four observations from every group. Note that since group 1 only has two elements, only these are returned.\n",
    "last_4 = ga.take_from_groups(slice(-4, None))\n",
    "np.testing.assert_equal(last_4.data, np.array([0, 1, 6, 7, 8, 9]))\n",
    "np.testing.assert_equal(last_4.indptr, np.array([0, 2, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b952d65-0afb-49b4-b1b1-f79c2b2599e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific subset of groups\n",
    "indptr = np.array([0, 2, 4, 7, 10])\n",
    "ga2 = GroupedArray(data, indptr)\n",
    "subset = ga2.take([0, 2])\n",
    "np.testing.assert_allclose(subset[0].data, ga2[0].data)\n",
    "np.testing.assert_allclose(subset[1].data, ga2[2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa62eab-f0f8-4a80-9dad-55dcee40681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The groups are [0, 1], [2, ..., 9]. expand_target(2) should take rolling pairs of them and fill with nans when there aren't enough\n",
    "np.testing.assert_equal(\n",
    "    ga.expand_target(2),\n",
    "    np.array([\n",
    "        [0, 1],\n",
    "        [1, np.nan],\n",
    "        [2, 3],\n",
    "        [3, 4],\n",
    "        [4, 5],\n",
    "        [5, 6],\n",
    "        [6, 7],\n",
    "        [7, 8],\n",
    "        [8, 9],\n",
    "        [9, np.nan]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6bbab-482f-495d-9a5d-567dc855997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to append new values that don't match the number of groups\n",
    "test_fail(lambda: ga.append(np.array([1., 2., 3.])), contains='new must be of size 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb59d16-6430-4903-82a2-dad5ab2b735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __setitem__\n",
    "new_vals = np.array([10, 11])\n",
    "ga[0] = new_vals\n",
    "np.testing.assert_equal(ga.data, np.append(new_vals, np.arange(2, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
