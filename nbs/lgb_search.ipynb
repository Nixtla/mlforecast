{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb976f-eafc-4236-8a27-02e142948574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp lgb_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cceedc-91c9-4d75-bd51-32ce33829ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948c2e2-c5ee-40fe-90d3-dab34d7d6bbf",
   "metadata": {},
   "source": [
    "# LightGBM search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f556b78-d988-4bbe-8d9a-c52b3fe5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import copy\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "from mlforecast import Forecast\n",
    "from mlforecast.utils import backtest_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc238-1d21-4e47-bda7-1ac1a8665395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class EarlyStopException(BaseException):\n",
    "    ...\n",
    "\n",
    "def _update_and_predict(fcst, n, h, valid):\n",
    "    for _ in range(n):\n",
    "        fcst.models_[0].update()\n",
    "    preds = fcst.predict(h)\n",
    "    preds = preds.merge(valid, on=['unique_id', 'ds'])\n",
    "    preds['sq_err'] = (preds['Booster'] - preds['y']) ** 2\n",
    "    rmse = preds.groupby('unique_id')['sq_err'].mean().pow(0.5).mean()\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dd93f-7d13-4905-9fa6-727e9b9c8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LGBMSearch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[str] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek\n",
    "        num_threads: int = 1,  # number of threads to use when computing the predictions of each window.\n",
    "    ):\n",
    "        self.num_threads = num_threads\n",
    "        self.fcst = Forecast([], freq, lags, lag_transforms, date_features, 1)\n",
    "        \n",
    "    def _should_stop(self, hist, early_stopping_evals, early_stopping_pct):\n",
    "        if len(hist) < early_stopping_evals + 1:\n",
    "            return False\n",
    "        # [8 5 4] (8 - 4) / 8 = 1 - 4 / 8 = 0.5\n",
    "        improvement_pct = 1 - hist[-1][1] / hist[-(early_stopping_evals + 1)][1]\n",
    "        return improvement_pct < early_stopping_pct\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: pd.DataFrame,  # time series\n",
    "        n_windows: int,  # number of windows to evaluate\n",
    "        window_size: int,  # test size in each window\n",
    "        params: Dict[str, Any] = {},  # lightgbm parameters\n",
    "        id_col: str = 'index',  # column that identifies each serie, can also be the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,  # column names of the features that don't change in time\n",
    "        dropna: bool = True,  # drop rows with missing values created by lags\n",
    "        keep_last_n: Optional[int] = None,  # keep only this many observations of each serie for computing the updates\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        weights: Optional[np.ndarray] = None,  # weight for each window\n",
    "        eval_every: int = 10,  # number of iterations to train before evaluating the full window\n",
    "        fit_on_all: bool = True,  # return model fitted on all data\n",
    "        verbose_eval: bool = True,  # print evaluation metrics\n",
    "        early_stopping_evals: int = 2,  # stop if the score doesn't improve in these many evaluations\n",
    "        early_stopping_pct: float = 0.01,  # score must improve at least in this percentage to keep training\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn        \n",
    "    ):\n",
    "        if eval_every <= 0:\n",
    "            raise ValueError(\n",
    "                \"eval_every should be > 0. If you don't want to evaluate the complete horizon use \"\n",
    "                \"Forecast.backtest instead.\"\n",
    "            )\n",
    "        if weights is None:\n",
    "            weights = np.full(n_windows, 1 / n_windows)        \n",
    "        elif len(weights) != n_windows:\n",
    "            raise ValueError('Must specify as many weights as the number of windows')\n",
    "        else:\n",
    "            weights = np.asarray(weights)\n",
    "            \n",
    "        orig = data.copy(deep=False)\n",
    "        if id_col != 'index':\n",
    "            data = data.set_index(id_col)\n",
    "        data = data.rename(columns={time_col: 'ds', target_col: 'y'}, copy=False)\n",
    "        data.index.name = 'unique_id'\n",
    "        \n",
    "        if np.issubdtype(data['ds'].dtype.type, np.integer):\n",
    "            freq = 1\n",
    "        else:\n",
    "            freq = self.fcst.freq\n",
    "        fcsts = []\n",
    "        valids = []\n",
    "        for _, train, valid in backtest_splits(data, n_windows, window_size, freq):\n",
    "            cv_fcst = copy.deepcopy(self.fcst)\n",
    "            prep = cv_fcst.preprocess(train, static_features=static_features)\n",
    "            valids.append(valid)\n",
    "            ds = lgb.Dataset(prep.drop(columns=['ds', 'y']), prep['y'])\n",
    "            bst = lgb.Booster(params, ds)\n",
    "            cv_fcst.models_ = [bst]\n",
    "            fcsts.append(cv_fcst)\n",
    "\n",
    "        hist = []\n",
    "        n_iter = lgb.basic._choose_param_value('num_iterations', params, 100)['num_iterations']\n",
    "        rmses = np.empty(n_windows)\n",
    "        \n",
    "        params['num_threads'] = os.cpu_count() // self.num_threads\n",
    "        if self.num_threads == 1:\n",
    "            try:\n",
    "                for i in range(0, n_iter, eval_every):\n",
    "                    for j, (fcst, valid) in enumerate(zip(fcsts, valids)):\n",
    "                        rmses[j] = _update_and_predict(fcst, eval_every, window_size, valid)\n",
    "                    rmse = rmses @ weights\n",
    "                    rounds = eval_every + i\n",
    "                    hist.append((rounds, rmse))\n",
    "                    if verbose_eval:\n",
    "                        print(f'[{rounds:,d}] RMSE: {rmse:,f}')                \n",
    "                    if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                        raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}')\n",
    "        else:\n",
    "            try:\n",
    "                with ThreadPoolExecutor(self.num_threads) as executor:\n",
    "                    for i in range(0, n_iter, eval_every):\n",
    "                        futures = []\n",
    "                        for fcst, valid in zip(fcsts, valids):\n",
    "                            future = executor.submit(_update_and_predict, fcst, eval_every, window_size, valid)\n",
    "                            futures.append(future)\n",
    "                        rmses[:] = [f.result() for f in futures]\n",
    "                        rmse = rmses @ weights\n",
    "                        rounds = eval_every + i\n",
    "                        hist.append((rounds, rmse))\n",
    "                        if verbose_eval:\n",
    "                            print(f'[{rounds:,d}] RMSE: {rmse:,f}')\n",
    "                        if self._should_stop(hist, early_stopping_evals, early_stopping_pct):\n",
    "                            raise EarlyStopException\n",
    "            except EarlyStopException:\n",
    "                print(f'Early stopping at round {rounds:,}.')\n",
    "            \n",
    "        if fit_on_all:\n",
    "            self.fcst.models = [lgb.LGBMRegressor(**params)]\n",
    "            self.fcst.fit(\n",
    "                orig,\n",
    "                id_col,\n",
    "                time_col,\n",
    "                target_col,\n",
    "                static_features,\n",
    "                dropna,\n",
    "                keep_last_n,\n",
    "            )\n",
    "        return hist\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,  # number of periods to predict in the future\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,  # future values for dynamic features\n",
    "        predict_fn: Optional[Callable] = None,  # custom function to compute predictions\n",
    "        **predict_fn_kwargs,  # additional arguments passed to predict_fn\n",
    "    ):\n",
    "        return self.fcst.predict(horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f82f1-a305-4be3-8f63-78dd38a6f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.utils import generate_daily_series\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean, seasonal_rolling_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9d1a-7c10-4b24-bf54-a0d1e765e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_daily_series(1_000, min_length=500, max_length=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921b826-e67f-4d53-8c3c-b85bf46efff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 3.250137\n",
      "[LightGBM] [Info] Start training from score 3.250088\n",
      "[10] RMSE: 1.219636\n",
      "[20] RMSE: 0.388444\n",
      "[30] RMSE: 0.166221\n",
      "[40] RMSE: 0.146804\n",
      "[50] RMSE: 0.144275\n",
      "[60] RMSE: 0.143951\n",
      "[70] RMSE: 0.143915\n",
      "Early stopping at round 70.\n",
      "CPU times: user 23.8 s, sys: 1.23 s, total: 25.1 s\n",
      "Wall time: 8.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 1.21963550280172),\n",
       " (20, 0.38844393451941606),\n",
       " (30, 0.1662208308025986),\n",
       " (40, 0.14680427658840745),\n",
       " (50, 0.1442752213372901),\n",
       " (60, 0.143951352761174),\n",
       " (70, 0.14391519107862275)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = LGBMSearch(\n",
    "    freq='D',\n",
    "    lags=[i + 1 for i in range(4)],\n",
    "    lag_transforms={\n",
    "        7 : [expanding_mean] + [(rolling_mean, 7)],\n",
    "        14: [expanding_mean] + [(rolling_mean, 14)],\n",
    "    },\n",
    "    num_threads=2,\n",
    ")\n",
    "%time search.fit(data, n_windows=2, window_size=14, params={'verbosity': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c23a2-77da-4c80-8fbc-40e0bc474658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-03</td>\n",
       "      <td>0.247302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-04</td>\n",
       "      <td>1.249704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-05</td>\n",
       "      <td>2.251363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000</th>\n",
       "      <td>2001-11-06</td>\n",
       "      <td>3.249986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>1.250885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_998</th>\n",
       "      <td>2002-05-08</td>\n",
       "      <td>3.250413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-30</td>\n",
       "      <td>3.249795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-07-31</td>\n",
       "      <td>4.249041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-01</td>\n",
       "      <td>5.247625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_999</th>\n",
       "      <td>2002-08-02</td>\n",
       "      <td>6.249185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  LGBMRegressor\n",
       "unique_id                          \n",
       "id_000    2001-11-03       0.247302\n",
       "id_000    2001-11-04       1.249704\n",
       "id_000    2001-11-05       2.251363\n",
       "id_000    2001-11-06       3.249986\n",
       "id_001    2001-07-01       1.250885\n",
       "...              ...            ...\n",
       "id_998    2002-05-08       3.250413\n",
       "id_999    2002-07-30       3.249795\n",
       "id_999    2002-07-31       4.249041\n",
       "id_999    2002-08-01       5.247625\n",
       "id_999    2002-08-02       6.249185\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
