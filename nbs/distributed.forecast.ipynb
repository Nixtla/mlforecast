{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e077d-b6cc-4913-b206-77b652053251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp distributed.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7d947-ce42-40ec-8b54-623ec2189dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82054e-db3d-43ca-a4fe-c397e351ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import show_doc\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ec908-b746-4b80-8da3-fcb0039145d4",
   "metadata": {},
   "source": [
    "# Distributed forecast\n",
    "\n",
    "> Distributed pipeline encapsulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d15cd-5734-4585-aaca-de860e07f9ab",
   "metadata": {},
   "source": [
    "**This interface is only tested on Linux**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e3690-1951-487a-8c66-ba1b2cc01756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import warnings\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask.distributed import Client, default_client\n",
    "from sklearn.base import clone\n",
    "\n",
    "from mlforecast.core import TimeSeries\n",
    "from mlforecast.forecast import Forecast\n",
    "from mlforecast.distributed.core import DistributedTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55dee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b7a1a-716f-433c-ab86-8ec33f0f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DistributedForecast(Forecast):\n",
    "    \"\"\"Distributed pipeline encapsulation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        models,  # model or list of mlforecast.distributed.models\n",
    "        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M. Don't set if you're using integer times.\n",
    "        lags: List[int] = [],  # list of lags to use as features\n",
    "        lag_transforms: Dict[int, List[Tuple]] = {},  # list of transformations to apply to each lag\n",
    "        date_features: List[str] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek\n",
    "        num_threads: int = 1,  # number of threads to use when computing lag features\n",
    "        client: Optional[Client] = None  # dask client to use for computations\n",
    "    ):\n",
    "        if not isinstance(models, list):\n",
    "            models = [models]\n",
    "        self.models = models\n",
    "        self.client = client or default_client()\n",
    "        self.dts = DistributedTimeSeries(\n",
    "            TimeSeries(freq, lags, lag_transforms, date_features, num_threads),\n",
    "            self.client,\n",
    "        )\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'DistributedForecast(models=[{\", \".join(m.__class__.__name__ for m in self.models)}], '\n",
    "            f'freq={self.freq}, '\n",
    "            f'lag_features={list(self.dts._base_ts.transforms.keys())}, '\n",
    "            f'date_features={self.dts._base_ts.date_features}, '\n",
    "            f'num_threads={self.dts._base_ts.num_threads}, '\n",
    "            f'client={self.client})'\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def freq(self):\n",
    "        return self.dts._base_ts.freq\n",
    "\n",
    "    def preprocess(\n",
    "        self,\n",
    "        data: dd.DataFrame,\n",
    "        id_col: str = 'unique_id',  # column that identifies each serie, it's recommended to have this as the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values        \n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None,        \n",
    "    ) -> dd.DataFrame:\n",
    "        \"\"\"Computes the transformations on each partition of `data` and\n",
    "        saves the required information for the forecasting step.\n",
    "        Returns a dask dataframe with the computed features.\"\"\"\n",
    "        if id_col in data:\n",
    "            warnings.warn('It is recommended to have id_col as the index, since setting the index is a slow operation.')\n",
    "            data = data.set_index(id_col)\n",
    "        return self.dts.fit_transform(data, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data: dd.DataFrame,\n",
    "        id_col: str = 'unique_id',  # column that identifies each serie, it's recommended to have this as the index.\n",
    "        time_col: str = 'ds',  # column with the timestamps\n",
    "        target_col: str = 'y',  # column with the series values\n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None) -> 'DistributedForecast':\n",
    "        \"\"\"Perform the preprocessing and fit the model.\"\"\"\n",
    "        train_ddf = self.preprocess(data, id_col, time_col, target_col, static_features, dropna, keep_last_n)\n",
    "        X, y = train_ddf.drop(columns=[time_col, target_col]), train_ddf[target_col]\n",
    "        self.fitted_models = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            model = clone(model)\n",
    "            model.client = self.client\n",
    "            self.fitted_models.append(model.fit(X, y))\n",
    "        return self\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,\n",
    "        predict_fn: Optional[Callable] = None,\n",
    "        **predict_fn_kwargs,\n",
    "    ) -> dd.DataFrame:\n",
    "        return self.dts.predict(\n",
    "            [m.model_ for m in self.fitted_models], horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs\n",
    "        )\n",
    "    \n",
    "    predict.__doc__ = Forecast.predict.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b21c7-23fa-4628-be0d-4da2448fa382",
   "metadata": {},
   "source": [
    "The `DistributedForecast` class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009c1fe-caba-4412-be41-69588a512bbf",
   "metadata": {},
   "source": [
    "## Example\n",
    "This shows an example with simulated data, for a real world example in a remote cluster you can check the [M5 distributed example](https://www.kaggle.com/lemuz90/m5-mlforecast-distributed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc621d-43b8-4160-a694-08d3259e202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "from mlforecast.utils import backtest_splits, generate_daily_series, generate_prices_for_series\n",
    "from mlforecast.distributed.models.lgb import LGBMForecast\n",
    "from mlforecast.distributed.models.xgb import XGBForecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a9b623-af02-4acb-9d09-cda1debead4e",
   "metadata": {},
   "source": [
    "The different things that you need to use `DistributedForecast` (as opposed to `Forecast`) are:\n",
    "1. You need to set up a `dask.distributed.Client`. If this client is connected to a remote cluster then the process will run there.\n",
    "2. Your data needs to be a `dask.dataframe.DataFrame`.\n",
    "3. You need to use a model that implements distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479a531-60db-4c1e-ac28-189b8628d3ef",
   "metadata": {},
   "source": [
    "### Client setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8d3ef-d1f3-48da-b2dc-0579ea058626",
   "metadata": {},
   "source": [
    "Here we define a client that connects to a `dask.distributed.LocalCluster`, however it could be any other kind of cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea1b0f-f8d3-4be5-89fe-3dcbe00dff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cfccf-5898-4046-a6c8-091fec26f0e4",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "\n",
    "The data is given as a `dask.dataframe.DataFrame`, you need to make sure that each time serie is only in one partition and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set `num_threads=1` in `TimeSeries` to avoid having nested parallelism.\n",
    "\n",
    "The required input format is the same as for `Forecast`, except that it's a `dask.dataframe.DataFrame` instead of a `pandas.Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388b1cf-78cb-4cf9-b146-6d2043d4d3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_50</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 2 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                           ds        y static_0 static_1\n",
       "npartitions=2                                           \n",
       "id_00          datetime64[ns]  float64    int64    int64\n",
       "id_50                     ...      ...      ...      ...\n",
       "id_99                     ...      ...      ...      ...\n",
       "Dask Name: from_pandas, 2 tasks"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n",
    "partitioned_series = dd.from_pandas(series, npartitions=2)\n",
    "partitioned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b92d81-3a70-424d-81dc-8a995af1fb9c",
   "metadata": {},
   "source": [
    "### Models\n",
    "In order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using `dask`. The current implementations are in `LGBMForecast` and `XGBForecast` which are just wrappers around `lightgbm.dask.DaskLGBMRegressor` and `xgboost.dask.DaskXGBRegressor` that add a `model_` property to get the trained model from them and send it to every worker to perform the predictions step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8012f8-3325-41a2-8fb0-7eaa07a24b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [XGBForecast(random_state=0), LGBMForecast(random_state=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e1983-7235-4930-9b44-36c76e35be69",
   "metadata": {},
   "source": [
    "### Training\n",
    "Once we have our model and time series we instantiate a `DistributedForecast` with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d20c9-5ad7-42e8-a6b2-40d8005467bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedForecast(models=[XGBForecast, LGBMForecast], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=['dayofweek', 'month'], num_threads=1, client=<Client: 'tcp://127.0.0.1:35947' processes=2 threads=2, memory=15.50 GiB>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = DistributedForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a2f97-ea31-4359-b57b-bb5db5cdcfc2",
   "metadata": {},
   "source": [
    "Here where we say that:\n",
    "\n",
    "* Our series have daily frequency.\n",
    "* We want to use lag 7 as a feature\n",
    "* We want the lag transformations to be:\n",
    "   * expanding mean of the lag 1\n",
    "   * rolling mean of the lag 7 over a window of size 14\n",
    "* We want to use dayofweek and month as date features.\n",
    "* We want to perform the preprocessing and the forecasting steps using 1 thread, because we have 10 partitions and 2 workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5713b6a-1436-4554-878f-cc47bf87b2d0",
   "metadata": {},
   "source": [
    "From this point we have two options:\n",
    "\n",
    "1. Preprocess the data and fit our models using all of it.\n",
    "2. Preprocess the data and get it back as a dataframe to do some custom splitting or adding additional features. And then training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bff858-7e8a-49dd-963d-3acd6214e7a8",
   "metadata": {},
   "source": [
    "#### 1. Using all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882214c-877f-4f5c-af51-3b509fafc3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DistributedForecast.fit\n",
       "\n",
       ">      DistributedForecast.fit (data:dask.dataframe.core.DataFrame,\n",
       ">                               id_col:str='unique_id', time_col:str='ds',\n",
       ">                               target_col:str='y',\n",
       ">                               static_features:Optional[List[str]]=None,\n",
       ">                               dropna:bool=True,\n",
       ">                               keep_last_n:Optional[int]=None)\n",
       "\n",
       "Perform the preprocessing and fit the model.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, it's recommended to have this as the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| **Returns** | **DistributedForecast** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DistributedForecast.fit\n",
       "\n",
       ">      DistributedForecast.fit (data:dask.dataframe.core.DataFrame,\n",
       ">                               id_col:str='unique_id', time_col:str='ds',\n",
       ">                               target_col:str='y',\n",
       ">                               static_features:Optional[List[str]]=None,\n",
       ">                               dropna:bool=True,\n",
       ">                               keep_last_n:Optional[int]=None)\n",
       "\n",
       "Perform the preprocessing and fit the model.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, it's recommended to have this as the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| **Returns** | **DistributedForecast** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributedForecast.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545b806-d828-42dc-be00-d71dab8499b6",
   "metadata": {},
   "source": [
    "Calling `.fit` on our data computes the features independently for each partition and performs distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472ae1e-4b26-4414-8c58-9cc9a9e4d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:51] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:10:51] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Info] Trying to bind port 34877...\n",
      "[LightGBM] [Info] Binding port 34877 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Warning] Connecting to rank 1 failed, waiting for 200 milliseconds\n",
      "[LightGBM] [Info] Trying to bind port 43777...\n",
      "[LightGBM] [Info] Binding port 43777 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Local rank: 0, total number of machines: 2\n",
      "[LightGBM] [Info] Local rank: 1, total number of machines: 2\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistributedForecast(models=[XGBForecast, LGBMForecast], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=['dayofweek', 'month'], num_threads=1, client=<Client: 'tcp://127.0.0.1:35947' processes=2 threads=2, memory=15.50 GiB>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.fit(partitioned_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b5ec6-bee0-4f68-8c91-b99c54576774",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e95a58-0fee-41ee-900b-d2b61825042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DistributedForecast.predict\n",
       "\n",
       ">      DistributedForecast.predict (horizon:int,\n",
       ">                                   dynamic_dfs:Optional[List[pandas.core.frame.\n",
       ">                                   DataFrame]]=None,\n",
       ">                                   predict_fn:Optional[Callable]=None,\n",
       ">                                   **predict_fn_kwargs)\n",
       "\n",
       "Compute the predictions for the next `horizon` steps.\n",
       "\n",
       "`predict_fn(model, new_x, dynamic_dfs, features_order, **predict_fn_kwargs)` is called in every timestep, where:\n",
       "`model` is the trained model.\n",
       "`new_x` is a dataframe with the same format as the input plus the computed features.\n",
       "`dynamic_dfs` is a list containing the dynamic dataframes.\n",
       "`features_order` is the list of column names that were used in the training step."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DistributedForecast.predict\n",
       "\n",
       ">      DistributedForecast.predict (horizon:int,\n",
       ">                                   dynamic_dfs:Optional[List[pandas.core.frame.\n",
       ">                                   DataFrame]]=None,\n",
       ">                                   predict_fn:Optional[Callable]=None,\n",
       ">                                   **predict_fn_kwargs)\n",
       "\n",
       "Compute the predictions for the next `horizon` steps.\n",
       "\n",
       "`predict_fn(model, new_x, dynamic_dfs, features_order, **predict_fn_kwargs)` is called in every timestep, where:\n",
       "`model` is the trained model.\n",
       "`new_x` is a dataframe with the same format as the input plus the computed features.\n",
       "`dynamic_dfs` is a list containing the dynamic dataframes.\n",
       "`features_order` is the list of column names that were used in the training step."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributedForecast.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417aa8d-e724-4ffa-a902-2ab822574030",
   "metadata": {},
   "source": [
    "Once we have our fitted model we can compute the predictions for the next 7 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a439d-e0d0-4f2f-925c-fccd92361c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float32</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_50</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 4 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                           ds XGBRegressor LGBMRegressor\n",
       "npartitions=2                                           \n",
       "id_00          datetime64[ns]      float32       float64\n",
       "id_50                     ...          ...           ...\n",
       "id_99                     ...          ...           ...\n",
       "Dask Name: from-delayed, 4 tasks"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a8518-0e2a-4699-8da0-e63f29a2f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "preds = preds.compute()\n",
    "preds2 = fcst.predict(7).compute()\n",
    "pd.testing.assert_frame_equal(preds, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8d462-8318-4d10-98e5-13739dcd4023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:53] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:10:53] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "non_std_series = partitioned_series.copy()\n",
    "non_std_series['ds'] = non_std_series['ds'].astype('int')\n",
    "non_std_series = non_std_series.reset_index().rename(columns={'ds': 'time', 'y': 'value'})\n",
    "flow_params = dict(\n",
    "    models=[XGBForecast(random_state=0)],\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    num_threads=1,\n",
    ")\n",
    "fcst = DistributedForecast(freq='D', **flow_params)\n",
    "preds = fcst.fit(partitioned_series).predict(7).compute()\n",
    "fcst2 = DistributedForecast(**flow_params)\n",
    "fcst2.preprocess(non_std_series, time_col='time', target_col='value')\n",
    "fcst2.fitted_models = fcst.fitted_models  # distributed training can end up with different fits\n",
    "non_std_preds = fcst2.predict(7).compute()\n",
    "non_std_preds.index.name = 'unique_id'\n",
    "pd.testing.assert_frame_equal(preds.drop(columns='ds'), non_std_preds.drop(columns='time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f27b9a-ebc3-4673-8459-ad5843a43dac",
   "metadata": {},
   "source": [
    "#### 2. Preprocess and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b1833-a63a-45da-b3dc-8e1e5bfeb589",
   "metadata": {},
   "source": [
    "If we only want to perform the preprocessing step we call `.preprocess` on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c34f3-faa9-44a8-b070-d28225d73cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DistributedForecast.preprocess\n",
       "\n",
       ">      DistributedForecast.preprocess (data:dask.dataframe.core.DataFrame,\n",
       ">                                      id_col:str='unique_id',\n",
       ">                                      time_col:str='ds', target_col:str='y',\n",
       ">                                      static_features:Optional[List[str]]=None,\n",
       ">                                      dropna:bool=True,\n",
       ">                                      keep_last_n:Optional[int]=None)\n",
       "\n",
       "Computes the transformations on each partition of `data` and\n",
       "saves the required information for the forecasting step.\n",
       "Returns a dask dataframe with the computed features.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, it's recommended to have this as the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DistributedForecast.preprocess\n",
       "\n",
       ">      DistributedForecast.preprocess (data:dask.dataframe.core.DataFrame,\n",
       ">                                      id_col:str='unique_id',\n",
       ">                                      time_col:str='ds', target_col:str='y',\n",
       ">                                      static_features:Optional[List[str]]=None,\n",
       ">                                      dropna:bool=True,\n",
       ">                                      keep_last_n:Optional[int]=None)\n",
       "\n",
       "Computes the transformations on each partition of `data` and\n",
       "saves the required information for the forecasting step.\n",
       "Returns a dask dataframe with the computed features.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | DataFrame |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, it's recommended to have this as the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| **Returns** | **DataFrame** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributedForecast.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9c699-8768-4485-bc22-4da64bea46d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>static_1</th>\n",
       "      <th>lag-7</th>\n",
       "      <th>expanding_mean_lag-1</th>\n",
       "      <th>rolling_mean_lag-7_window_size-14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-25</td>\n",
       "      <td>497.668437</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>506.946385</td>\n",
       "      <td>250.013666</td>\n",
       "      <td>263.200596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-26</td>\n",
       "      <td>39.183469</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>38.877800</td>\n",
       "      <td>261.806750</td>\n",
       "      <td>263.133868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-27</td>\n",
       "      <td>94.377779</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>115.127739</td>\n",
       "      <td>251.687510</td>\n",
       "      <td>263.980563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-28</td>\n",
       "      <td>179.235741</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>180.384975</td>\n",
       "      <td>244.847957</td>\n",
       "      <td>264.252723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-29</td>\n",
       "      <td>267.546447</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>242.228588</td>\n",
       "      <td>242.114114</td>\n",
       "      <td>263.055629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds           y  static_0  static_1       lag-7  \\\n",
       "unique_id                                                          \n",
       "id_00     2000-10-25  497.668437        79        45  506.946385   \n",
       "id_00     2000-10-26   39.183469        79        45   38.877800   \n",
       "id_00     2000-10-27   94.377779        79        45  115.127739   \n",
       "id_00     2000-10-28  179.235741        79        45  180.384975   \n",
       "id_00     2000-10-29  267.546447        79        45  242.228588   \n",
       "\n",
       "           expanding_mean_lag-1  rolling_mean_lag-7_window_size-14  \n",
       "unique_id                                                           \n",
       "id_00                250.013666                         263.200596  \n",
       "id_00                261.806750                         263.133868  \n",
       "id_00                251.687510                         263.980563  \n",
       "id_00                244.847957                         264.252723  \n",
       "id_00                242.114114                         263.055629  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ddf = fcst.preprocess(partitioned_series)\n",
    "features_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b647b-7d05-42d7-b626-35c35fcf517b",
   "metadata": {},
   "source": [
    "This is useful if we want to inspect the data the model will be trained, adding additional features or performing some custom train-valid split. Here we perform a 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9f0b3-63d6-457f-be72-39c4adc97309",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "def mask_as_series(df):\n",
    "    return pd.Series(rng.rand(df.shape[0]) < 0.8, index=df.index)\n",
    "\n",
    "train_mask = features_ddf.map_partitions(mask_as_series)\n",
    "train, valid = features_ddf[train_mask], features_ddf[~train_mask]\n",
    "X_train, y_train = train.drop(columns=['ds', 'y']), train.y\n",
    "X_valid, y_valid = valid.drop(columns=['ds', 'y']), valid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9205a1c-1ea5-4dfd-ba69-9756fb59b1ca",
   "metadata": {},
   "source": [
    "If we do this we must \"manually\" train our model calling `DistributedForecast.model.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4055884-0525-4c5f-9898-1afe85e07057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:55] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBForecast(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "            colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "            grow_policy='depthwise', interaction_constraints='',\n",
       "            learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "            max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "            monotone_constraints='()', n_jobs=1, num_parallel_tree=1,\n",
       "            objective='reg:squarederror', predictor='auto', random_state=0,\n",
       "            reg_alpha=0, reg_lambda=1, sampling_method='uniform',\n",
       "            scale_pos_weight=1, subsample=1, tree_method='approx',\n",
       "            validate_parameters=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.models[0].fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_metric='rmse',\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424717d-153a-4e5e-94b1-11d4991656de",
   "metadata": {},
   "source": [
    "We can see the RMSE by iteration for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c864900-88fa-4d2a-86d3-5a9638808a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_0</th>\n",
       "      <th>validation_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.96</td>\n",
       "      <td>155.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.40</td>\n",
       "      <td>109.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.17</td>\n",
       "      <td>77.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.04</td>\n",
       "      <td>54.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.02</td>\n",
       "      <td>39.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.80</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7.80</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.79</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.76</td>\n",
       "      <td>9.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7.74</td>\n",
       "      <td>9.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    validation_0  validation_1\n",
       "0         159.96        155.58\n",
       "1         112.40        109.37\n",
       "2          79.17         77.09\n",
       "3          56.04         54.67\n",
       "4          40.02         39.12\n",
       "..           ...           ...\n",
       "95          7.80          9.54\n",
       "96          7.80          9.54\n",
       "97          7.79          9.54\n",
       "98          7.76          9.52\n",
       "99          7.74          9.51\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    k: np.round(fcst.models[0].evals_result_[k]['rmse'], 2)\n",
    "    for k in ('validation_0', 'validation_1')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d1a41-a56c-4113-a7d9-a79f643021ab",
   "metadata": {},
   "source": [
    "#### Dynamic features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e66766-a8e9-4af0-96e3-9f5b847c4f0b",
   "metadata": {},
   "source": [
    "By default the predict method repeats the static features and updates the transformations and the date features. If you have dynamic features like prices or a calendar with holidays you can pass them as a list to the `dynamic_dfs` argument of `Forecast.predict`, which will call `pd.DataFrame.merge` on each of them in order.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "Suppose that we have a `product_id` column and we have a catalog for prices based on that `product_id` and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee52992-0b18-43b0-833d-62f7246951c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-06-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20180</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>99</td>\n",
       "      <td>0.223520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>99</td>\n",
       "      <td>0.446104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20182</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>99</td>\n",
       "      <td>0.044783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20183</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>99</td>\n",
       "      <td>0.483216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20184</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>99</td>\n",
       "      <td>0.799660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ds  product_id     price\n",
       "0     2000-06-09           1  0.548814\n",
       "1     2000-06-10           1  0.715189\n",
       "2     2000-06-11           1  0.602763\n",
       "3     2000-06-12           1  0.544883\n",
       "4     2000-06-13           1  0.423655\n",
       "...          ...         ...       ...\n",
       "20180 2001-05-17          99  0.223520\n",
       "20181 2001-05-18          99  0.446104\n",
       "20182 2001-05-19          99  0.044783\n",
       "20183 2001-05-20          99  0.483216\n",
       "20184 2001-05-21          99  0.799660\n",
       "\n",
       "[20185 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_series = series.rename(columns={'static_1': 'product_id'})\n",
    "prices_catalog = generate_prices_for_series(dynamic_series)\n",
    "prices_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7730055-6bab-4b52-bc83-e8456358309e",
   "metadata": {},
   "source": [
    "And you have already merged these prices into your series dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e34f7-3ee0-48a1-93d1-4cc77f1afdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>39.811983</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.570826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-06</td>\n",
       "      <td>103.274013</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.260562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-07</td>\n",
       "      <td>176.574744</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.274048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-08</td>\n",
       "      <td>258.987900</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.433878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2000-10-09</td>\n",
       "      <td>344.940404</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds           y  static_0  product_id     price\n",
       "unique_id                                                       \n",
       "id_00     2000-10-05   39.811983        79          45  0.570826\n",
       "id_00     2000-10-06  103.274013        79          45  0.260562\n",
       "id_00     2000-10-07  176.574744        79          45  0.274048\n",
       "id_00     2000-10-08  258.987900        79          45  0.433878\n",
       "id_00     2000-10-09  344.940404        79          45  0.653738"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_series = partitioned_series.rename(columns={'static_1': 'product_id'})\n",
    "dynamic_series = dynamic_series.reset_index()\n",
    "series_with_prices = dynamic_series.merge(prices_catalog, how='left')\n",
    "series_with_prices = series_with_prices.set_index('unique_id', sorted=True)\n",
    "series_with_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e348d3-a449-4823-8d5c-1c8b13f9b133",
   "metadata": {},
   "source": [
    "This dataframe will be passed to `DistributedForecast.fit` (or `DistributedForecast.preprocess`), however since the price is dynamic we have to tell that method that only `static_0` and `product_id` are static and we'll have to update `price` in every timestep, which basically involves merging the updated features with the prices catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ea277-66d3-4bf8-aeaa-cc117cfa8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:56] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistributedForecast(models=[XGBForecast, LGBMForecast], freq=<Day>, lag_features=['lag-7', 'expanding_mean_lag-1', 'rolling_mean_lag-7_window_size-14'], date_features=['dayofweek', 'month'], num_threads=1, client=<Client: 'tcp://127.0.0.1:35947' processes=2 threads=2, memory=15.50 GiB>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst = DistributedForecast(\n",
    "    models,\n",
    "    freq='D',\n",
    "    lags=[7],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean],\n",
    "        7: [(rolling_mean, 14)]\n",
    "    },\n",
    "    date_features=['dayofweek', 'month'],\n",
    "    num_threads=1,\n",
    ")\n",
    "series_with_prices = series_with_prices\n",
    "fcst.fit(series_with_prices, static_features=['static_0', 'product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9bba71-8bb1-491b-bb0c-7ef8c6004f7b",
   "metadata": {},
   "source": [
    "So in order to update the price in each timestep we just call `DistributedForecast.predict` with our forecast horizon and pass the prices catalog as a dynamic dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bc484-5e79-4139-acd5-c9ee3cf7270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>423.707642</td>\n",
       "      <td>425.271062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>501.180878</td>\n",
       "      <td>499.367199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>13.227302</td>\n",
       "      <td>19.680575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>98.732613</td>\n",
       "      <td>103.003798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_00</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>179.789963</td>\n",
       "      <td>186.687089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>437.574402</td>\n",
       "      <td>441.140547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>18.790911</td>\n",
       "      <td>19.506097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>87.097137</td>\n",
       "      <td>91.141189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-20</td>\n",
       "      <td>154.764557</td>\n",
       "      <td>151.241891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_99</th>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>226.731979</td>\n",
       "      <td>228.440428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  XGBRegressor  LGBMRegressor\n",
       "unique_id                                        \n",
       "id_00     2001-05-15    423.707642     425.271062\n",
       "id_00     2001-05-16    501.180878     499.367199\n",
       "id_00     2001-05-17     13.227302      19.680575\n",
       "id_00     2001-05-18     98.732613     103.003798\n",
       "id_00     2001-05-19    179.789963     186.687089\n",
       "...              ...           ...            ...\n",
       "id_99     2001-05-17    437.574402     441.140547\n",
       "id_99     2001-05-18     18.790911      19.506097\n",
       "id_99     2001-05-19     87.097137      91.141189\n",
       "id_99     2001-05-20    154.764557     151.241891\n",
       "id_99     2001-05-21    226.731979     228.440428\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fcst.predict(7, dynamic_dfs=[prices_catalog])\n",
    "preds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b03634-d3e0-46e5-b05b-df7291fc8fdc",
   "metadata": {},
   "source": [
    "#### Custom predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa29c8f-65a6-4048-bf6a-0aa9874e2a2c",
   "metadata": {},
   "source": [
    "If you want to do something like scaling the predictions you can define a function and pass it to `DistributedForecast.predict` as described in <a href=\"/mlforecast/forecast.html#Custom-predictions\">Custom predictions</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33846e-6d3c-4199-afe8-c5e064a53aac",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "Refer to `Forecast.cross_validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c97388-73f5-460d-9299-ab5cc6f31720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Forecast.cross_validation\n",
       "\n",
       ">      Forecast.cross_validation (data, n_windows:int, window_size:int,\n",
       ">                                 id_col:str='unique_id', time_col:str='ds',\n",
       ">                                 target_col:str='y',\n",
       ">                                 static_features:Optional[List[str]]=None,\n",
       ">                                 dropna:bool=True,\n",
       ">                                 keep_last_n:Optional[int]=None, dynamic_dfs:Op\n",
       ">                                 tional[List[pandas.core.frame.DataFrame]]=None\n",
       ">                                 , predict_fn:Optional[Callable]=None,\n",
       ">                                 **predict_fn_kwargs)\n",
       "\n",
       "Creates `n_windows` splits of `window_size` from `data`, trains the model\n",
       "on the training set, predicts the window and merges the actuals and the predictions\n",
       "in a dataframe.\n",
       "\n",
       "Returns a dataframe containing the datestamps, actual values, train ends and predictions.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data |  |  |  |\n",
       "| n_windows | int |  |  |\n",
       "| window_size | int |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None |  |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None |  |\n",
       "| predict_fn_kwargs |  |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Forecast.cross_validation\n",
       "\n",
       ">      Forecast.cross_validation (data, n_windows:int, window_size:int,\n",
       ">                                 id_col:str='unique_id', time_col:str='ds',\n",
       ">                                 target_col:str='y',\n",
       ">                                 static_features:Optional[List[str]]=None,\n",
       ">                                 dropna:bool=True,\n",
       ">                                 keep_last_n:Optional[int]=None, dynamic_dfs:Op\n",
       ">                                 tional[List[pandas.core.frame.DataFrame]]=None\n",
       ">                                 , predict_fn:Optional[Callable]=None,\n",
       ">                                 **predict_fn_kwargs)\n",
       "\n",
       "Creates `n_windows` splits of `window_size` from `data`, trains the model\n",
       "on the training set, predicts the window and merges the actuals and the predictions\n",
       "in a dataframe.\n",
       "\n",
       "Returns a dataframe containing the datestamps, actual values, train ends and predictions.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data |  |  |  |\n",
       "| n_windows | int |  |  |\n",
       "| window_size | int |  |  |\n",
       "| id_col | str | unique_id | column that identifies each serie, can also be the index. |\n",
       "| time_col | str | ds | column with the timestamps |\n",
       "| target_col | str | y | column with the series values |\n",
       "| static_features | typing.Optional[typing.List[str]] | None |  |\n",
       "| dropna | bool | True |  |\n",
       "| keep_last_n | typing.Optional[int] | None |  |\n",
       "| dynamic_dfs | typing.Optional[typing.List[pandas.core.frame.DataFrame]] | None |  |\n",
       "| predict_fn | typing.Optional[typing.Callable] | None |  |\n",
       "| predict_fn_kwargs |  |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributedForecast.cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab05e3-3d72-4afa-a74e-6961a3d9186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:57] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:10:57] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Info] Trying to bind port 42157...\n",
      "[LightGBM] [Info] Binding port 42157 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Warning] Connecting to rank 1 failed, waiting for 200 milliseconds\n",
      "[LightGBM] [Info] Trying to bind port 55203...\n",
      "[LightGBM] [Info] Binding port 55203 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Local rank: 0, total number of machines: 2\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Local rank: 1, total number of machines: 2\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:10:58] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:10:58] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Info] Trying to bind port 43587...\n",
      "[LightGBM] [Info] Binding port 43587 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Trying to bind port 49251...\n",
      "[LightGBM] [Info] Binding port 49251 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Local rank: 0, total number of machines: 2\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Local rank: 1, total number of machines: 2\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n",
      "[LightGBM] [Warning] num_threads is set=1, n_jobs=-1 will be ignored. Current value: num_threads=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float64</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>float32</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: concat, 58 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                           ds        y          cutoff XGBRegressor LGBMRegressor\n",
       "npartitions=4                                                                    \n",
       "               datetime64[ns]  float64  datetime64[ns]      float32       float64\n",
       "                          ...      ...             ...          ...           ...\n",
       "                          ...      ...             ...          ...           ...\n",
       "                          ...      ...             ...          ...           ...\n",
       "                          ...      ...             ...          ...           ...\n",
       "Dask Name: concat, 58 tasks"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_windows = 2\n",
    "window_size = 14\n",
    "\n",
    "backtest_results = fcst.cross_validation(partitioned_series, n_windows, window_size)\n",
    "backtest_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffbd79-f544-4cfc-8b62-ba009165c071",
   "metadata": {},
   "source": [
    "We can aggregate these by date to get a rough estimate of how our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4a701-1779-4007-b9be-dbdee3454bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-04-17</th>\n",
       "      <td>161.232312</td>\n",
       "      <td>162.149048</td>\n",
       "      <td>162.078552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-18</th>\n",
       "      <td>152.139197</td>\n",
       "      <td>151.376801</td>\n",
       "      <td>151.354280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-19</th>\n",
       "      <td>169.856989</td>\n",
       "      <td>171.695221</td>\n",
       "      <td>171.306728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-20</th>\n",
       "      <td>180.683402</td>\n",
       "      <td>180.697113</td>\n",
       "      <td>180.020983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-21</th>\n",
       "      <td>182.006090</td>\n",
       "      <td>181.487701</td>\n",
       "      <td>181.230938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y  XGBRegressor  LGBMRegressor\n",
       "ds                                                 \n",
       "2001-04-17  161.232312    162.149048     162.078552\n",
       "2001-04-18  152.139197    151.376801     151.354280\n",
       "2001-04-19  169.856989    171.695221     171.306728\n",
       "2001-04-20  180.683402    180.697113     180.020983\n",
       "2001-04-21  182.006090    181.487701     181.230938"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = backtest_results.compute().groupby('ds').mean()\n",
    "agg_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8651d-bf63-4a42-bd19-95e1271fed95",
   "metadata": {},
   "source": [
    "We can include some more context by using the values in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd06319-4031-422e-bd1e-93c56ca2bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-02-26</th>\n",
       "      <td>15560.913051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-27</th>\n",
       "      <td>15849.105590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>14695.554047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-01</th>\n",
       "      <td>17110.908354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-02</th>\n",
       "      <td>17845.327523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-10</th>\n",
       "      <td>171.394991</td>\n",
       "      <td>171.039734</td>\n",
       "      <td>171.152135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-11</th>\n",
       "      <td>180.413157</td>\n",
       "      <td>180.548401</td>\n",
       "      <td>180.644497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-12</th>\n",
       "      <td>181.652667</td>\n",
       "      <td>180.978073</td>\n",
       "      <td>180.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-13</th>\n",
       "      <td>168.138961</td>\n",
       "      <td>168.937668</td>\n",
       "      <td>169.138480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-14</th>\n",
       "      <td>157.971393</td>\n",
       "      <td>158.862701</td>\n",
       "      <td>158.496260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       y  XGBRegressor  LGBMRegressor\n",
       "ds                                                   \n",
       "2001-02-26  15560.913051           NaN            NaN\n",
       "2001-02-27  15849.105590           NaN            NaN\n",
       "2001-02-28  14695.554047           NaN            NaN\n",
       "2001-03-01  17110.908354           NaN            NaN\n",
       "2001-03-02  17845.327523           NaN            NaN\n",
       "...                  ...           ...            ...\n",
       "2001-05-10    171.394991    171.039734     171.152135\n",
       "2001-05-11    180.413157    180.548401     180.644497\n",
       "2001-05-12    181.652667    180.978073     180.605739\n",
       "2001-05-13    168.138961    168.937668     169.138480\n",
       "2001-05-14    157.971393    158.862701     158.496260\n",
       "\n",
       "[78 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = series[series.ds < agg_results.index.min()]\n",
    "agg_history = history.groupby('ds')[['y']].sum().tail(50)\n",
    "pd.concat([agg_history, agg_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da220459-5595-4bd4-901f-4c4f5ee8090c",
   "metadata": {},
   "source": [
    "We can also compute the error for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efc3c1-f6ba-490f-8d19-9e4587c8e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBRegressor': 88.83, 'LGBMRegressor': 92.11}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_from_dask_dataframe(ddf):\n",
    "    mses = {}\n",
    "    for model_name in ddf.columns.drop(['ds', 'y', 'cutoff']):\n",
    "        mses[model_name] = (ddf['y'] - ddf[model_name]).pow(2).mean()\n",
    "    return client.gather(client.compute(mses))\n",
    "\n",
    "{k: round(v, 2) for k, v in mse_from_dask_dataframe(backtest_results).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16332f77-d864-4787-aa67-d3c5f8ae8e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:11:00] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:11:00] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n",
      "[23:11:01] task [xgboost.dask]:tcp://127.0.0.1:43193 got new rank 0\n",
      "[23:11:01] task [xgboost.dask]:tcp://127.0.0.1:34107 got new rank 1\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "fcst = DistributedForecast(XGBForecast(random_state=0), freq='D', lags=[7, 14])\n",
    "backtest_results = fcst.cross_validation(partitioned_series, n_windows, window_size).compute()\n",
    "cv_models = fcst.cv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c121ea-72ac-4bb9-9718-9ba1ca27046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_results = []\n",
    "for i, (cutoff, train, valid) in enumerate(backtest_splits(partitioned_series, n_windows, window_size, fcst.freq)):\n",
    "    fcst.preprocess(train)\n",
    "    fcst.fitted_models = cv_models[i]\n",
    "    pred = fcst.predict(window_size).compute()\n",
    "    res = valid[['ds', 'y']].compute()\n",
    "    res['cutoff'] = cutoff\n",
    "    manual_results.append(res.merge(pred, on=['unique_id', 'ds'], how='left'))\n",
    "manual_results = pd.concat(manual_results)\n",
    "pd.testing.assert_frame_equal(backtest_results, manual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0086c2a-c5b3-4a40-9901-b05139c3d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
