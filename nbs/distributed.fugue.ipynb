{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5b1d7-bc13-4ed3-af30-f15cacc861f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp distributed.fugue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9a984-a442-41d2-8132-471d73e64d96",
   "metadata": {},
   "source": [
    "# Fugue\n",
    "\n",
    "> Distributed fugue backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8108c14-6d27-4dfd-b3e8-a2b315eb5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import copy\n",
    "from typing import Any, Callable, Iterable, List, Optional\n",
    "\n",
    "import cloudpickle\n",
    "try:\n",
    "    import dask.dataframe as dd\n",
    "    DASK_INSTALLED = True\n",
    "except ModuleNotFoundError:\n",
    "    DASK_INSTALLED = False\n",
    "import fugue.api as fa\n",
    "import pandas as pd\n",
    "try:\n",
    "    from pyspark.ml.feature import VectorAssembler\n",
    "    from pyspark.sql import DataFrame as SparkDataFrame\n",
    "    SPARK_INSTALLED = True\n",
    "except ModuleNotFoundError:\n",
    "    SPARK_INSTALLED = False\n",
    "from sklearn.base import clone\n",
    "\n",
    "from mlforecast.core import (\n",
    "    DateFeature,\n",
    "    Differences,\n",
    "    Freq,\n",
    "    LagTransforms,\n",
    "    Lags,\n",
    "    TimeSeries,\n",
    "    _name_models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f19b4-4582-4c51-94cd-c7c220d35dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FugueMLForecast:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models,\n",
    "        freq: Optional[Freq] = None,\n",
    "        lags: Optional[Lags] = None,\n",
    "        lag_transforms: Optional[LagTransforms] = None,\n",
    "        date_features: Optional[Iterable[DateFeature]] = None,\n",
    "        differences: Optional[Differences] = None,\n",
    "        num_threads: int = 1,\n",
    "        engine = None,\n",
    "    ):\n",
    "        if not isinstance(models, dict) and not isinstance(models, list):\n",
    "            models = [models]\n",
    "        if isinstance(models, list):\n",
    "            model_names = _name_models([m.__class__.__name__ for m in models])\n",
    "            models_with_names = dict(zip(model_names, models))\n",
    "        else:\n",
    "            models_with_names = models\n",
    "        self.models = models_with_names\n",
    "        self._base_ts = TimeSeries(\n",
    "            freq, lags, lag_transforms, date_features, differences, num_threads\n",
    "        )\n",
    "        self.engine = engine\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'{self.__class__.__name__}(models=[{\", \".join(self.models.keys())}], '\n",
    "            f\"freq={self._base_ts.freq}, \"\n",
    "            f\"lag_features={list(self._base_ts.transforms.keys())}, \"\n",
    "            f\"date_features={self._base_ts.date_features}, \"\n",
    "            f\"num_threads={self._base_ts.num_threads}, \"\n",
    "            f\"engine={self.engine})\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_partition(\n",
    "        part: pd.DataFrame,\n",
    "        base_ts: TimeSeries,        \n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None,\n",
    "        i_window: Optional[int] = None,\n",
    "        n_windows: Optional[int] = None,\n",
    "        window_size: Optional[int] = None,\n",
    "    ) -> List[List[Any]]:\n",
    "        ts = copy.deepcopy(base_ts)\n",
    "        if i_window is None:\n",
    "            train = part\n",
    "            valid = None\n",
    "        else:            \n",
    "            max_dates = part.groupby(id_col)[time_col].transform('max')\n",
    "            train_ends = max_dates - (n_windows - i_window) * window_size * base_ts.freq\n",
    "            valid_ends = train_ends + window_size * base_ts.freq\n",
    "            train_mask = part[time_col].le(train_ends)\n",
    "            valid_mask = part[time_col].gt(train_ends) & part[time_col].le(valid_ends)\n",
    "            train = part[train_mask]\n",
    "            valid_keep_cols = part.columns\n",
    "            if static_features is not None:\n",
    "                valid_keep_cols.drop(static_features)\n",
    "            valid = part.loc[valid_mask, valid_keep_cols]\n",
    "        transformed = ts.fit_transform(\n",
    "            train,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "            static_features=static_features,\n",
    "            dropna=dropna,\n",
    "            keep_last_n=keep_last_n,\n",
    "        )\n",
    "        return [[cloudpickle.dumps(ts), cloudpickle.dumps(transformed), cloudpickle.dumps(valid)]]\n",
    "\n",
    "    @staticmethod\n",
    "    def _retrieve_df(items: List[List[Any]]) -> Iterable[pd.DataFrame]:\n",
    "        for _, serialized_train, _ in items:\n",
    "            yield cloudpickle.loads(serialized_train)\n",
    "\n",
    "    def preprocess(\n",
    "        self,\n",
    "        data,\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None,\n",
    "    ):\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "        self.partition_results = fa.transform(\n",
    "            data,\n",
    "            FugueMLForecast._preprocess_partition,\n",
    "            params={\n",
    "                'base_ts': self._base_ts,\n",
    "                'id_col': id_col,\n",
    "                'time_col': time_col,\n",
    "                'target_col': target_col,\n",
    "                'static_features': static_features,\n",
    "                'dropna': dropna,\n",
    "                'keep_last_n': keep_last_n,\n",
    "                'i_window': getattr(self, '_i_window', None),\n",
    "                'n_windows': getattr(self, '_n_windows', None),\n",
    "                'window_size': getattr(self, '_window_size', None),\n",
    "            },\n",
    "            schema='ts:binary,train:binary,valid:binary',\n",
    "            engine=self.engine,\n",
    "            as_fugue=True,\n",
    "        )\n",
    "        base_schema = str(fa.get_schema(data))\n",
    "        features_schema = ','.join(f'{feat}:double' for feat in self._base_ts.features)\n",
    "        res = fa.transform(\n",
    "            self.partition_results,\n",
    "            FugueMLForecast._retrieve_df,\n",
    "            schema=f'{base_schema},{features_schema}',\n",
    "            engine=self.engine,\n",
    "        )\n",
    "        return fa.get_native_as_df(res)\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        data,\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None,\n",
    "    ):\n",
    "        prep = self.preprocess(\n",
    "            data,\n",
    "            id_col=id_col,\n",
    "            time_col=time_col,\n",
    "            target_col=target_col,\n",
    "            static_features=static_features,\n",
    "            dropna=dropna,\n",
    "            keep_last_n=keep_last_n,\n",
    "        )\n",
    "        features = [x for x in prep.columns if x not in {id_col, time_col, target_col}]\n",
    "        self.models_ = {}\n",
    "        if SPARK_INSTALLED and isinstance(data, SparkDataFrame):\n",
    "            try:\n",
    "                import lightgbm as lgb\n",
    "                from synapse.ml.lightgbm import LightGBMRegressor as SynapseLGBMRegressor\n",
    "                LGBM_INSTALLED = True\n",
    "            except ModuleNotFoundError:\n",
    "                LGBM_INSTALLED = False\n",
    "            try:\n",
    "                import xgboost as xgb\n",
    "                from xgboost.spark import SparkXGBRegressor  # type: ignore\n",
    "                XGB_INSTALLED = True\n",
    "            except ModuleNotFoundError:\n",
    "                XGB_INSTALLED = False\n",
    "\n",
    "            featurizer = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "            train_data = featurizer.transform(prep)[target_col, \"features\"]\n",
    "            for name, model in self.models.items():\n",
    "                if LGBM_INSTALLED and isinstance(model, SynapseLGBMRegressor):\n",
    "                    trained_model = model.setLabelCol(target_col).fit(train_data)\n",
    "                    model_str = trained_model.getNativeModel()\n",
    "                    local_model = lgb.Booster(model_str=model_str)                    \n",
    "                elif XGB_INSTALLED and isinstance(model, SparkXGBRegressor):\n",
    "                    model.setParams(label_col=target_col)\n",
    "                    trained_model = model.fit(train_data)\n",
    "                    model_str = trained_model.get_booster().save_raw('ubj')\n",
    "                    local_model = xgb.XGBRegressor()\n",
    "                    local_model.load_model(model_str)\n",
    "                else:\n",
    "                    raise ValueError('Only LightGBMRegressor from SynapseML and SparkXGBRegressor are supported in spark.')\n",
    "                self.models_[name] = local_model\n",
    "        elif DASK_INSTALLED and isinstance(data, dd.DataFrame):\n",
    "            try:\n",
    "                from mlforecast.distributed.models.lgb import LGBMForecast\n",
    "                LGBM_INSTALLED = True\n",
    "            except ModuleNotFoundError:\n",
    "                LGBM_INSTALLED = False\n",
    "            try:\n",
    "                from mlforecast.distributed.models.xgb import XGBForecast\n",
    "                XGB_INSTALLED = True\n",
    "            except ModuleNotFoundError:\n",
    "                XGB_INSTALLED = False\n",
    "            X, y = prep[features], prep[target_col]\n",
    "            for name, model in self.models.items():\n",
    "                if not ((LGBM_INSTALLED and isinstance(model, LGBMForecast)) or (XGB_INSTALLED and isinstance(model, XGBForecast))):\n",
    "                    raise ValueError('Models must be either LGBMForecast or XGBForecast with dask backend.')\n",
    "                self.models_[name] = clone(model).fit(X, y).model_\n",
    "        else:\n",
    "            raise NotImplementedError('Only spark and dask engines are supported.')\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _predict(\n",
    "        items: List[List[Any]],\n",
    "        models,        \n",
    "        horizon,\n",
    "        dynamic_dfs,\n",
    "        before_predict_callback,\n",
    "        after_predict_callback,\n",
    "    ) -> Iterable[pd.DataFrame]:\n",
    "        for serialized_ts, _, serialized_valid in items:\n",
    "            valid = cloudpickle.loads(serialized_valid)\n",
    "            ts = cloudpickle.loads(serialized_ts)\n",
    "            if valid is not None:\n",
    "                dynamic_features = valid.columns.drop(\n",
    "                    [ts.id_col, ts.time_col, ts.target_col]\n",
    "                )\n",
    "                if not dynamic_features.empty:\n",
    "                    dynamic_dfs = [valid.drop(columns=ts.target_col)]\n",
    "            res = ts.predict(\n",
    "                models=models,\n",
    "                horizon=horizon,\n",
    "                dynamic_dfs=dynamic_dfs,\n",
    "                before_predict_callback=before_predict_callback,\n",
    "                after_predict_callback=after_predict_callback,\n",
    "            ).reset_index()\n",
    "            if valid is not None:\n",
    "                res = res.merge(valid, how='left')\n",
    "            yield res\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        dynamic_dfs: Optional[List[pd.DataFrame]] = None,\n",
    "        before_predict_callback: Optional[Callable] = None,\n",
    "        after_predict_callback: Optional[Callable] = None,\n",
    "    ):\n",
    "        model_names = self.models.keys()\n",
    "        models_schema = ','.join(f'{model_name}:double' for model_name in model_names)\n",
    "        schema = f'{self.id_col}:string,{self.time_col}:datetime,' + models_schema\n",
    "        if getattr(self, '_n_windows', None) is not None:\n",
    "            schema += f',{self.target_col}:double'\n",
    "        return fa.transform(\n",
    "            self.partition_results,\n",
    "            FugueMLForecast._predict,\n",
    "            params={\n",
    "                'models': self.models_,\n",
    "                'horizon': horizon,\n",
    "                'dynamic_dfs': dynamic_dfs,\n",
    "                'before_predict_callback': before_predict_callback,\n",
    "                'after_predict_callback': after_predict_callback,\n",
    "            },\n",
    "            schema=schema,\n",
    "            engine=self.engine,\n",
    "        )\n",
    "\n",
    "    def cross_validation(\n",
    "        self,\n",
    "        data,\n",
    "        n_windows: int,\n",
    "        window_size: int,\n",
    "        id_col: str,\n",
    "        time_col: str,\n",
    "        target_col: str,\n",
    "        step_size: Optional[int] = None, \n",
    "        static_features: Optional[List[str]] = None,\n",
    "        dropna: bool = True,\n",
    "        keep_last_n: Optional[int] = None,\n",
    "        refit: bool = True,\n",
    "        before_predict_callback: Optional[Callable] = None,\n",
    "        after_predict_callback: Optional[Callable] = None,\n",
    "    ):\n",
    "        self.cv_models_ = []\n",
    "        self._n_windows = n_windows\n",
    "        self._window_size = window_size\n",
    "        for i in range(n_windows):\n",
    "            self._i_window = i\n",
    "            self.fit(\n",
    "                data,\n",
    "                id_col=id_col,\n",
    "                time_col=time_col,\n",
    "                target_col=target_col,\n",
    "                static_features=static_features,\n",
    "                dropna=dropna,\n",
    "                keep_last_n=keep_last_n,\n",
    "            )\n",
    "            self.cv_models_.append(self.models_)\n",
    "            preds = self.predict(\n",
    "                window_size,\n",
    "                before_predict_callback=before_predict_callback,\n",
    "                after_predict_callback=after_predict_callback,\n",
    "            )\n",
    "            yield preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e350d0b-8a4c-40e0-83be-7c1ef1bf5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from window_ops.expanding import expanding_mean\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cea5f-b826-4c9b-ae9f-2532f92f31bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>static_0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-10-05</td>\n",
       "      <td>3.981198</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.856289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-10-06</td>\n",
       "      <td>10.327401</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.710628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-10-07</td>\n",
       "      <td>17.657474</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.418277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-10-08</td>\n",
       "      <td>25.898790</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.363121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2000-10-09</td>\n",
       "      <td>34.494040</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>0.201515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-10</td>\n",
       "      <td>45.340051</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.458545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>3.022948</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.881891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>10.131371</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.306065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27001</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-13</td>\n",
       "      <td>14.572434</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.932251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27002</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-14</td>\n",
       "      <td>22.816357</td>\n",
       "      <td>69</td>\n",
       "      <td>35</td>\n",
       "      <td>0.865276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27003 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id         ds          y  static_0  product_id     price\n",
       "0         id_00 2000-10-05   3.981198        79          45  0.856289\n",
       "1         id_00 2000-10-06  10.327401        79          45  0.710628\n",
       "2         id_00 2000-10-07  17.657474        79          45  0.418277\n",
       "3         id_00 2000-10-08  25.898790        79          45  0.363121\n",
       "4         id_00 2000-10-09  34.494040        79          45  0.201515\n",
       "...         ...        ...        ...       ...         ...       ...\n",
       "26998     id_99 2001-05-10  45.340051        69          35  0.458545\n",
       "26999     id_99 2001-05-11   3.022948        69          35  0.881891\n",
       "27000     id_99 2001-05-12  10.131371        69          35  0.306065\n",
       "27001     id_99 2001-05-13  14.572434        69          35  0.932251\n",
       "27002     id_99 2001-05-14  22.816357        69          35  0.865276\n",
       "\n",
       "[27003 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = (\n",
    "    generate_daily_series(100, n_static_features=2, static_as_categorical=False, equal_ends=True)\n",
    "    .reset_index()\n",
    "    .rename(columns={'static_1': 'product_id'})\n",
    ")\n",
    "prices = generate_prices_for_series(series, horizon=14)\n",
    "series = series.merge(prices, on=['product_id', 'ds'], how='left')\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd1c31-9270-4176-b9b1-eaaaeae3cf28",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81348566-8200-419f-9921-c6b5b655652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9713172-2263-48a5-99fd-f66b13117cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.2\")\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efe100-a3b8-4b23-93c5-8235cbe4e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_series = spark.createDataFrame(series).repartitionByRange(4, 'unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e6bb6-7cfe-4208-bae9-8e8b4cc0cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.lightgbm import LightGBMRegressor as SynapseLGBMRegressor\n",
    "from xgboost.spark import SparkXGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba790bc5-5a6d-426d-ad5e-74705f815725",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = FugueMLForecast(\n",
    "    [\n",
    "        SynapseLGBMRegressor(),\n",
    "        SparkXGBRegressor()\n",
    "    ],\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77108e-0cc2-4774-9591-9e9480b5438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:21:11] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "/home/jose/mambaforge/envs/mlforecast/lib/python3.10/site-packages/xgboost/sklearn.py:808: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>LightGBMRegressor</th>\n",
       "      <th>SparkXGBRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>42.227353</td>\n",
       "      <td>42.170174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>49.678239</td>\n",
       "      <td>49.665058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>1.425428</td>\n",
       "      <td>2.123648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>10.021719</td>\n",
       "      <td>10.150534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>18.167309</td>\n",
       "      <td>18.219870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-24</td>\n",
       "      <td>43.879492</td>\n",
       "      <td>43.089096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-25</td>\n",
       "      <td>1.592245</td>\n",
       "      <td>1.300191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>8.765065</td>\n",
       "      <td>8.563540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-27</td>\n",
       "      <td>15.720301</td>\n",
       "      <td>15.627042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-28</td>\n",
       "      <td>22.443045</td>\n",
       "      <td>23.139147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds  LightGBMRegressor  SparkXGBRegressor\n",
       "0        id_00 2001-05-15          42.227353          42.170174\n",
       "1        id_00 2001-05-16          49.678239          49.665058\n",
       "2        id_00 2001-05-17           1.425428           2.123648\n",
       "3        id_00 2001-05-18          10.021719          10.150534\n",
       "4        id_00 2001-05-19          18.167309          18.219870\n",
       "...        ...        ...                ...                ...\n",
       "1395     id_99 2001-05-24          43.879492          43.089096\n",
       "1396     id_99 2001-05-25           1.592245           1.300191\n",
       "1397     id_99 2001-05-26           8.765065           8.563540\n",
       "1398     id_99 2001-05-27          15.720301          15.627042\n",
       "1399     id_99 2001-05-28          22.443045          23.139147\n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.fit(\n",
    "    spark_series,\n",
    "    id_col='unique_id',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    static_features=['static_0', 'product_id'],\n",
    ")\n",
    "fcst.predict(14, dynamic_dfs=[prices]).as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d12b6-67f7-4a57-b341-b9b8d8400c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:21:30] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "/home/jose/mambaforge/envs/mlforecast/lib/python3.10/site-packages/xgboost/sklearn.py:808: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>LightGBMRegressor</th>\n",
       "      <th>SparkXGBRegressor</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-17</td>\n",
       "      <td>41.397289</td>\n",
       "      <td>41.412704</td>\n",
       "      <td>40.499332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-18</td>\n",
       "      <td>50.008758</td>\n",
       "      <td>49.848236</td>\n",
       "      <td>50.888323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-19</td>\n",
       "      <td>1.868972</td>\n",
       "      <td>1.531837</td>\n",
       "      <td>0.121812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-20</td>\n",
       "      <td>10.266771</td>\n",
       "      <td>9.750021</td>\n",
       "      <td>10.987977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-04-21</td>\n",
       "      <td>18.296489</td>\n",
       "      <td>17.535915</td>\n",
       "      <td>16.370385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-04-26</td>\n",
       "      <td>43.910674</td>\n",
       "      <td>43.634216</td>\n",
       "      <td>43.919033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-04-27</td>\n",
       "      <td>1.955158</td>\n",
       "      <td>1.962174</td>\n",
       "      <td>2.950931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-04-28</td>\n",
       "      <td>8.864172</td>\n",
       "      <td>8.601549</td>\n",
       "      <td>10.255720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-04-29</td>\n",
       "      <td>15.983674</td>\n",
       "      <td>15.883894</td>\n",
       "      <td>16.900854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>22.950702</td>\n",
       "      <td>23.148775</td>\n",
       "      <td>21.741976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds  LightGBMRegressor  SparkXGBRegressor          y\n",
       "0        id_00 2001-04-17          41.397289          41.412704  40.499332\n",
       "1        id_00 2001-04-18          50.008758          49.848236  50.888323\n",
       "2        id_00 2001-04-19           1.868972           1.531837   0.121812\n",
       "3        id_00 2001-04-20          10.266771           9.750021  10.987977\n",
       "4        id_00 2001-04-21          18.296489          17.535915  16.370385\n",
       "...        ...        ...                ...                ...        ...\n",
       "1395     id_99 2001-04-26          43.910674          43.634216  43.919033\n",
       "1396     id_99 2001-04-27           1.955158           1.962174   2.950931\n",
       "1397     id_99 2001-04-28           8.864172           8.601549  10.255720\n",
       "1398     id_99 2001-04-29          15.983674          15.883894  16.900854\n",
       "1399     id_99 2001-04-30          22.950702          23.148775  21.741976\n",
       "\n",
       "[1400 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = fcst.cross_validation(spark_series, n_windows=2, window_size=14, id_col='unique_id', time_col='ds', target_col='y')\n",
    "res1 = next(cv_res)\n",
    "res1.as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a734f48-fb9b-4d08-9548-ca0b53661563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:21:46] task 0 got new rank 0                                    (0 + 1) / 1]\n",
      "/home/jose/mambaforge/envs/mlforecast/lib/python3.10/site-packages/xgboost/sklearn.py:808: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>LightGBMRegressor</th>\n",
       "      <th>SparkXGBRegressor</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>41.510874</td>\n",
       "      <td>41.991829</td>\n",
       "      <td>40.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-02</td>\n",
       "      <td>49.580176</td>\n",
       "      <td>49.946548</td>\n",
       "      <td>51.332152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-03</td>\n",
       "      <td>1.699062</td>\n",
       "      <td>1.733775</td>\n",
       "      <td>3.937318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-04</td>\n",
       "      <td>10.143278</td>\n",
       "      <td>9.953071</td>\n",
       "      <td>10.813979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-05</td>\n",
       "      <td>18.001024</td>\n",
       "      <td>17.789112</td>\n",
       "      <td>16.726525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-10</td>\n",
       "      <td>43.846853</td>\n",
       "      <td>43.703159</td>\n",
       "      <td>45.340051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>1.832246</td>\n",
       "      <td>1.999386</td>\n",
       "      <td>3.022948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>8.805302</td>\n",
       "      <td>8.618651</td>\n",
       "      <td>10.131371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-13</td>\n",
       "      <td>15.946444</td>\n",
       "      <td>15.728466</td>\n",
       "      <td>14.572434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-14</td>\n",
       "      <td>22.699001</td>\n",
       "      <td>23.113226</td>\n",
       "      <td>22.816357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds  LightGBMRegressor  SparkXGBRegressor          y\n",
       "0        id_00 2001-05-01          41.510874          41.991829  40.036960\n",
       "1        id_00 2001-05-02          49.580176          49.946548  51.332152\n",
       "2        id_00 2001-05-03           1.699062           1.733775   3.937318\n",
       "3        id_00 2001-05-04          10.143278           9.953071  10.813979\n",
       "4        id_00 2001-05-05          18.001024          17.789112  16.726525\n",
       "...        ...        ...                ...                ...        ...\n",
       "1395     id_99 2001-05-10          43.846853          43.703159  45.340051\n",
       "1396     id_99 2001-05-11           1.832246           1.999386   3.022948\n",
       "1397     id_99 2001-05-12           8.805302           8.618651  10.131371\n",
       "1398     id_99 2001-05-13          15.946444          15.728466  14.572434\n",
       "1399     id_99 2001-05-14          22.699001          23.113226  22.816357\n",
       "\n",
       "[1400 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = next(cv_res)\n",
    "res2.as_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3322f-3a0f-47d8-92f2-689b525111aa",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2228d0-e004-4e40-b413-314b54c36056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "from mlforecast.distributed.models.lgb import LGBMForecast\n",
    "from mlforecast.distributed.models.xgb import XGBForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a5876-b898-4b48-940c-d5046397c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e9f0d-9d2e-41f6-a801-8f16395adb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_series = (\n",
    "    dd\n",
    "    .from_pandas(series.set_index('unique_id'), npartitions=4)  # make sure we split by the series identifier\n",
    "    .map_partitions(lambda df: df.reset_index())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96a1f8-0b77-4327-a5d7-28bc69873466",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = FugueMLForecast(\n",
    "    [LGBMForecast(), XGBForecast()],\n",
    "    freq='D',\n",
    "    lags=[1],\n",
    "    lag_transforms={\n",
    "        1: [expanding_mean]\n",
    "    },\n",
    "    date_features=['dayofweek'],\n",
    "    engine=client,\n",
    ")\n",
    "_ = fcst.fit(dask_series, id_col='unique_id', time_col='ds', target_col='y', static_features=['static_0', 'product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffef75-fcfc-4014-8ac0-e8dcf09c9b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>LGBMForecast</th>\n",
       "      <th>XGBForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-15</td>\n",
       "      <td>41.973648</td>\n",
       "      <td>42.544678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-16</td>\n",
       "      <td>49.584736</td>\n",
       "      <td>50.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>1.897230</td>\n",
       "      <td>2.404574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-18</td>\n",
       "      <td>10.047935</td>\n",
       "      <td>10.144515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00</td>\n",
       "      <td>2001-05-19</td>\n",
       "      <td>18.230554</td>\n",
       "      <td>17.768204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-24</td>\n",
       "      <td>43.668056</td>\n",
       "      <td>43.913208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-25</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>1.769517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>8.747513</td>\n",
       "      <td>8.689207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-27</td>\n",
       "      <td>15.776157</td>\n",
       "      <td>15.858318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>id_99</td>\n",
       "      <td>2001-05-28</td>\n",
       "      <td>22.791415</td>\n",
       "      <td>22.818695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id         ds  LGBMForecast  XGBForecast\n",
       "0        id_00 2001-05-15     41.973648    42.544678\n",
       "1        id_00 2001-05-16     49.584736    50.006393\n",
       "2        id_00 2001-05-17      1.897230     2.404574\n",
       "3        id_00 2001-05-18     10.047935    10.144515\n",
       "4        id_00 2001-05-19     18.230554    17.768204\n",
       "...        ...        ...           ...          ...\n",
       "1395     id_99 2001-05-24     43.668056    43.913208\n",
       "1396     id_99 2001-05-25     -0.257059     1.769517\n",
       "1397     id_99 2001-05-26      8.747513     8.689207\n",
       "1398     id_99 2001-05-27     15.776157    15.858318\n",
       "1399     id_99 2001-05-28     22.791415    22.818695\n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst.predict(14, dynamic_dfs=[prices]).as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823a224-4861-40ab-b35f-7bf522e772d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = fcst.cross_validation(dask_series, n_windows=2, window_size=14, id_col='unique_id', time_col='ds', target_col='y')\n",
    "res1 = next(cv_res)\n",
    "res1.as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b303ee-b90a-40d4-83fa-9273e20f6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = next(cv_res)\n",
    "res2.as_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
