{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2247f-be0c-4a71-bf79-d260988e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp target_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639d9d1-0b9f-41b2-b154-3172bf8cbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00a9c6-845d-4840-ad64-68a8d5430836",
   "metadata": {},
   "source": [
    "# Target transforms\n",
    "Transformations that can be applied to the target before computing the features and restored after computing the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088aa3-7a4e-4c29-98fe-940277d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import abc\n",
    "import copy\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, clone\n",
    "from utilsforecast.compat import DataFrame\n",
    "from utilsforecast.target_transforms import (\n",
    "    LocalBoxCox as BoxCox,\n",
    "    LocalMinMaxScaler as MinMaxScaler,\n",
    "    LocalRobustScaler as RobustScaler,\n",
    "    LocalStandardScaler as StandardScaler,\n",
    "    _common_scaler_inverse_transform,\n",
    "    _transform,\n",
    ")\n",
    "\n",
    "from mlforecast.grouped_array import GroupedArray, _apply_difference\n",
    "from mlforecast.utils import _ShortSeriesException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daa3f7-c214-4eb8-bd8d-e12095c0be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastcore.test import test_fail\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from utilsforecast.processing import counts_by_id\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c487eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseTargetTransform(abc.ABC):\n",
    "    \"\"\"Base class used for target transformations.\"\"\"\n",
    "    def set_column_names(self, id_col: str, time_col: str, target_col: str):\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def update(self, df: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit_transform(self, df: DataFrame) -> DataFrame:\n",
    "        ...\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def inverse_transform(self, df: DataFrame) -> DataFrame:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76764887-3aff-4e11-80b8-004da868f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseGroupedArrayTargetTransform(abc.ABC):\n",
    "    \"\"\"Base class used for target transformations that operate on grouped arrays.\"\"\"\n",
    "    idxs: Optional[np.ndarray] = None\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ...\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ...\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ...\n",
    "\n",
    "    def inverse_transform_fitted(self, ga: GroupedArray) -> GroupedArray:\n",
    "        return self.inverse_transform(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5dfb5-a9fe-4f02-8561-3ad8f14d04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Differences(BaseGroupedArrayTargetTransform):\n",
    "    \"\"\"Subtracts previous values of the serie. Can be used to remove trend or seasonalities.\"\"\"\n",
    "    store_fitted = False\n",
    "    \n",
    "    def __init__(self, differences: Iterable[int]):\n",
    "        self.differences = list(differences)\n",
    "\n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ga = copy.copy(ga)\n",
    "        self.fitted_: List[GroupedArray] = []\n",
    "        original_sizes = np.diff(ga.indptr)\n",
    "        total_diffs = sum(self.differences)\n",
    "        small_series = original_sizes < total_diffs\n",
    "        if small_series.any():\n",
    "            raise _ShortSeriesException(np.arange(ga.n_groups)[small_series])\n",
    "        self.original_values_ = []\n",
    "        n_series = len(ga.indptr) - 1\n",
    "        for d in self.differences:\n",
    "            if self.store_fitted:\n",
    "                # these are saved in order to be able to perform a correct\n",
    "                # inverse transform when trying to retrieve the fitted values.\n",
    "                self.fitted_.append(copy.copy(ga))\n",
    "            new_data = np.empty_like(ga.data, shape=n_series * d)\n",
    "            new_indptr = d * np.arange(n_series + 1, dtype=np.int32)\n",
    "            _apply_difference(ga.data, ga.indptr, new_data, new_indptr, d)\n",
    "            self.original_values_.append(GroupedArray(new_data, new_indptr))\n",
    "        return ga\n",
    "\n",
    "    def update(self, ga: GroupedArray) -> GroupedArray:\n",
    "        transformed = copy.copy(ga)\n",
    "        for d, orig_ga in zip(self.differences, self.original_values_):\n",
    "            orig_ga.update_difference(d, transformed)\n",
    "        return transformed\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ga = copy.copy(ga)\n",
    "        for d, orig_vals_ga in zip(reversed(self.differences), reversed(self.original_values_)):\n",
    "            if self.idxs is not None:\n",
    "                orig_vals_ga = orig_vals_ga.take(self.idxs)\n",
    "            orig_vals_ga.restore_difference(ga.data, d)\n",
    "        return ga\n",
    "\n",
    "    def inverse_transform_fitted(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ga = copy.copy(ga)\n",
    "        for d, fitted in zip(reversed(self.differences), reversed(self.fitted_)):\n",
    "            if self.idxs is not None:\n",
    "                fitted = fitted.take(self.idxs)\n",
    "            fitted.restore_fitted_difference(ga.data, ga.indptr, d)\n",
    "        return ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a83a1-4acb-42b5-bf13-9c2833891560",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(10, min_length=50, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8ace2-b5c1-4fd2-9f2d-2a3aecae6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = Differences([1, 2, 5])\n",
    "id_counts = counts_by_id(series, 'unique_id')\n",
    "indptr = np.append(0, id_counts['counts'].cumsum())\n",
    "ga = GroupedArray(series['y'].values, indptr)\n",
    "\n",
    "# differences are applied correctly\n",
    "transformed = diffs.fit_transform(ga)\n",
    "assert diffs.fitted_ == []\n",
    "expected = series.copy()\n",
    "for d in diffs.differences:\n",
    "    expected['y'] -= expected.groupby('unique_id')['y'].shift(d)\n",
    "np.testing.assert_allclose(transformed.data, expected['y'].values)\n",
    "\n",
    "# fitted differences are restored correctly\n",
    "diffs.store_fitted = True\n",
    "transformed = diffs.fit_transform(ga)\n",
    "keep_mask = ~np.isnan(transformed.data)\n",
    "restored = diffs.inverse_transform_fitted(transformed)\n",
    "np.testing.assert_allclose(ga.data[keep_mask], restored.data[keep_mask])\n",
    "restored_subs = diffs.inverse_transform_fitted(transformed.take_from_groups(slice(8, None)))\n",
    "np.testing.assert_allclose(ga.data[keep_mask], restored_subs.data)\n",
    "\n",
    "# test transform\n",
    "new_ga = GroupedArray(np.random.rand(10), np.arange(11))\n",
    "prev_orig = [diffs.original_values_[i].data[::d].copy() for i, d in enumerate(diffs.differences)]\n",
    "expected = new_ga.data - np.add.reduce(prev_orig)\n",
    "updates = diffs.update(new_ga)\n",
    "np.testing.assert_allclose(expected, updates.data)\n",
    "np.testing.assert_allclose(diffs.original_values_[0].data, new_ga.data)\n",
    "np.testing.assert_allclose(diffs.original_values_[1].data[1::2], new_ga.data - prev_orig[0])\n",
    "np.testing.assert_allclose(diffs.original_values_[2].data[4::5], new_ga.data - np.add.reduce(prev_orig[:2]))\n",
    "# variable sizes\n",
    "diff1 = Differences([1])\n",
    "ga = GroupedArray(np.arange(10), np.array([0, 3, 10]))\n",
    "diff1.fit_transform(ga)\n",
    "new_ga = GroupedArray(np.arange(4), np.array([0, 1, 4]))\n",
    "updates = diff1.update(new_ga)\n",
    "np.testing.assert_allclose(updates.data, np.array([0 - 2, 1 - 9, 2 - 1, 3 - 2]))\n",
    "np.testing.assert_allclose(diff1.original_values_[0].data, np.array([0, 3]))\n",
    "\n",
    "# short series\n",
    "ga = GroupedArray(np.arange(20), np.array([0, 2, 20]))\n",
    "test_fail(lambda: diffs.fit_transform(ga), contains=\"[0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67473e24-19f4-4c04-bc4b-13c313cbf52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class BaseLocalScaler(BaseGroupedArrayTargetTransform):\n",
    "    scaler_factory: type\n",
    "\n",
    "    def update(self, ga: GroupedArray) -> GroupedArray:\n",
    "        return GroupedArray(self.scaler_.transform(ga), ga.indptr)\n",
    "    \n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        self.scaler_ = self.scaler_factory()\n",
    "        transformed = self.scaler_.fit_transform(ga)\n",
    "        return GroupedArray(transformed, ga.indptr)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        stats = self.scaler_.stats_\n",
    "        if self.idxs is not None:\n",
    "            stats = stats[self.idxs]\n",
    "        if stats.shape[0] != ga.n_groups:\n",
    "            raise ValueError('Found different number of groups in scaler.')\n",
    "        transformed = _transform(ga.data, ga.indptr, stats, _common_scaler_inverse_transform)\n",
    "        return GroupedArray(transformed, ga.indptr)\n",
    "\n",
    "    def inverse_transform_fitted(self, ga: GroupedArray) -> GroupedArray:\n",
    "        return self.inverse_transform(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ece47-2f97-43a4-bf52-6a2a9cebf7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaler(sc, series):\n",
    "    id_counts = counts_by_id(series, 'unique_id')\n",
    "    indptr = np.append(0, id_counts['counts'].cumsum())\n",
    "    ga = GroupedArray(series['y'].values, indptr)\n",
    "    transformed = sc.fit_transform(ga)\n",
    "    np.testing.assert_allclose(\n",
    "        sc.inverse_transform(transformed).data,\n",
    "        ga.data,\n",
    "    )\n",
    "    transformed2 = sc.update(ga)\n",
    "    np.testing.assert_allclose(transformed.data, transformed2.data)\n",
    "    \n",
    "    idxs = [0, 7]\n",
    "    subset = ga.take(idxs)\n",
    "    transformed_subset = transformed.take(idxs)\n",
    "    sc.idxs = idxs\n",
    "    np.testing.assert_allclose(\n",
    "        sc.inverse_transform(transformed_subset).data,\n",
    "        subset.data,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f8d0e-d2a9-450d-8c95-58e5edbf4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalStandardScaler(BaseLocalScaler):\n",
    "    \"\"\"Standardizes each serie by subtracting its mean and dividing by its standard deviation.\"\"\"\n",
    "    scaler_factory = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a3c5b-5512-434d-809a-49e8b498c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalStandardScaler(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e413c9-0125-4551-923b-60209b92b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalMinMaxScaler(BaseLocalScaler):\n",
    "    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n",
    "    scaler_factory = MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2b18a-639b-466b-98fc-71a36465c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalMinMaxScaler(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb33300-24a0-4ba0-9a43-6a98b18c987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalRobustScaler(BaseLocalScaler):\n",
    "    \"\"\"Scaler robust to outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : str (default='iqr')\n",
    "        Statistic to use for scaling. Can be either 'iqr' (Inter Quartile Range) or 'mad' (Median Asbolute Deviation)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale: str):\n",
    "        self.scaler_factory = lambda: RobustScaler(scale)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368179bc-ba11-49ec-a015-dca1c0827e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalRobustScaler(scale='iqr'), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a97f26-3b4f-4441-9887-0dd537c73a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalRobustScaler(scale='mad'), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fccb7-7e8c-4cca-a6e4-fbf64d10bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalBoxCox(BaseLocalScaler):\n",
    "    \"\"\"Finds the optimum lambda for each serie and applies the Box-Cox transformation\"\"\"\n",
    "    def __init__(self):\n",
    "        self.scaler_ = BoxCox()\n",
    "    \n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        return GroupedArray(self.scaler_.fit_transform(ga), ga.indptr)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        from scipy.special import inv_boxcox1p\n",
    "\n",
    "        sizes = np.diff(ga.indptr)\n",
    "        lmbdas = self.scaler_.lmbdas_\n",
    "        if self.idxs is not None:\n",
    "            lmbdas = lmbdas[self.idxs]\n",
    "        lmbdas = np.repeat(lmbdas, sizes, axis=0)\n",
    "        return GroupedArray(inv_boxcox1p(ga.data, lmbdas), ga.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5bf731-2d9a-4c08-9c60-c4fbc9af2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalBoxCox(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffb5e1-43db-48b9-8436-29b09e0dded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GlobalSklearnTransformer(BaseTargetTransform):\n",
    "    \"\"\"Applies the same scikit-learn transformer to all series.\"\"\"    \n",
    "    def __init__(self, transformer: TransformerMixin):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def update(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy(deep=False)\n",
    "        df[self.target_col] = self.transformer_.transform(df[[self.target_col]].values)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy(deep=False)\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        df[self.target_col] = self.transformer_.fit_transform(df[[self.target_col]].values)\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy(deep=False)\n",
    "        cols_to_transform = df.columns.drop([self.id_col, self.time_col])\n",
    "        for col in cols_to_transform:\n",
    "            df[col] = self.transformer_.inverse_transform(df[[col]].values)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d714474-fd4e-416a-bd5c-e093423ded38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this import in order for isinstance to work\n",
    "from mlforecast.target_transforms import Differences as ExportedDifferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a2af6-53ed-4dc6-8c79-99d21eb97257",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_boxcox = PowerTransformer(method='box-cox', standardize=False)\n",
    "boxcox_global = GlobalSklearnTransformer(sk_boxcox)\n",
    "single_difference = ExportedDifferences([1])\n",
    "series = generate_daily_series(10)\n",
    "fcst = MLForecast(\n",
    "    models=[LinearRegression()],\n",
    "    freq='D',\n",
    "    lags=[1, 2],\n",
    "    target_transforms=[boxcox_global, single_difference]\n",
    ")\n",
    "prep = fcst.preprocess(series, dropna=False)\n",
    "expected = (\n",
    "    pd.Series(\n",
    "        sk_boxcox.fit_transform(series[['y']])[:, 0], index=series['unique_id']\n",
    "    ).groupby('unique_id')\n",
    "    .diff()\n",
    "    .values\n",
    ")\n",
    "np.testing.assert_allclose(prep['y'].values, expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
