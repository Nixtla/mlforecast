{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2247f-be0c-4a71-bf79-d260988e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp target_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639d9d1-0b9f-41b2-b154-3172bf8cbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00a9c6-845d-4840-ad64-68a8d5430836",
   "metadata": {},
   "source": [
    "# Target transforms\n",
    "Transformations that can be applied to the target before computing the features and restored after computing the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088aa3-7a4e-4c29-98fe-940277d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import abc\n",
    "import copy\n",
    "import reprlib\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, clone\n",
    "from numba import njit\n",
    "from utilsforecast.compat import DataFrame\n",
    "from utilsforecast.target_transforms import (\n",
    "    LocalBoxCox as BoxCox,\n",
    "    LocalMinMaxScaler as MinMaxScaler,\n",
    "    LocalRobustScaler as RobustScaler,\n",
    "    LocalStandardScaler as StandardScaler,\n",
    "    _common_scaler_inverse_transform,\n",
    "    _transform,\n",
    ")\n",
    "\n",
    "from mlforecast.grouped_array import GroupedArray, _apply_difference\n",
    "from mlforecast.utils import _ensure_shallow_copy, _ShortSeriesException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daa3f7-c214-4eb8-bd8d-e12095c0be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastcore.test import test_fail\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.utils import generate_daily_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c487eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseTargetTransform(abc.ABC):\n",
    "    \"\"\"Base class used for target transformations.\"\"\"\n",
    "    def set_column_names(self, id_col: str, time_col: str, target_col: str):\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit_transform(self, df: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def inverse_transform(self, df: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76764887-3aff-4e11-80b8-004da868f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseGroupedArrayTargetTransform(abc.ABC):\n",
    "    \"\"\"Base class used for target transformations that operate on grouped arrays.\"\"\"\n",
    "    idxs: Optional[np.ndarray] = None\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5dfb5-a9fe-4f02-8561-3ad8f14d04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Differences(BaseGroupedArrayTargetTransform):\n",
    "    \"\"\"Subtracts previous values of the serie. Can be used to remove trend or seasonalities.\"\"\"\n",
    "    store_fitted = False\n",
    "    \n",
    "    def __init__(self, differences: Iterable[int]):\n",
    "        self.differences = list(differences)\n",
    "\n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ga = copy.copy(ga)\n",
    "        self.fitted_: List[GroupedArray] = []\n",
    "        original_sizes = np.diff(ga.indptr)\n",
    "        total_diffs = sum(self.differences)\n",
    "        small_series = original_sizes < total_diffs\n",
    "        if small_series.any():\n",
    "            raise _ShortSeriesException(np.arange(ga.ngroups)[small_series])\n",
    "        self.original_values_ = []\n",
    "        n_series = len(ga.indptr) - 1\n",
    "        for d in self.differences:\n",
    "            if self.store_fitted:\n",
    "                # these are saved in order to be able to perform a correct\n",
    "                # inverse transform when trying to retrieve the fitted values.\n",
    "                self.fitted_.append(copy.copy(ga))\n",
    "            new_data = np.empty_like(ga.data, shape=n_series * d)\n",
    "            new_indptr = d * np.arange(n_series + 1, dtype=np.int32)\n",
    "            _apply_difference(ga.data, ga.indptr, new_data, new_indptr, d)\n",
    "            self.original_values_.append(GroupedArray(new_data, new_indptr))\n",
    "        return ga\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        ga = copy.copy(ga)\n",
    "        for d, orig_vals_ga in zip(reversed(self.differences), reversed(self.original_values_)):\n",
    "            if self.idxs is not None:\n",
    "                orig_vals_ga = orig_vals_ga.take(self.idxs)\n",
    "            orig_vals_ga.restore_difference(ga.data, d)\n",
    "        return ga\n",
    "\n",
    "    def inverse_transform_fitted(self, ga: GroupedArray) -> pd.DataFrame:\n",
    "        ga = copy.copy(ga)\n",
    "        for d, orig_vals_ga in zip(reversed(self.differences), reversed(self.fitted_)):\n",
    "            orig_vals_ga.restore_fitted_difference(ga.data, ga.indptr, d)\n",
    "        return ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a83a1-4acb-42b5-bf13-9c2833891560",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_daily_series(10, min_length=50, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8ace2-b5c1-4fd2-9f2d-2a3aecae6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = Differences([1, 2, 5])\n",
    "ga = GroupedArray.from_sorted_df(series, 'unique_id', 'ds', 'y')\n",
    "\n",
    "# differences are applied correctly\n",
    "transformed = diffs.fit_transform(ga)\n",
    "assert diffs.fitted_ == []\n",
    "expected = series.copy()\n",
    "for d in diffs.differences:\n",
    "    expected['y'] -= expected.groupby('unique_id')['y'].shift(d)\n",
    "np.testing.assert_allclose(transformed.data, expected['y'].values)\n",
    "\n",
    "# fitted differences are restored correctly\n",
    "diffs.store_fitted = True\n",
    "transformed = diffs.fit_transform(ga)\n",
    "keep_mask = ~np.isnan(transformed.data)\n",
    "restored = diffs.inverse_transform_fitted(transformed)\n",
    "np.testing.assert_allclose(ga.data[keep_mask], restored.data[keep_mask])\n",
    "restored_subs = diffs.inverse_transform_fitted(transformed.take_from_groups(slice(8, None)))\n",
    "np.testing.assert_allclose(ga.data[keep_mask], restored_subs.data)\n",
    "\n",
    "# short series\n",
    "ga = GroupedArray(np.arange(20), np.array([0, 2, 20]))\n",
    "test_fail(lambda: diffs.fit_transform(ga), contains=\"[0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67473e24-19f4-4c04-bc4b-13c313cbf52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class BaseLocalScaler(BaseGroupedArrayTargetTransform):\n",
    "    \"\"\"Standardizes each serie by subtracting its mean and dividing by its standard deviation.\"\"\"\n",
    "    scaler_factory: type\n",
    "    \n",
    "    def fit_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        self.scaler_ = self.scaler_factory()\n",
    "        transformed = self.scaler_.fit_transform(ga)\n",
    "        return GroupedArray(transformed, ga.indptr)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> GroupedArray:\n",
    "        stats = self.scaler_.stats_\n",
    "        if self.idxs is not None:\n",
    "            stats = stats[self.idxs]\n",
    "        transformed = _transform(ga.data, ga.indptr, stats, _common_scaler_inverse_transform)\n",
    "        return GroupedArray(transformed, ga.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ece47-2f97-43a4-bf52-6a2a9cebf7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaler(sc, series):\n",
    "    ga = GroupedArray.from_sorted_df(series, 'unique_id', 'ds', 'y')\n",
    "    transformed = sc.fit_transform(ga)\n",
    "    np.testing.assert_allclose(\n",
    "        sc.inverse_transform(transformed).data,\n",
    "        ga.data,\n",
    "    )\n",
    "    \n",
    "    def filter_df(df):\n",
    "        return (\n",
    "            df[df['unique_id'].isin(['id_0', 'id_7'])]\n",
    "            .groupby('unique_id', observed=True)\n",
    "            .head(10)\n",
    "        )\n",
    "    \n",
    "    idxs = [0, 7]\n",
    "    subset = ga.take(idxs)\n",
    "    transformed_subset = transformed.take(idxs)\n",
    "    sc.idxs = idxs\n",
    "    np.testing.assert_allclose(\n",
    "        sc.inverse_transform(transformed_subset).data,\n",
    "        subset.data,\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f8d0e-d2a9-450d-8c95-58e5edbf4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalStandardScaler(BaseLocalScaler):\n",
    "    \"\"\"Standardizes each serie by subtracting its mean and dividing by its standard deviation.\"\"\"\n",
    "    scaler_factory = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a3c5b-5512-434d-809a-49e8b498c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalStandardScaler(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e413c9-0125-4551-923b-60209b92b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalMinMaxScaler(BaseLocalScaler):\n",
    "    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n",
    "    scaler_factory = MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2b18a-639b-466b-98fc-71a36465c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalMinMaxScaler(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb33300-24a0-4ba0-9a43-6a98b18c987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalRobustScaler(BaseLocalScaler):\n",
    "    \"\"\"Scaler robust to outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : str (default='iqr')\n",
    "        Statistic to use for scaling. Can be either 'iqr' (Inter Quartile Range) or 'mad' (Median Asbolute Deviation)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale: str):\n",
    "        self.scaler_factory = lambda: RobustScaler(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368179bc-ba11-49ec-a015-dca1c0827e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalRobustScaler(scale='iqr'), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a97f26-3b4f-4441-9887-0dd537c73a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler(LocalRobustScaler(scale='mad'), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffb5e1-43db-48b9-8436-29b09e0dded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GlobalSklearnTransformer(BaseTargetTransform):\n",
    "    \"\"\"Applies the same scikit-learn transformer to all series.\"\"\"    \n",
    "    def __init__(self, transformer: TransformerMixin):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy(deep=False)\n",
    "        self.transformer_ = clone(self.transformer)\n",
    "        df[self.target_col] = self.transformer_.fit_transform(df[[self.target_col]].values)\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy(deep=False)\n",
    "        cols_to_transform = df.columns.drop([self.id_col, self.time_col])\n",
    "        for col in cols_to_transform:\n",
    "            df[col] = self.transformer_.inverse_transform(df[[col]].values)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d714474-fd4e-416a-bd5c-e093423ded38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need this import in order for isinstance to work\n",
    "from mlforecast.target_transforms import Differences as ExportedDifferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a2af6-53ed-4dc6-8c79-99d21eb97257",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_boxcox = PowerTransformer(method='box-cox', standardize=False)\n",
    "boxcox_global = GlobalSklearnTransformer(sk_boxcox)\n",
    "single_difference = ExportedDifferences([1])\n",
    "series = generate_daily_series(10)\n",
    "fcst = MLForecast(\n",
    "    models=[LinearRegression()],\n",
    "    freq='D',\n",
    "    lags=[1, 2],\n",
    "    target_transforms=[boxcox_global, single_difference]\n",
    ")\n",
    "prep = fcst.preprocess(series, dropna=False)\n",
    "expected = (\n",
    "    pd.Series(\n",
    "        sk_boxcox.fit_transform(series[['y']])[:, 0], index=series['unique_id']\n",
    "    ).groupby('unique_id')\n",
    "    .diff()\n",
    "    .values\n",
    ")\n",
    "np.testing.assert_allclose(prep['y'].values, expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
