[
  {
    "objectID": "callbacks.html",
    "href": "callbacks.html",
    "title": "Callbacks",
    "section": "",
    "text": "SaveFeatures\n\n SaveFeatures ()\n\nSaves the features in every timestamp.\n\n\n\nSaveFeatures.get_features\n\n SaveFeatures.get_features (with_step:bool=False)\n\nRetrieves the input features for every timestep\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nwith_step\nbool\nFalse\nAdd a column indicating the step\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nDataFrame with input features\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.models.dask.lgb.html",
    "href": "distributed.models.dask.lgb.html",
    "title": "DaskLGBMForecast",
    "section": "",
    "text": "Wrapper of lightgbm.dask.DaskLGBMRegressor that adds a model_ property that contains the fitted booster and is sent to the workers to in the forecasting step.\n\n\nDaskLGBMForecast\n\n DaskLGBMForecast (boosting_type:str='gbdt', num_leaves:int=31,\n                   max_depth:int=-1, learning_rate:float=0.1,\n                   n_estimators:int=100, subsample_for_bin:int=200000, obj\n                   ective:Union[str,Callable[[Optional[numpy.ndarray],nump\n                   y.ndarray],Tuple[numpy.ndarray,numpy.ndarray]],Callable\n                   [[Optional[numpy.ndarray],numpy.ndarray,Optional[numpy.\n                   ndarray]],Tuple[numpy.ndarray,numpy.ndarray]],Callable[\n                   [Optional[numpy.ndarray],numpy.ndarray,Optional[numpy.n\n                   darray],Optional[numpy.ndarray]],Tuple[numpy.ndarray,nu\n                   mpy.ndarray]],NoneType]=None,\n                   class_weight:Union[dict,str,NoneType]=None,\n                   min_split_gain:float=0.0, min_child_weight:float=0.001,\n                   min_child_samples:int=20, subsample:float=1.0,\n                   subsample_freq:int=0, colsample_bytree:float=1.0,\n                   reg_alpha:float=0.0, reg_lambda:float=0.0, random_state\n                   :Union[int,numpy.random.mtrand.RandomState,NoneType]=No\n                   ne, n_jobs:Optional[int]=None,\n                   importance_type:str='split',\n                   client:Optional[distributed.client.Client]=None,\n                   **kwargs:Any)\n\nDistributed version of lightgbm.LGBMRegressor.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.forecast.html",
    "href": "distributed.forecast.html",
    "title": "Distributed Forecast",
    "section": "",
    "text": "DistributedMLForecast\n\n DistributedMLForecast (models,\n                        freq:Union[int,str,pandas._libs.tslibs.offsets.Bas\n                        eOffset], lags:Optional[Iterable[int]]=None, lag_t\n                        ransforms:Optional[Dict[int,List[Union[Callable,Tu\n                        ple[Callable,Any]]]]]=None, date_features:Optional\n                        [Iterable[Union[str,Callable]]]=None,\n                        num_threads:int=1, target_transforms:Optional[List\n                        [Union[mlforecast.target_transforms.BaseTargetTran\n                        sform,mlforecast.target_transforms.BaseGroupedArra\n                        yTargetTransform]]]=None, engine=None,\n                        num_partitions:Optional[int]=None)\n\nMulti backend distributed pipeline\n\n\n\nDistributedMLForecast.fit\n\n DistributedMLForecast.fit (df:~AnyDataFrame, id_col:str='unique_id',\n                            time_col:str='ds', target_col:str='y',\n                            static_features:Optional[List[str]]=None,\n                            dropna:bool=True,\n                            keep_last_n:Optional[int]=None)\n\nApply the feature engineering and train the models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nAnyDataFrame\n\nSeries data in long format.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nReturns\nDistributedMLForecast\n\nForecast object with series values and trained models.\n\n\n\n\n\n\nDistributedMLForecast.predict\n\n DistributedMLForecast.predict (h:int,\n                                before_predict_callback:Optional[Callable]\n                                =None, after_predict_callback:Optional[Cal\n                                lable]=None,\n                                new_df:Optional[~AnyDataFrame]=None)\n\nCompute the predictions for the next horizon steps.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon.\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\nnew_df\ntyping.Optional[~AnyDataFrame]\nNone\nSeries data of new observations for which forecasts are to be generated. This dataframe should have the same structure as the one used to fit the model, including any features and time series data. If new_df is not None, the method will generate forecasts for the new observations.\n\n\nReturns\nAnyDataFrame\n\nPredictions for each serie and timestep, with one column per model.\n\n\n\n\n\n\nDistributedMLForecast.preprocess\n\n DistributedMLForecast.preprocess (df:~AnyDataFrame,\n                                   id_col:str='unique_id',\n                                   time_col:str='ds', target_col:str='y', \n                                   static_features:Optional[List[str]]=Non\n                                   e, dropna:bool=True,\n                                   keep_last_n:Optional[int]=None)\n\nAdd the features to data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nAnyDataFrame\n\nSeries data in long format.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nReturns\nAnyDataFrame\n\ndf with added features.\n\n\n\n\n\n\nDistributedMLForecast.cross_validation\n\n DistributedMLForecast.cross_validation (df:~AnyDataFrame, n_windows:int,\n                                         h:int, id_col:str='unique_id',\n                                         time_col:str='ds',\n                                         target_col:str='y',\n                                         step_size:Optional[int]=None, sta\n                                         tic_features:Optional[List[str]]=\n                                         None, dropna:bool=True,\n                                         keep_last_n:Optional[int]=None,\n                                         refit:bool=True, before_predict_c\n                                         allback:Optional[Callable]=None, \n                                         after_predict_callback:Optional[C\n                                         allable]=None,\n                                         input_size:Optional[int]=None)\n\nPerform time series cross validation. Creates n_windows splits where each window has h test periods, trains the models, computes the predictions and merges the actuals.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nAnyDataFrame\n\nSeries data in long format.\n\n\nn_windows\nint\n\nNumber of windows to evaluate.\n\n\nh\nint\n\nNumber of test periods in each window.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstep_size\ntyping.Optional[int]\nNone\nStep size between each cross validation window. If None it will be equal to h.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nrefit\nbool\nTrue\nRetrain model for each cross validation window.If False, the models are trained at the beginning and then used to predict each window.\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\ninput_size\ntyping.Optional[int]\nNone\nMaximum training samples per serie in each window. If None, will use an expanding window.\n\n\nReturns\nAnyDataFrame\n\nPredictions for each window with the series id, timestamp, target value and predictions from each model.\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/training_with_numpy.html",
    "href": "docs/how-to-guides/training_with_numpy.html",
    "title": "Training with numpy arrays",
    "section": "",
    "text": "Most of the machine learning libraries use numpy arrays, even when you provide a dataframe it ends up being converted into a numpy array. By providing an array to those models we can make the process faster, since the conversion will only happen once.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/training_with_numpy.html#data-setup",
    "href": "docs/how-to-guides/training_with_numpy.html#data-setup",
    "title": "Training with numpy arrays",
    "section": "Data setup",
    "text": "Data setup\n\nfrom mlforecast.utils import generate_daily_series\n\n\nseries = generate_daily_series(5)"
  },
  {
    "objectID": "docs/how-to-guides/training_with_numpy.html#fit-and-cross_validation-methods",
    "href": "docs/how-to-guides/training_with_numpy.html#fit-and-cross_validation-methods",
    "title": "Training with numpy arrays",
    "section": "fit and cross_validation methods",
    "text": "fit and cross_validation methods\n\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom mlforecast import MLForecast\n\n\nfcst = MLForecast(\n    models={'lr': LinearRegression(), 'lgbm': LGBMRegressor(verbosity=-1)},\n    freq='D',\n    lags=[7, 14],\n    date_features=['dayofweek'],\n)\n\nIf you’re using the fit/cross_validation methods from MLForecast all you have to do to train with numpy arrays is provide the as_numpy argument, which will cast the features to an array before passing them to the models.\n\nfcst.fit(series, as_numpy=True)\n\nMLForecast(models=[lr, lgbm], freq=&lt;Day&gt;, lag_features=['lag7', 'lag14'], date_features=['dayofweek'], num_threads=1)\n\n\nWhen predicting, the new features will also be cast to arrays, so it can also be faster.\n\nfcst.predict(1)\n\n\n\n\n\n\n\n\nunique_id\nds\nlr\nlgbm\n\n\n\n\n0\nid_0\n2000-08-10\n5.268787\n6.322262\n\n\n1\nid_1\n2000-04-07\n4.437316\n5.213255\n\n\n2\nid_2\n2000-06-16\n3.246518\n4.373904\n\n\n3\nid_3\n2000-08-30\n0.144860\n1.285219\n\n\n4\nid_4\n2001-01-08\n2.211318\n3.236700\n\n\n\n\n\n\n\nFor cross_validation we also just need to specify as_numpy=True.\n\ncv_res = fcst.cross_validation(series, n_windows=2, h=2, as_numpy=True)"
  },
  {
    "objectID": "docs/how-to-guides/training_with_numpy.html#preprocess-method",
    "href": "docs/how-to-guides/training_with_numpy.html#preprocess-method",
    "title": "Training with numpy arrays",
    "section": "preprocess method",
    "text": "preprocess method\nHaving the features as a numpy array can also be helpful in cases where you have categorical columns and the library doesn’t support them, for example LightGBM with polars. In order to use categorical features with LightGBM and polars we have to convert them to their integer representation and tell LightGBM to treat those features as categorical, which we can achieve in the following way:\n\nseries_pl = generate_daily_series(5, n_static_features=1, engine='polars')\nseries_pl.head(2)\n\n\nshape: (2, 4)\n\n\n\nunique_id\nds\ny\nstatic_0\n\n\ncat\ndatetime[ns]\nf64\ncat\n\n\n\n\n\"id_0\"\n2000-01-01 00:00:00\n36.462689\n\"84\"\n\n\n\"id_0\"\n2000-01-02 00:00:00\n121.008199\n\"84\"\n\n\n\n\n\n\n\nfcst = MLForecast(\n    models=[],\n    freq='1d',\n    lags=[7, 14],\n    date_features=['weekday'],\n)\n\nIn order to get the features as an array with the preprocess method we also have to ask for the X, y tuple.\n\nX, y = fcst.preprocess(series_pl, return_X_y=True, as_numpy=True)\nX[:2]\n\narray([[  0.        ,  20.30076749,  36.46268875,   6.        ],\n       [  0.        , 119.51717097, 121.0081989 ,   7.        ]])\n\n\nThe feature names are available in fcst.ts.features_order_\n\nfcst.ts.features_order_\n\n['static_0', 'lag7', 'lag14', 'weekday']\n\n\nNow we can just train a LightGBM model specifying the feature names and which features should be treated as categorical.\n\nmodel = LGBMRegressor(verbosity=-1)\nmodel.fit(\n    X=X,\n    y=y,\n    feature_name=fcst.ts.features_order_,\n    categorical_feature=['static_0', 'weekday'],\n);\n\nWe can now add this model to our models dict, as described in the custom training guide.\n\nfcst.models_ = {'lgbm': model}\n\nAnd use it to predict.\n\nfcst.predict(1)\n\n\nshape: (5, 3)\n\n\n\nunique_id\nds\nlgbm\n\n\ncat\ndatetime[ns]\nf64\n\n\n\n\n\"id_0\"\n2000-08-10 00:00:00\n448.796188\n\n\n\"id_1\"\n2000-04-07 00:00:00\n81.058211\n\n\n\"id_2\"\n2000-06-16 00:00:00\n4.450549\n\n\n\"id_3\"\n2000-08-30 00:00:00\n14.219603\n\n\n\"id_4\"\n2001-01-08 00:00:00\n87.361881"
  },
  {
    "objectID": "docs/how-to-guides/one_model_per_horizon.html",
    "href": "docs/how-to-guides/one_model_per_horizon.html",
    "title": "One model per step",
    "section": "",
    "text": "By default mlforecast uses the recursive strategy, i.e. a model is trained to predict the next value and if we’re predicting several values we do it one at a time and then use the model’s predictions as the new target, recompute the features and predict the next step.\nThere’s another approach where if we want to predict 10 steps ahead we train 10 different models, where each model is trained to predict the value at each specific step, i.e. one model predicts the next value, another one predicts the value two steps ahead and so on. This can be very time consuming but can also provide better results. If you want to use this approach you can specify max_horizon in MLForecast.fit, which will train that many models and each model will predict its corresponding horizon when you call MLForecast.predict.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/one_model_per_horizon.html#setup",
    "href": "docs/how-to-guides/one_model_per_horizon.html#setup",
    "title": "One model per step",
    "section": "Setup",
    "text": "Setup\n\nimport random\nimport lightgbm as lgb\nimport pandas as pd\nfrom datasetsforecast.m4 import M4, M4Info\nfrom utilsforecast.evaluation import evaluate\nfrom utilsforecast.losses import smape\nfrom window_ops.ewm import ewm_mean\nfrom window_ops.rolling import rolling_mean\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\n\n\nData\nWe will use four random series from the M4 dataset\n\ngroup = 'Hourly'\nawait M4.async_download('data', group=group)\ndf, *_ = M4.load(directory='data', group=group)\ndf['ds'] = df['ds'].astype('int')\nids = df['unique_id'].unique()\nrandom.seed(0)\nsample_ids = random.choices(ids, k=4)\nsample_df = df[df['unique_id'].isin(sample_ids)]\ninfo = M4Info[group]\nhorizon = info.horizon\nvalid = sample_df.groupby('unique_id').tail(horizon)\ntrain = sample_df.drop(valid.index)\n\n\ndef avg_smape(df):\n    \"\"\"Computes the SMAPE by serie and then averages it across all series.\"\"\"\n    full = df.merge(valid)\n    return (\n        evaluate(full, metrics=[smape])\n        .drop(columns='metric')\n        .set_index('unique_id')\n        .squeeze()\n    )"
  },
  {
    "objectID": "docs/how-to-guides/one_model_per_horizon.html#model",
    "href": "docs/how-to-guides/one_model_per_horizon.html#model",
    "title": "One model per step",
    "section": "Model",
    "text": "Model\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(random_state=0, verbosity=-1),\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        1: [(rolling_mean, 24)],\n        24: [(rolling_mean, 24)],\n        48: [(ewm_mean, 0.3)],\n    },\n    num_threads=1,\n    target_transforms=[Differences([24])],\n)\n\n\nhorizon = 24\n# the following will train 24 models, one for each horizon\nindividual_fcst = fcst.fit(train, max_horizon=horizon)\nindividual_preds = individual_fcst.predict(horizon)\navg_smape_individual = avg_smape(individual_preds).rename('individual')\n# the following will train a single model and use the recursive strategy\nrecursive_fcst = fcst.fit(train)\nrecursive_preds = recursive_fcst.predict(horizon)\navg_smape_recursive = avg_smape(recursive_preds).rename('recursive')\n# results\nprint('Average SMAPE per method and serie')\navg_smape_individual.to_frame().join(avg_smape_recursive).applymap('{:.1%}'.format)\n\nAverage SMAPE per method and serie\n\n\n\n\n\n\n\n\n\nindividual\nrecursive\n\n\nunique_id\n\n\n\n\n\n\nH196\n0.3%\n0.3%\n\n\nH256\n0.4%\n0.3%\n\n\nH381\n20.9%\n9.5%\n\n\nH413\n11.9%\n13.6%"
  },
  {
    "objectID": "docs/how-to-guides/predict_callbacks.html",
    "href": "docs/how-to-guides/predict_callbacks.html",
    "title": "Predict callbacks",
    "section": "",
    "text": "If you want to do something to the input before predicting or something to the output before it gets used to update the target (and thus the next features that rely on lags), you can pass a function to run at any of these times.\nHere are a couple of examples:\nimport lightgbm as lgb\nimport numpy as np\nfrom IPython.display import display\n\nfrom mlforecast import MLForecast\nfrom mlforecast.utils import generate_daily_series\nseries = generate_daily_series(1)\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/predict_callbacks.html#before-predicting",
    "href": "docs/how-to-guides/predict_callbacks.html#before-predicting",
    "title": "Predict callbacks",
    "section": "Before predicting",
    "text": "Before predicting\n\nInspecting the input\nWe can define a function that displays our input dataframe before predicting.\n\ndef inspect_input(new_x):\n    \"\"\"Displays the model inputs to inspect them\"\"\"\n    display(new_x)\n    return new_x\n\nAnd now we can pass this function to the before_predict_callback argument of MLForecast.predict.\n\nfcst = MLForecast(lgb.LGBMRegressor(verbosity=-1), freq='D', lags=[1, 2])\nfcst.fit(series, static_features=['unique_id'])\npreds = fcst.predict(2, before_predict_callback=inspect_input)\npreds\n\n\n\n\n\n\n\n\nunique_id\nlag1\nlag2\n\n\n\n\n0\nid_0\n4.15593\n3.000028\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunique_id\nlag1\nlag2\n\n\n\n\n0\nid_0\n5.250205\n4.15593\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\n\n\n\n\n0\nid_0\n2000-08-10\n5.250205\n\n\n1\nid_0\n2000-08-11\n6.241739\n\n\n\n\n\n\n\n\n\nSaving the input features\nSaving the features that are sent as input to the model in each timestamp can be helpful, for example to estimate SHAP values. This can be easily achieved with the SaveFeatures callback.\n\nfrom mlforecast.callbacks import SaveFeatures\n\n\nfcst = MLForecast(lgb.LGBMRegressor(verbosity=-1), freq='D', lags=[1])\nfcst.fit(series, static_features=['unique_id'])\nsave_features_cbk = SaveFeatures()\nfcst.predict(2, before_predict_callback=save_features_cbk);\n\nOnce we’ve called predict we can just retrieve the features.\n\nsave_features_cbk.get_features()\n\n\n\n\n\n\n\n\nunique_id\nlag1\n\n\n\n\n0\nid_0\n4.155930\n\n\n1\nid_0\n5.281643"
  },
  {
    "objectID": "docs/how-to-guides/predict_callbacks.html#after-predicting",
    "href": "docs/how-to-guides/predict_callbacks.html#after-predicting",
    "title": "Predict callbacks",
    "section": "After predicting",
    "text": "After predicting\nWhen predicting with the recursive strategy (the default) the predictions for each timestamp are used to update the target and recompute the features. If you want to do something to these predictions before that happens you can use the after_predict_callback argument of MLForecast.predict.\n\nIncreasing predictions values\nSuppose we know that our model always underestimates and we want to prevent that from happening by making our predictions 10% higher. We can achieve that with the following:\n\ndef increase_predictions(predictions):\n    \"\"\"Increases all predictions by 10%\"\"\"\n    return 1.1 * predictions\n\n\nfcst = MLForecast(\n    {'model': lgb.LGBMRegressor(verbosity=-1)},\n    freq='D',\n    date_features=['dayofweek'],\n)\nfcst.fit(series)\noriginal_preds = fcst.predict(2)\nscaled_preds = fcst.predict(2, after_predict_callback=increase_predictions)\nnp.testing.assert_array_less(\n    original_preds['model'].values,\n    scaled_preds['model'].values,\n)"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html",
    "href": "docs/how-to-guides/prediction_intervals.html",
    "title": "Probabilistic forecasting",
    "section": "",
    "text": "Prerequesites\n\n\n\n\n\nThis tutorial assumes basic familiarity with MLForecast. For a minimal example visit the Quick Start\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#introduction",
    "href": "docs/how-to-guides/prediction_intervals.html#introduction",
    "title": "Probabilistic forecasting",
    "section": "Introduction",
    "text": "Introduction\nWhen we generate a forecast, we usually produce a single value known as the point forecast. This value, however, doesn’t tell us anything about the uncertainty associated with the forecast. To have a measure of this uncertainty, we need prediction intervals.\nA prediction interval is a range of values that the forecast can take with a given probability. Hence, a 95% prediction interval should contain a range of values that include the actual future value with probability 95%. Probabilistic forecasting aims to generate the full forecast distribution. Point forecasting, on the other hand, usually returns the mean or the median or said distribution. However, in real-world scenarios, it is better to forecast not only the most probable future outcome, but many alternative outcomes as well.\nWith MLForecast you can train sklearn models to generate point forecasts. It also takes the advantages of ConformalPrediction to generate the same point forecasts and adds them prediction intervals. By the end of this tutorial, you’ll have a good understanding of how to add probabilistic intervals to sklearn models for time series forecasting. Furthermore, you’ll also learn how to generate plots with the historical data, the point forecasts, and the prediction intervals.\n\n\n\n\n\n\nImportant\n\n\n\nAlthough the terms are often confused, prediction intervals are not the same as confidence intervals.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn practice, most prediction intervals are too narrow since models do not account for all sources of uncertainty. A discussion about this can be found here.\n\n\nOutline:\n\nInstall libraries\nLoad and explore the data\nTrain models\nPlot prediction intervals\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#install-libraries",
    "href": "docs/how-to-guides/prediction_intervals.html#install-libraries",
    "title": "Probabilistic forecasting",
    "section": "Install libraries",
    "text": "Install libraries\nInstall the necessary packages using pip install mlforecast utilsforecast"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#load-and-explore-the-data",
    "href": "docs/how-to-guides/prediction_intervals.html#load-and-explore-the-data",
    "title": "Probabilistic forecasting",
    "section": "Load and explore the data",
    "text": "Load and explore the data\nFor this example, we’ll use the hourly dataset from the M4 Competition. We first need to download the data from a URL and then load it as a pandas dataframe. Notice that we’ll load the train and the test data separately. We’ll also rename the y column of the test data as y_test.\n\nimport pandas as pd\nfrom utilsforecast.plotting import plot_series\n\n\ntrain = pd.read_csv('https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv')\ntest = pd.read_csv('https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv')\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH1\n1\n605.0\n\n\n1\nH1\n2\n586.0\n\n\n2\nH1\n3\n586.0\n\n\n3\nH1\n4\n559.0\n\n\n4\nH1\n5\n511.0\n\n\n\n\n\n\n\n\ntest.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH1\n701\n619.0\n\n\n1\nH1\n702\n565.0\n\n\n2\nH1\n703\n532.0\n\n\n3\nH1\n704\n495.0\n\n\n4\nH1\n705\n481.0\n\n\n\n\n\n\n\nSince the goal of this notebook is to generate prediction intervals, we’ll only use the first 8 series of the dataset to reduce the total computational time.\n\nn_series = 8 \nuids = train['unique_id'].unique()[:n_series] # select first n_series of the dataset\ntrain = train.query('unique_id in @uids')\ntest = test.query('unique_id in @uids')\n\nWe can plot these series using the plot_series function from the utilsforecast library. This function has multiple parameters, and the required ones to generate the plots in this notebook are explained below.\n\ndf: A pandas dataframe with columns [unique_id, ds, y].\nforecasts_df: A pandas dataframe with columns [unique_id, ds] and models.\nplot_random: bool = True. Plots the time series randomly.\nmodels: List[str]. A list with the models we want to plot.\nlevel: List[float]. A list with the prediction intervals we want to plot.\nengine: str = matplotlib. It can also be plotly. plotly generates interactive plots, while matplotlib generates static plots.\n\n\nfig = plot_series(train, test.rename(columns={'y': 'y_test'}), models=['y_test'], plot_random=False)"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#train-models",
    "href": "docs/how-to-guides/prediction_intervals.html#train-models",
    "title": "Probabilistic forecasting",
    "section": "Train models",
    "text": "Train models\nMLForecast can train multiple models that follow the sklearn syntax (fit and predict) on different time series efficiently.\nFor this example, we’ll use the following sklearn baseline models:\n\nLasso\nLinearRegression\nRidge\nK-Nearest Neighbors\nMultilayer Perceptron (NeuralNetwork)\n\nTo use these models, we first need to import them from sklearn and then we need to instantiate them.\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\nfrom mlforecast.utils import PredictionIntervals\nfrom sklearn.linear_model import Lasso, LinearRegression, Ridge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n# Create a list of models and instantiation parameters \nmodels = [\n    KNeighborsRegressor(),\n    Lasso(),\n    LinearRegression(),\n    MLPRegressor(),\n    Ridge(),\n]\n\nTo instantiate a new MLForecast object, we need the following parameters:\n\nmodels: The list of models defined in the previous step.\n\ntarget_transforms: Transformations to apply to the target before computing the features. These are restored at the forecasting step.\nlags: Lags of the target to use as features.\n\n\nmlf = MLForecast(\n    models=[Ridge(), Lasso(), LinearRegression(), KNeighborsRegressor(), MLPRegressor(random_state=0)],\n    freq=1,\n    target_transforms=[Differences([1])],\n    lags=[24 * (i+1) for i in range(7)],\n)\n\nNow we’re ready to generate the point forecasts and the prediction intervals. To do this, we’ll use the fit method, which takes the following arguments:\n\ndata: Series data in long format.\nid_col: Column that identifies each series. In our case, unique_id.\ntime_col: Column that identifies each timestep, its values can be timestamps or integers. In our case, ds.\ntarget_col: Column that contains the target. In our case, y.\nprediction_intervals: A PredicitonIntervals class. The class takes two parameters: n_windows and h. n_windows represents the number of cross-validation windows used to calibrate the intervals and h is the forecast horizon. The strategy will adjust the intervals for each horizon step, resulting in different widths for each step.\n\n\nmlf.fit(\n    train,\n    prediction_intervals=PredictionIntervals(n_windows=10, h=48),\n);\n\nAfter fitting the models, we will call the predict method to generate forecasts with prediction intervals. The method takes the following arguments:\n\nhorizon: An integer that represent the forecasting horizon. In this case, we’ll forecast the next 48 hours.\nlevel: A list of floats with the confidence levels of the prediction intervals. For example, level=[95] means that the range of values should include the actual future value with probability 95%.\n\n\nlevels = [50, 80, 95]\nforecasts = mlf.predict(48, level=levels)\nforecasts.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nRidge\nLasso\nLinearRegression\nKNeighborsRegressor\nMLPRegressor\nRidge-lo-95\nRidge-lo-80\nRidge-lo-50\n...\nKNeighborsRegressor-lo-50\nKNeighborsRegressor-hi-50\nKNeighborsRegressor-hi-80\nKNeighborsRegressor-hi-95\nMLPRegressor-lo-95\nMLPRegressor-lo-80\nMLPRegressor-lo-50\nMLPRegressor-hi-50\nMLPRegressor-hi-80\nMLPRegressor-hi-95\n\n\n\n\n0\nH1\n701\n612.418170\n612.418079\n612.418170\n615.2\n612.651532\n590.473256\n594.326570\n603.409944\n...\n609.45\n620.95\n627.20\n631.310\n584.736193\n591.084898\n597.462107\n627.840957\n634.218166\n640.566870\n\n\n1\nH1\n702\n552.309298\n552.308073\n552.309298\n551.6\n548.791801\n498.721501\n518.433843\n532.710850\n...\n535.85\n567.35\n569.16\n597.525\n497.308756\n500.417799\n515.452396\n582.131207\n597.165804\n600.274847\n\n\n2\nH1\n703\n494.943384\n494.943367\n494.943384\n509.6\n490.226796\n448.253304\n463.266064\n475.006125\n...\n492.70\n526.50\n530.92\n544.180\n424.587658\n436.042788\n448.682502\n531.771091\n544.410804\n555.865935\n\n\n3\nH1\n704\n462.815779\n462.815363\n462.815779\n474.6\n459.619069\n409.975219\n422.243593\n436.128272\n...\n451.80\n497.40\n510.26\n525.500\n379.291083\n392.580306\n413.353178\n505.884959\n526.657832\n539.947054\n\n\n4\nH1\n705\n440.141034\n440.140586\n440.141034\n451.6\n438.091712\n377.999588\n392.523016\n413.474795\n...\n427.40\n475.80\n488.96\n503.945\n348.618034\n362.503767\n386.303325\n489.880099\n513.679657\n527.565389\n\n\n\n\n5 rows × 37 columns\n\n\n\n\ntest = test.merge(forecasts, how='left', on=['unique_id', 'ds'])"
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#plot-prediction-intervals",
    "href": "docs/how-to-guides/prediction_intervals.html#plot-prediction-intervals",
    "title": "Probabilistic forecasting",
    "section": "Plot prediction intervals",
    "text": "Plot prediction intervals\nTo plot the point and the prediction intervals, we’ll use the plot_series function again. Notice that now we also need to specify the model and the levels that we want to plot.\n\nKNeighborsRegressor\n\nfig = plot_series(\n    train, \n    test, \n    plot_random=False, \n    models=['KNeighborsRegressor'], \n    level=levels, \n    max_insample_length=48\n)\n\n\n\n\nLasso\n\nfig = plot_series(\n    train, \n    test, \n    plot_random=False, \n    models=['Lasso'],\n    level=levels, \n    max_insample_length=48\n)\n\n\n\n\nLineaRegression\n\nfig = plot_series(\n    train, \n    test, \n    plot_random=False, \n    models=['LinearRegression'],\n    level=levels, \n    max_insample_length=48\n)\n\n\n\n\nMLPRegressor\n\nfig = plot_series(\n    train, \n    test, \n    plot_random=False, \n    models=['MLPRegressor'],\n    level=levels, \n    max_insample_length=48\n)\n\n\n\n\nRidge\n\nfig = plot_series(\n    train, \n    test, \n    plot_random=False, \n    models=['Ridge'],\n    level=levels, \n    max_insample_length=48\n)\n\n\nFrom these plots, we can conclude that the uncertainty around each forecast varies according to the model that is being used. For the same time series, one model can predict a wider range of possible future values than others."
  },
  {
    "objectID": "docs/how-to-guides/prediction_intervals.html#references",
    "href": "docs/how-to-guides/prediction_intervals.html#references",
    "title": "Probabilistic forecasting",
    "section": "References",
    "text": "References\n\nKamile Stankeviciute, Ahmed M. Alaa and Mihaela van der Schaar (2021). “Conformal Time-Series Forecasting”\nRob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, The Statistical Forecasting Perspective”."
  },
  {
    "objectID": "docs/how-to-guides/predict_subset.html",
    "href": "docs/how-to-guides/predict_subset.html",
    "title": "Predicting a subset of ids",
    "section": "",
    "text": "from lightgbm import LGBMRegressor\nfrom fastcore.test import test_fail\n\nfrom mlforecast import MLForecast\nfrom mlforecast.utils import generate_daily_series\n\n\nseries = generate_daily_series(5)\nfcst = MLForecast({'lgb': LGBMRegressor(verbosity=-1)}, freq='D', date_features=['dayofweek'])\nfcst.fit(series)\nall_preds = fcst.predict(1)\nall_preds\n\n\n\n\n\n\n\n\nunique_id\nds\nlgb\n\n\n\n\n0\nid_0\n2000-08-10\n3.728396\n\n\n1\nid_1\n2000-04-07\n4.749133\n\n\n2\nid_2\n2000-06-16\n4.749133\n\n\n3\nid_3\n2000-08-30\n2.758949\n\n\n4\nid_4\n2001-01-08\n3.331394\n\n\n\n\n\n\n\nBy default all series seen during training will be forecasted with the predict method. If you’re only interested in predicting a couple of them you can use the ids argument.\n\nfcst.predict(1, ids=['id_0', 'id_4'])\n\n\n\n\n\n\n\n\nunique_id\nds\nlgb\n\n\n\n\n0\nid_0\n2000-08-10\n3.728396\n\n\n1\nid_4\n2001-01-08\n3.331394\n\n\n\n\n\n\n\nNote that the ids must’ve been seen during training, if you try to predict an id that wasn’t there you’ll get an error.\n\ntest_fail(lambda: fcst.predict(1, ids=['fake_id']), contains='fake_id')\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/target_transforms_guide.html",
    "href": "docs/how-to-guides/target_transforms_guide.html",
    "title": "Target transformations",
    "section": "",
    "text": "Since mlforecast uses a single global model it can be helpful to apply some transformations to the target to ensure that all series have similar distributions. They can also help remove trend for models that can’t deal with it out of the box.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/target_transforms_guide.html#data-setup",
    "href": "docs/how-to-guides/target_transforms_guide.html#data-setup",
    "title": "Target transformations",
    "section": "Data setup",
    "text": "Data setup\nFor this example we’ll use a single serie from the M4 dataset.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom datasetsforecast.m4 import M4\nfrom sklearn.base import BaseEstimator\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences, LocalStandardScaler\n\n\ndata_path = 'data'\nawait M4.async_download(data_path, group='Hourly')\ndf, *_ = M4.load(data_path, 'Hourly')\ndf['ds'] = df['ds'].astype('int32')\nserie = df[df['unique_id'].eq('H196')]"
  },
  {
    "objectID": "docs/how-to-guides/target_transforms_guide.html#local-transformations",
    "href": "docs/how-to-guides/target_transforms_guide.html#local-transformations",
    "title": "Target transformations",
    "section": "Local transformations",
    "text": "Local transformations\n\nTransformations applied per serie\n\n\nDifferences\nWe’ll take a look at our serie to see possible differences that would help our models.\n\ndef plot(series, fname):\n    n_series = len(series)\n    fig, ax = plt.subplots(ncols=n_series, figsize=(7 * n_series, 6), squeeze=False)\n    for (title, serie), axi in zip(series.items(), ax.flat):\n        serie.set_index('ds')['y'].plot(title=title, ax=axi)\n    fig.savefig(f'../../figs/{fname}', bbox_inches='tight')\n    plt.close()\n\n\nplot({'original': serie}, 'target_transforms__eda.png')\n\n\nWe can see that our data has a trend as well as a clear seasonality. We can try removing the trend first.\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[Differences([1])],\n)\nwithout_trend = fcst.preprocess(serie)\nplot({'original': serie, 'without trend': without_trend}, 'target_transforms__diff1.png')\n\n\nThe trend is gone, we can now try taking the 24 difference (subtract the value at the same hour in the previous day).\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[Differences([1, 24])],\n)\nwithout_trend_and_seasonality = fcst.preprocess(serie)\nplot({'original': serie, 'without trend and seasonality': without_trend_and_seasonality}, 'target_transforms__diff2.png')\n\n\n\n\nLocalStandardScaler\nWe see that our serie is random noise now. Suppose we also want to standardize it, i.e. make it have a mean of 0 and variance of 1. We can add the LocalStandardScaler transformation after these differences.\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[Differences([1, 24]), LocalStandardScaler()],\n)\nstandardized = fcst.preprocess(serie)\nplot({'original': serie, 'standardized': standardized}, 'target_transforms__standardized.png')\nstandardized['y'].agg(['mean', 'var']).round(2)\n\nmean   -0.0\nvar     1.0\nName: y, dtype: float64\n\n\n\nNow that we’ve captured the components of the serie (trend + seasonality), we could try forecasting it with a model that always predicts 0, which will basically project the trend and seasonality.\n\nclass Zeros(BaseEstimator):\n    def fit(self, X, y=None):\n        return self\n\n    def predict(self, X, y=None):\n        return np.zeros(X.shape[0])\n\nfcst = MLForecast(\n    models={'zeros_model': Zeros()},\n    freq=1,\n    target_transforms=[Differences([1, 24]), LocalStandardScaler()],\n)\npreds = fcst.fit(serie).predict(48)\nfig, ax = plt.subplots()\npd.concat([serie.tail(24 * 10), preds]).set_index('ds').plot(ax=ax)\nplt.close()"
  },
  {
    "objectID": "docs/how-to-guides/target_transforms_guide.html#global-transformations",
    "href": "docs/how-to-guides/target_transforms_guide.html#global-transformations",
    "title": "Target transformations",
    "section": "Global transformations",
    "text": "Global transformations\n\nTransformations applied to all series\n\n\nGlobalSklearnTransformer\nThere are some transformations that don’t require to learn any parameters, such as applying logarithm for example. These can be easily defined using the GlobalSklearnTransformer, which takes a scikit-learn compatible transformer and applies it to all series. Here’s an example on how to define a transformation that applies logarithm to each value of the series + 1, which can help avoid computing the log of 0.\n\nimport numpy as np\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom mlforecast.target_transforms import GlobalSklearnTransformer\n\nsk_log1p = FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\nfcst = MLForecast(\n    models={'zeros_model': Zeros()},\n    freq=1,\n    target_transforms=[GlobalSklearnTransformer(sk_log1p)],\n)\nlog1p_transformed = fcst.preprocess(serie)\nplot({'original': serie, 'Log transformed': log1p_transformed}, 'target_transforms__log.png')\n\n\nWe can also combine this with local transformations. For example we can apply log first and then differencing.\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[GlobalSklearnTransformer(sk_log1p), Differences([1, 24])],\n)\nlog_diffs = fcst.preprocess(serie)\nplot({'original': serie, 'Log + Differences': log_diffs}, 'target_transforms__log_diffs.png')"
  },
  {
    "objectID": "docs/how-to-guides/target_transforms_guide.html#custom-transformations",
    "href": "docs/how-to-guides/target_transforms_guide.html#custom-transformations",
    "title": "Target transformations",
    "section": "Custom transformations",
    "text": "Custom transformations\n\nImplementing your own target transformations\n\nIn order to implement your own target transformation you have to define a class that inherits from mlforecast.target_transforms.BaseTargetTransform (this takes care of setting the column names as the id_col, time_col and target_col attributes) and implement the fit_transform and inverse_transform methods. Here’s an example on how to define a min-max scaler.\n\nfrom mlforecast.target_transforms import BaseTargetTransform\n\n\nclass LocalMinMaxScaler(BaseTargetTransform):\n    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n    def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        self.stats_ = df.groupby(self.id_col)[self.target_col].agg(['min', 'max'])\n        df = df.merge(self.stats_, on=self.id_col)\n        df[self.target_col] = (df[self.target_col] - df['min']) / (df['max'] - df['min'])\n        df = df.drop(columns=['min', 'max'])\n        return df\n\n    def inverse_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        df = df.merge(self.stats_, on=self.id_col)\n        for col in df.columns.drop([self.id_col, self.time_col, 'min', 'max']):\n            df[col] = df[col] * (df['max'] - df['min']) + df['min']\n        df = df.drop(columns=['min', 'max'])\n        return df\n\nAnd now you can pass an instance of this class to the target_transforms argument.\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[LocalMinMaxScaler()],\n)\nminmax_scaled = fcst.preprocess(serie)\nplot({'original': serie, 'min-max scaled': minmax_scaled}, 'target_transforms__minmax.png')"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html",
    "href": "docs/how-to-guides/custom_training.html",
    "title": "Custom training",
    "section": "",
    "text": "mlforecast abstracts away most of the training details, which is useful for iterating quickly. However, sometimes you want more control over the fit parameters, the data that goes into the model, etc. This guide shows how you can train a model in a specific way and then giving it back to mlforecast to produce forecasts with it.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#data-setup",
    "href": "docs/how-to-guides/custom_training.html#data-setup",
    "title": "Custom training",
    "section": "Data setup",
    "text": "Data setup\n\nfrom mlforecast.utils import generate_daily_series\n\n\nseries = generate_daily_series(5)"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#creating-forecast-object",
    "href": "docs/how-to-guides/custom_training.html#creating-forecast-object",
    "title": "Custom training",
    "section": "Creating forecast object",
    "text": "Creating forecast object\n\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom mlforecast import MLForecast\n\nSuppose we want to train a linear regression with the default settings.\n\nfcst = MLForecast(\n    models={'lr': LinearRegression()},\n    freq='D',\n    date_features=['dayofweek'],\n)"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#generate-training-set",
    "href": "docs/how-to-guides/custom_training.html#generate-training-set",
    "title": "Custom training",
    "section": "Generate training set",
    "text": "Generate training set\nUse MLForecast.preprocess to generate the training data.\n\nprep = fcst.preprocess(series)\nprep.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\ndayofweek\n\n\n\n\n0\nid_0\n2000-01-01\n0.428973\n5\n\n\n1\nid_0\n2000-01-02\n1.423626\n6\n\n\n2\nid_0\n2000-01-03\n2.311782\n0\n\n\n3\nid_0\n2000-01-04\n3.192191\n1\n\n\n4\nid_0\n2000-01-05\n4.148767\n2\n\n\n\n\n\n\n\n\nX = prep.drop(columns=['unique_id', 'ds', 'y'])\ny = prep['y']"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#regular-training",
    "href": "docs/how-to-guides/custom_training.html#regular-training",
    "title": "Custom training",
    "section": "Regular training",
    "text": "Regular training\nSince we don’t want to do anything special in our training process for the linear regression, we can just call MLForecast.fit_models\n\nfcst.fit_models(X, y)\n\nMLForecast(models=[lr], freq=&lt;Day&gt;, lag_features=[], date_features=['dayofweek'], num_threads=1)\n\n\nThis has trained the linear regression model and is now available in the MLForecast.models_ attribute.\n\nfcst.models_\n\n{'lr': LinearRegression()}"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#custom-training",
    "href": "docs/how-to-guides/custom_training.html#custom-training",
    "title": "Custom training",
    "section": "Custom training",
    "text": "Custom training\nNow suppose you also want to train a LightGBM model on the same data, but specifying sample weights.\n\nrng = np.random.RandomState(0)\nweights = rng.rand(y.size)\n\nWe train the model as we normally would and provide the weights through the sample_weight argument.\n\nmodel = LGBMRegressor(verbosity=-1).fit(X, y, sample_weight=weights)"
  },
  {
    "objectID": "docs/how-to-guides/custom_training.html#computing-forecasts",
    "href": "docs/how-to-guides/custom_training.html#computing-forecasts",
    "title": "Custom training",
    "section": "Computing forecasts",
    "text": "Computing forecasts\nNow we just assign this model to the MLForecast.models_ dictionary. Note that you can assign as many models as you want.\n\nfcst.models_['lgbm'] = model\nfcst.models_\n\n{'lr': LinearRegression(), 'lgbm': LGBMRegressor(verbosity=-1)}\n\n\nAnd now when calling MLForecast.predict, mlforecast will use those models to compute the forecasts.\n\nfcst.predict(1)\n\n\n\n\n\n\n\n\nunique_id\nds\nlr\nlgbm\n\n\n\n\n0\nid_0\n2000-08-10\n3.247803\n3.642456\n\n\n1\nid_1\n2000-04-07\n3.182126\n4.808618\n\n\n2\nid_2\n2000-06-16\n3.182126\n4.808618\n\n\n3\nid_3\n2000-08-30\n3.313480\n2.777129\n\n\n4\nid_4\n2001-01-08\n3.444834\n3.404631"
  },
  {
    "objectID": "docs/tutorials/electricity_load_forecasting.html",
    "href": "docs/tutorials/electricity_load_forecasting.html",
    "title": "Electricity Load Forecast",
    "section": "",
    "text": "Some time series are generated from very low frequency data. These data generally exhibit multiple seasonalities. For example, hourly data may exhibit repeated patterns every hour (every 24 observations) or every day (every 24 * 7, hours per day, observations). This is the case for electricity load. Electricity load may vary hourly, e.g., during the evenings electricity consumption may be expected to increase. But also, the electricity load varies by week. Perhaps on weekends there is an increase in electrical activity.\nIn this example we will show how to model the two seasonalities of the time series to generate accurate forecasts in a short time. We will use hourly PJM electricity load data. The original data can be found here.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/electricity_load_forecasting.html#introduction",
    "href": "docs/tutorials/electricity_load_forecasting.html#introduction",
    "title": "Electricity Load Forecast",
    "section": "",
    "text": "Some time series are generated from very low frequency data. These data generally exhibit multiple seasonalities. For example, hourly data may exhibit repeated patterns every hour (every 24 observations) or every day (every 24 * 7, hours per day, observations). This is the case for electricity load. Electricity load may vary hourly, e.g., during the evenings electricity consumption may be expected to increase. But also, the electricity load varies by week. Perhaps on weekends there is an increase in electrical activity.\nIn this example we will show how to model the two seasonalities of the time series to generate accurate forecasts in a short time. We will use hourly PJM electricity load data. The original data can be found here."
  },
  {
    "objectID": "docs/tutorials/electricity_load_forecasting.html#libraries",
    "href": "docs/tutorials/electricity_load_forecasting.html#libraries",
    "title": "Electricity Load Forecast",
    "section": "Libraries",
    "text": "Libraries\nIn this example we will use the following libraries:\n\nmlforecast. Accurate and ⚡️ fast forecasting withc lassical machine learning models.\nprophet. Benchmark model developed by Facebook.\nutilsforecast. Library with different functions for forecasting evaluation.\n\nIf you have already installed the libraries you can skip the next cell, if not be sure to run it.\n\n# %%capture\n# !pip install prophet\n# !pip install -U mlforecast\n# !pip install -U utilsforecast"
  },
  {
    "objectID": "docs/tutorials/electricity_load_forecasting.html#forecast-using-multiple-seasonalities",
    "href": "docs/tutorials/electricity_load_forecasting.html#forecast-using-multiple-seasonalities",
    "title": "Electricity Load Forecast",
    "section": "Forecast using Multiple Seasonalities",
    "text": "Forecast using Multiple Seasonalities\n\nElectricity Load Data\nAccording to the dataset’s page,\n\nPJM Interconnection LLC (PJM) is a regional transmission organization (RTO) in the United States. It is part of the Eastern Interconnection grid operating an electric transmission system serving all or parts of Delaware, Illinois, Indiana, Kentucky, Maryland, Michigan, New Jersey, North Carolina, Ohio, Pennsylvania, Tennessee, Virginia, West Virginia, and the District of Columbia. The hourly power consumption data comes from PJM’s website and are in megawatts (MW).\n\nLet’s take a look to the data.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom utilsforecast.plotting import plot_series\n\n\npd.plotting.register_matplotlib_converters()\nplt.rc(\"figure\", figsize=(10, 8))\nplt.rc(\"font\", size=10)\n\n\ndata_url = 'https://raw.githubusercontent.com/panambY/Hourly_Energy_Consumption/master/data/PJM_Load_hourly.csv'\ndf = pd.read_csv(data_url, parse_dates=['Datetime'])\ndf.columns = ['ds', 'y']\ndf.insert(0, 'unique_id', 'PJM_Load_hourly')\ndf['ds'] = pd.to_datetime(df['ds'])\ndf = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\nprint(f'Shape of the data {df.shape}')\ndf.tail()\n\nShape of the data (32896, 3)\n\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n32891\nPJM_Load_hourly\n2001-12-31 20:00:00\n36392.0\n\n\n32892\nPJM_Load_hourly\n2001-12-31 21:00:00\n35082.0\n\n\n32893\nPJM_Load_hourly\n2001-12-31 22:00:00\n33890.0\n\n\n32894\nPJM_Load_hourly\n2001-12-31 23:00:00\n32590.0\n\n\n32895\nPJM_Load_hourly\n2002-01-01 00:00:00\n31569.0\n\n\n\n\n\n\n\n\nfig = plot_series(df)\n\n\nWe clearly observe that the time series exhibits seasonal patterns. Moreover, the time series contains 32,896 observations, so it is necessary to use very computationally efficient methods to display them in production.\nWe are going to split our series in order to create a train and test set. The model will be tested using the last 24 hours of the timeseries.\n\nthreshold_time = df['ds'].max() - pd.Timedelta(hours=24)\n\n# Split the dataframe\ndf_train = df[df['ds'] &lt;= threshold_time]\ndf_last_24_hours = df[df['ds'] &gt; threshold_time]\n\n\n\nAnalizing Seasonalities\nFirst we must visualize the seasonalities of the model. As mentioned before, the electricity load presents seasonalities every 24 hours (Hourly) and every 24 * 7 (Daily) hours. Therefore, we will use [24, 24 * 7] as the seasonalities for the model. In order to analize how they affect our series we are going to use the Difference method.\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\n\nWe can use the MLForecast.preprocess method to explore different transformations. It looks like these series have a strong seasonality on the hour of the day, so we can subtract the value from the same hour in the previous day to remove it. This can be done with the mlforecast.target_transforms.Differences transformer, which we pass through target_transforms.\nIn order to analize the trends individually and combined we are going to plot them individually and combined. Therefore, we can compare them against the original series. We can use the next function for that.\n\ndef plot_differences(df, differences,fname):\n    prep = [df]\n    # Plot individual Differences\n    for d in differences:\n        fcst = MLForecast(\n        models=[],  # we're not interested in modeling yet\n        freq='H',  # our series have hourly frequency \n        target_transforms=[Differences([d])],\n        )\n        df_ = fcst.preprocess(df)\n        df_['unique_id'] = df_['unique_id'] + f'_{d}'\n        prep.append(df_)\n        \n    # Plot combined Differences\n    fcst = MLForecast(\n    models=[],  # we're not interested in modeling yet\n    freq='H',  # our series have hourly frequency \n    target_transforms=[Differences([24, 24*7])],\n    )\n    df_ = fcst.preprocess(df)\n    df_['unique_id'] = df_['unique_id'] + f'_all_diff'\n    prep.append(df_)\n    prep = pd.concat(prep, ignore_index=True)\n    #return prep\n    n_series = len(prep['unique_id'].unique())\n    fig, ax = plt.subplots(nrows=n_series, figsize=(7 * n_series, 10*n_series), squeeze=False)\n    for title, axi in zip(prep['unique_id'].unique(), ax.flat):\n        df_ = prep[prep['unique_id'] == title]\n        df_.set_index('ds')['y'].plot(title=title, ax=axi)\n    fig.savefig(f'../../figs/{fname}', bbox_inches='tight')\n    plt.close()\n\nSince the seasonalities are present at 24 hours (daily) and 24*7 (weekly) we are going to substract them from the serie using Differences([24, 24*7]) and plot them.\n\nplot_differences(df=df_train, differences=[24, 24*7], fname='load_forecasting__differences.png')\n\n\nAs we can see when we extract the 24 difference (daily) in PJM_Load_hourly_24 the series seem to stabilize sisnce the peaks seem more uniform in comparison with the original series PJM_Load_hourly.\nWhen we extrac the 24*7 (weekly) PJM_Load_hourly_168 difference we can see there is more periodicity in the peaks in comparison with the original series.\nFinally we can see the result from the combined result from substracting all the differences PJM_Load_hourly_all_diff.\nFor modeling we are going to use both difference for the forecasting, therefore we are setting the argument target_transforms from the MLForecast object equal to [Differences([24, 24*7])], if we wanted to include a yearly difference we would need to add the term 24*365.\n\nfcst = MLForecast(\n    models=[],  # we're not interested in modeling yet\n    freq='H',  # our series have hourly frequency \n    target_transforms=[Differences([24, 24*7])],\n)\nprep = fcst.preprocess(df_train)\nprep\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n192\nPJM_Load_hourly\n1998-04-09 02:00:00\n831.0\n\n\n193\nPJM_Load_hourly\n1998-04-09 03:00:00\n918.0\n\n\n194\nPJM_Load_hourly\n1998-04-09 04:00:00\n760.0\n\n\n195\nPJM_Load_hourly\n1998-04-09 05:00:00\n849.0\n\n\n196\nPJM_Load_hourly\n1998-04-09 06:00:00\n710.0\n\n\n...\n...\n...\n...\n\n\n32867\nPJM_Load_hourly\n2001-12-30 20:00:00\n3417.0\n\n\n32868\nPJM_Load_hourly\n2001-12-30 21:00:00\n3596.0\n\n\n32869\nPJM_Load_hourly\n2001-12-30 22:00:00\n3501.0\n\n\n32870\nPJM_Load_hourly\n2001-12-30 23:00:00\n3939.0\n\n\n32871\nPJM_Load_hourly\n2001-12-31 00:00:00\n4235.0\n\n\n\n\n32680 rows × 3 columns\n\n\n\n\nfig = plot_series(prep)\n\n\n\n\nModel Selection with Cross-Validation\nWe can test many models simoultaneously using MLForecast cross_validation. We can import lightgbm and scikit-learn models and try different combinations of them, alongside different target transformations (as the ones we created previously) and historical variables.\nYou can see an in-depth tutorial on how to use MLForecast Cross Validation methods here\n\nimport lightgbm as lgb\nfrom mlforecast.target_transforms import Differences\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\nfrom sklearn.base import BaseEstimator\nfrom sklearn.linear_model import Lasso, LinearRegression, Ridge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nWe can create a benchmark Naive model that uses the electricity load of the last hour as prediction lag1 as showed in the next cell. You can create your own models and try them with MLForecast using the same structure.\n\nclass Naive(BaseEstimator):\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X):\n        return X['lag1']\n\nNow let’s try differen models from the scikit-learn library: Lasso, LinearRegression, Ridge, KNN, MLP and Random Forest alongside the LightGBM. You can add any model to the dictionary to train and compare them by adding them to the dictionary (models) as shown.\n\n# Model dictionary\nmodels ={\n        'naive': Naive(),\n        'lgbm': lgb.LGBMRegressor(verbosity=-1),\n        'lasso': Lasso(),\n        'lin_reg': LinearRegression(),\n        'ridge': Ridge(),\n        'knn': KNeighborsRegressor(),\n        'mlp': MLPRegressor(), \n        'rf': RandomForestRegressor()\n    }\n\nThe we can instanciate the MLForecast class with the models we want to try along side target_transforms, lags, lag_transforms, and date_features. All this features are applied to the models we selected.\nIn this case we use the 1st, 12th and 24th lag, which are passed as a list. Potentially you could pass a range.\nlags=[1,12,24]\nLag transforms are defined as a dictionary where the keys are the lags and the values are lists of functions that transform an array. These must be numba jitted functions (so that computing the features doesn’t become a bottleneck). There are some implemented in the window-ops package but you can also implement your own.\nFor this example we applied an expanding mean to the first lag, and a rolling mean to the 24th lag.\n    lag_transforms={  \n            1: [expanding_mean],\n            24: [(rolling_mean, 48)],\n        }\nFor using the date features you need to be sure that your time column is made of timestamps. Then it might make sense to extract features like week, dayofweek, quarter, etc. You can do that by passing a list of strings with pandas time/date components. You can also pass functions that will take the time column as input, as we’ll show here.\nHere we add month, hour and dayofweek features:\n    date_features=['month', 'hour', 'dayofweek']\n\n\nmlf = MLForecast(\n    models = models, \n    freq='H',  # our series have hourly frequency \n    target_transforms=[Differences([24, 24*7])],\n    lags=[1,12,24], # Lags to be used as features\n    lag_transforms={  \n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=['month', 'hour', 'dayofweek']\n)\n\nNow we use the cross_validation method to train and evalaute the models. + df: Receives the training data + h: Forecast horizon + n_windows: The number of folds we want to predict\nYou can specify the names of the time series id, time and target columns. + id_col:Column that identifies each serie ( Default unique_id ) + time_col: Column that identifies each timestep, its values can be timestamps or integer( Default ds ) + target_col:Column that contains the target ( Default y )\n\ncrossvalidation_df = mlf.cross_validation(\n    df=df_train,\n    h=24,\n    n_windows=4,\n    refit=False,\n)\ncrossvalidation_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nnaive\nlgbm\nlasso\nlin_reg\nridge\nknn\nmlp\nrf\n\n\n\n\n0\nPJM_Load_hourly\n2001-12-27 01:00:00\n2001-12-27\n28332.0\n28837.0\n28526.505572\n28703.185712\n28702.625949\n28702.625956\n28479.0\n28834.839479\n28277.94\n\n\n1\nPJM_Load_hourly\n2001-12-27 02:00:00\n2001-12-27\n27329.0\n27969.0\n27467.860847\n27693.502318\n27692.395954\n27692.395969\n27521.6\n27940.414699\n27307.90\n\n\n2\nPJM_Load_hourly\n2001-12-27 03:00:00\n2001-12-27\n26986.0\n27435.0\n26605.710615\n26991.795124\n26990.157567\n26990.157589\n26451.6\n27370.170779\n26599.23\n\n\n3\nPJM_Load_hourly\n2001-12-27 04:00:00\n2001-12-27\n27009.0\n27401.0\n26284.065138\n26789.418399\n26787.262262\n26787.262291\n26388.4\n27294.232077\n26366.54\n\n\n4\nPJM_Load_hourly\n2001-12-27 05:00:00\n2001-12-27\n27555.0\n28169.0\n26823.617078\n27369.643789\n27366.983075\n27366.983111\n26779.6\n28014.090505\n27095.55\n\n\n\n\n\n\n\nNow we can plot each model and window (fold) to see how it behaves\n\ndef plot_cv(df, df_cv, uid, fname, last_n=24 * 14, models={}):\n    cutoffs = df_cv.query('unique_id == @uid')['cutoff'].unique()\n    fig, ax = plt.subplots(nrows=len(cutoffs), ncols=1, figsize=(14, 14), gridspec_kw=dict(hspace=0.8))\n    for cutoff, axi in zip(cutoffs, ax.flat):\n        max_date = df_cv.query('unique_id == @uid & cutoff == @cutoff')['ds'].max()\n        df[df['ds'] &lt; max_date].query('unique_id == @uid').tail(last_n).set_index('ds').plot(ax=axi, title=uid, y='y')\n        for m in models.keys():\n            df_cv.query('unique_id == @uid & cutoff == @cutoff').set_index('ds').plot(ax=axi, title=uid, y=m)          \n    fig.savefig(f'../../figs/{fname}', bbox_inches='tight')\n    plt.close()\n\n\nplot_cv(df_train, crossvalidation_df, 'PJM_Load_hourly', 'load_forecasting__predictions.png', models=models)\n\n\nVisually examining the forecasts can give us some idea of how the model is behaving, yet in order to asses the performace we need to evaluate them trough metrics. For that we use the utilsforecast library that contains many useful metrics and an evaluate function.\n\nfrom utilsforecast.losses import *\nfrom utilsforecast.evaluation import evaluate\n\n\n# Metrics to be used for evaluation\nmetrics = [\n    mae,\n    rmse,\n    mape,\n    smape\n    ]\n\n\n# Function to evaluate the crossvalidation\ndef evaluate_crossvalidation(crossvalidation_df, metrics, models):\n    evaluations = []\n    for c in crossvalidation_df['cutoff'].unique():\n        df_cv = crossvalidation_df.query('cutoff == @c')\n        evaluation = evaluate(\n            df = df_cv,\n            metrics=metrics,\n            models=list(models.keys())\n            )\n        evaluations.append(evaluation)\n    evaluations = pd.concat(evaluations, ignore_index=True).drop(columns='unique_id')\n    evaluations = evaluations.groupby('metric').mean()\n    return evaluations.style.background_gradient(cmap='RdYlGn_r', axis=1)\n\n\nevaluate_crossvalidation(crossvalidation_df, metrics, models)\n\n\n\n\n\n\n \nnaive\nlgbm\nlasso\nlin_reg\nridge\nknn\nmlp\nrf\n\n\nmetric\n \n \n \n \n \n \n \n \n\n\n\n\nmae\n1631.395833\n971.536200\n1003.796433\n1007.998597\n1007.998547\n1248.145833\n1268.841369\n1219.286771\n\n\nmape\n0.049759\n0.030966\n0.031760\n0.031888\n0.031888\n0.038721\n0.039149\n0.037969\n\n\nrmse\n1871.398919\n1129.713256\n1148.616156\n1153.262719\n1153.262664\n1451.964390\n1463.836007\n1409.549197\n\n\nsmape\n0.024786\n0.015886\n0.016269\n0.016338\n0.016338\n0.019549\n0.019704\n0.019252\n\n\n\n\n\nWe can se that the model lgbm has top performance in most metrics folowed by the lasso regression. Both models perform way better than the naive.\n\n\nTest Evaluation\nNow we are going to evaluate their perfonce in the test set. We can use both of them for forecasting the test alongside some prediction intervals. For that we can use the PredictionIntervals function in mlforecast.utils.\nYou can see an in-depth tutotorial of Probabilistic Forecasting here\n\nfrom mlforecast.utils import PredictionIntervals\n\n\nmodels_evaluation ={\n        'lgbm': lgb.LGBMRegressor(verbosity=-1),\n        'lasso': Lasso(),\n    }\n\nmlf_evaluation = MLForecast(\n    models = models_evaluation, \n    freq='H',  # our series have hourly frequency \n    target_transforms=[Differences([24, 24*7])],\n    lags=[1,12,24], \n    lag_transforms={  \n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=['month', 'hour', 'dayofweek']\n)\n\nNow we’re ready to generate the point forecasts and the prediction intervals. To do this, we’ll use the fit method, which takes the following arguments:\n\ndf: Series data in long format.\nid_col: Column that identifies each series. In our case, unique_id.\ntime_col: Column that identifies each timestep, its values can be timestamps or integers. In our case, ds.\ntarget_col: Column that contains the target. In our case, y.\n\nThe PredictionIntervals function is used to compute prediction intervals for the models using Conformal Prediction. The function takes the following arguments: + n_windows: represents the number of cross-validation windows used to calibrate the intervals + h: the forecast horizon\n\nmlf_evaluation.fit(\n    df = df_train,\n    prediction_intervals=PredictionIntervals(n_windows=4, h=24)\n)\n\nMLForecast(models=[lgbm, lasso], freq=&lt;Hour&gt;, lag_features=['lag1', 'lag12', 'lag24', 'expanding_mean_lag1', 'rolling_mean_lag24_window_size48'], date_features=['month', 'hour', 'dayofweek'], num_threads=1)\n\n\nNow that the model has been trained we are going to forecast the next 24 hours using the predict method so we can compare them to our test data. Additionally, we are going to create prediction intervals at levels [90,95].\n\nlevels = [90, 95] # Levels for prediction intervals\nforecasts = mlf_evaluation.predict(24, level=levels)\nforecasts.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nlgbm\nlasso\nlgbm-lo-95\nlgbm-lo-90\nlgbm-hi-90\nlgbm-hi-95\nlasso-lo-95\nlasso-lo-90\nlasso-hi-90\nlasso-hi-95\n\n\n\n\n0\nPJM_Load_hourly\n2001-12-31 01:00:00\n28847.573176\n29124.085976\n28544.593464\n28567.603130\n29127.543222\n29150.552888\n28762.752269\n28772.604275\n29475.567677\n29485.419682\n\n\n1\nPJM_Load_hourly\n2001-12-31 02:00:00\n27862.589195\n28365.330749\n27042.311414\n27128.839888\n28596.338503\n28682.866977\n27528.548959\n27619.065224\n29111.596275\n29202.112539\n\n\n2\nPJM_Load_hourly\n2001-12-31 03:00:00\n27044.418960\n27712.161676\n25596.659896\n25688.230426\n28400.607493\n28492.178023\n26236.955369\n26338.087102\n29086.236251\n29187.367984\n\n\n3\nPJM_Load_hourly\n2001-12-31 04:00:00\n26976.104125\n27661.572733\n25249.961527\n25286.024722\n28666.183529\n28702.246724\n25911.133521\n25959.815715\n29363.329750\n29412.011944\n\n\n4\nPJM_Load_hourly\n2001-12-31 05:00:00\n26694.246238\n27393.922370\n25044.220845\n25051.548832\n28336.943644\n28344.271631\n25751.547897\n25762.524815\n29025.319924\n29036.296843\n\n\n\n\n\n\n\nThe predict method returns a DataFrame witht the predictions for each model (lasso and lgbm) along side the prediction tresholds. The high-threshold is indicated by the keyword hi, the low-threshold by the keyword lo, and the level by the number in the column names.\n\ntest = df_last_24_hours.merge(forecasts, how='left', on=['unique_id', 'ds'])\ntest.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlgbm\nlasso\nlgbm-lo-95\nlgbm-lo-90\nlgbm-hi-90\nlgbm-hi-95\nlasso-lo-95\nlasso-lo-90\nlasso-hi-90\nlasso-hi-95\n\n\n\n\n0\nPJM_Load_hourly\n2001-12-31 01:00:00\n29001.0\n28847.573176\n29124.085976\n28544.593464\n28567.603130\n29127.543222\n29150.552888\n28762.752269\n28772.604275\n29475.567677\n29485.419682\n\n\n1\nPJM_Load_hourly\n2001-12-31 02:00:00\n28138.0\n27862.589195\n28365.330749\n27042.311414\n27128.839888\n28596.338503\n28682.866977\n27528.548959\n27619.065224\n29111.596275\n29202.112539\n\n\n2\nPJM_Load_hourly\n2001-12-31 03:00:00\n27830.0\n27044.418960\n27712.161676\n25596.659896\n25688.230426\n28400.607493\n28492.178023\n26236.955369\n26338.087102\n29086.236251\n29187.367984\n\n\n3\nPJM_Load_hourly\n2001-12-31 04:00:00\n27874.0\n26976.104125\n27661.572733\n25249.961527\n25286.024722\n28666.183529\n28702.246724\n25911.133521\n25959.815715\n29363.329750\n29412.011944\n\n\n4\nPJM_Load_hourly\n2001-12-31 05:00:00\n28427.0\n26694.246238\n27393.922370\n25044.220845\n25051.548832\n28336.943644\n28344.271631\n25751.547897\n25762.524815\n29025.319924\n29036.296843\n\n\n\n\n\n\n\nNow we can evaluate the metrics and performance in the test set.\n\nevaluate(\n            df = test,\n            metrics=metrics,\n            models=list(models_evaluation.keys())\n            )\n\n\n\n\n\n\n\n\nunique_id\nmetric\nlgbm\nlasso\n\n\n\n\n0\nPJM_Load_hourly\nmae\n1092.050817\n899.979743\n\n\n1\nPJM_Load_hourly\nrmse\n1340.422762\n1163.695525\n\n\n2\nPJM_Load_hourly\nmape\n0.033600\n0.027688\n\n\n3\nPJM_Load_hourly\nsmape\n0.017137\n0.013812\n\n\n\n\n\n\n\nWe can see that the lasso regression performed slighty better than the LightGBM for the test set. Additonally, we can also plot the forecasts alongside their prediction intervals. For that we can use the plot_series method available in utilsforecast.plotting.\nWe can plot one or many models at once alongside their coinfidence intervals.\n\nfig = plot_series(\n    df_train, \n    test, \n    models=['lasso', 'lgbm'],\n    plot_random=False, \n    level=levels, \n    max_insample_length=24\n)\n\n\n\n\nComparison with Prophet\nOne of the most widely used models for time series forecasting is Prophet. This model is known for its ability to model different seasonalities (weekly, daily yearly). We will use this model as a benchmark to see if the lgbm alongside MLForecast adds value for this time series.\n\nfrom prophet import Prophet\nfrom time import time\n\n\n# create prophet model\nprophet = Prophet(interval_width=0.9)\ninit = time()\nprophet.fit(df_train)\n# produce forecasts\nfuture = prophet.make_future_dataframe(periods=len(df_last_24_hours), freq='H', include_history=False)\nforecast_prophet = prophet.predict(future)\nend = time()\n# data wrangling\nforecast_prophet = forecast_prophet[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\nforecast_prophet.columns = ['ds', 'Prophet', 'Prophet-lo-90', 'Prophet-hi-90']\nforecast_prophet.insert(0, 'unique_id', 'PJM_Load_hourly')\nforecast_prophet.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nProphet\nProphet-lo-90\nProphet-hi-90\n\n\n\n\n0\nPJM_Load_hourly\n2001-12-31 01:00:00\n25294.246960\n20452.615295\n30151.111598\n\n\n1\nPJM_Load_hourly\n2001-12-31 02:00:00\n24000.725423\n18954.861631\n28946.645807\n\n\n2\nPJM_Load_hourly\n2001-12-31 03:00:00\n23324.771966\n18562.568378\n28009.837383\n\n\n3\nPJM_Load_hourly\n2001-12-31 04:00:00\n23332.519871\n18706.835864\n28253.861051\n\n\n4\nPJM_Load_hourly\n2001-12-31 05:00:00\n24107.126827\n18966.217684\n28907.516733\n\n\n\n\n\n\n\n\ntime_prophet = (end - init) \nprint(f'Prophet Time: {time_prophet:.2f} seconds')\n\nProphet Time: 36.90 seconds\n\n\n\nmodels_comparison ={\n        'lgbm': lgb.LGBMRegressor(verbosity=-1)\n    }\n\nmlf_comparison = MLForecast(\n    models = models_comparison, \n    freq='H',  # our series have hourly frequency \n    target_transforms=[Differences([24, 24*7])],\n    lags=[1,12,24],\n    lag_transforms={  \n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=['month', 'hour', 'dayofweek']\n)\n\ninit = time()\nmlf_comparison.fit(\n    df = df_train,\n    prediction_intervals=PredictionIntervals(n_windows=4, h=24)\n)\n\nlevels = [90]\nforecasts_comparison = mlf_comparison.predict(24, level=levels)\nend = time()\nforecasts_comparison.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nlgbm\nlgbm-lo-90\nlgbm-hi-90\n\n\n\n\n0\nPJM_Load_hourly\n2001-12-31 01:00:00\n28847.573176\n28567.603130\n29127.543222\n\n\n1\nPJM_Load_hourly\n2001-12-31 02:00:00\n27862.589195\n27128.839888\n28596.338503\n\n\n2\nPJM_Load_hourly\n2001-12-31 03:00:00\n27044.418960\n25688.230426\n28400.607493\n\n\n3\nPJM_Load_hourly\n2001-12-31 04:00:00\n26976.104125\n25286.024722\n28666.183529\n\n\n4\nPJM_Load_hourly\n2001-12-31 05:00:00\n26694.246238\n25051.548832\n28336.943644\n\n\n\n\n\n\n\n\ntime_lgbm = (end - init)\nprint(f'LGBM Time: {time_lgbm:.2f} seconds')\n\nLGBM Time: 1.34 seconds\n\n\n\nmetrics_comparison = df_last_24_hours.merge(forecasts_comparison, how='left', on=['unique_id', 'ds']).merge(\n    forecast_prophet, how='left', on=['unique_id', 'ds'])\nmetrics_comparison = evaluate(\n            df = metrics_comparison,\n            metrics=metrics,\n            models=['Prophet', 'lgbm']\n            )\nmetrics_comparison.reset_index(drop=True).style.background_gradient(cmap='RdYlGn_r', axis=1)\n\n\n\n\n\n\n \nunique_id\nmetric\nProphet\nlgbm\n\n\n\n\n0\nPJM_Load_hourly\nmae\n2282.966977\n1092.050817\n\n\n1\nPJM_Load_hourly\nrmse\n2721.817203\n1340.422762\n\n\n2\nPJM_Load_hourly\nmape\n0.073750\n0.033600\n\n\n3\nPJM_Load_hourly\nsmape\n0.038633\n0.017137\n\n\n\n\n\nAs we can see lgbm had consistently better metrics than prophet.\n\nmetrics_comparison['improvement'] = metrics_comparison['Prophet'] /  metrics_comparison['lgbm']\nmetrics_comparison['improvement'] = metrics_comparison['improvement'].apply(lambda x: f'{x:.2f}')\nmetrics_comparison.set_index('metric')[['improvement']]\n\n\n\n\n\n\n\n\nimprovement\n\n\nmetric\n\n\n\n\n\nmae\n2.09\n\n\nrmse\n2.03\n\n\nmape\n2.19\n\n\nsmape\n2.25\n\n\n\n\n\n\n\n\nprint(f'lgbm with MLForecast has a speedup of {time_prophet/time_lgbm:.2f} compared with prophet')\n\nlgbm with MLForecast has a speedup of 27.62 compared with prophet\n\n\nWe can see that lgbm with MLForecast was able to provide metrics at least twice as good as Prophet as seen in the column improvement above, and way faster."
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html",
    "href": "docs/getting-started/quick_start_local.html",
    "title": "Quick start (local)",
    "section": "",
    "text": "The main component of mlforecast is the MLForecast class, which abstracts away:\n\nFeature engineering and model training through MLForecast.fit\nFeature updates and multi step ahead predictions through MLForecast.predict\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html#main-concepts",
    "href": "docs/getting-started/quick_start_local.html#main-concepts",
    "title": "Quick start (local)",
    "section": "",
    "text": "The main component of mlforecast is the MLForecast class, which abstracts away:\n\nFeature engineering and model training through MLForecast.fit\nFeature updates and multi step ahead predictions through MLForecast.predict"
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html#data-format",
    "href": "docs/getting-started/quick_start_local.html#data-format",
    "title": "Quick start (local)",
    "section": "Data format",
    "text": "Data format\nThe data is expected to be a pandas dataframe in long format, that is, each row represents an observation of a single serie at a given time, with at least three columns:\n\nid_col: column that identifies each serie.\ntarget_col: column that has the series values at each timestamp.\ntime_col: column that contains the time the series value was observed. These are usually timestamps, but can also be consecutive integers.\n\nHere we present an example using the classic Box & Jenkins airline data, which measures monthly totals of international airline passengers from 1949 to 1960. Source: Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G.\n\nimport pandas as pd\nfrom utilsforecast.plotting import plot_series\n\n\ndf = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/air-passengers.csv', parse_dates=['ds'])\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nAirPassengers\n1949-01-01\n112\n\n\n1\nAirPassengers\n1949-02-01\n118\n\n\n2\nAirPassengers\n1949-03-01\n132\n\n\n3\nAirPassengers\n1949-04-01\n129\n\n\n4\nAirPassengers\n1949-05-01\n121\n\n\n\n\n\n\n\n\ndf['unique_id'].value_counts()\n\nAirPassengers    144\nName: unique_id, dtype: int64\n\n\nHere the unique_id column has the same value for all rows because this is a single time series, you can have multiple time series by stacking them together and having a column that differentiates them.\nWe also have the ds column that contains the timestamps, in this case with a monthly frequency, and the y column that contains the series values in each timestamp."
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html#modeling",
    "href": "docs/getting-started/quick_start_local.html#modeling",
    "title": "Quick start (local)",
    "section": "Modeling",
    "text": "Modeling\n\nfig = plot_series(df)\n\n\nWe can see that the serie has a clear trend, so we can take the first difference, i.e. take each value and subtract the value at the previous month. This can be achieved by passing an mlforecast.target_transforms.Differences([1]) instance to target_transforms.\nWe can then train a linear regression using the value from the same month at the previous year (lag 12) as a feature, this is done by passing lags=[12].\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\nfrom sklearn.linear_model import LinearRegression\n\n\nfcst = MLForecast(\n    models=LinearRegression(),\n    freq='MS',  # our serie has a monthly frequency\n    lags=[12],\n    target_transforms=[Differences([1])],\n)\nfcst.fit(df)\n\nMLForecast(models=[LinearRegression], freq=&lt;MonthBegin&gt;, lag_features=['lag12'], date_features=[], num_threads=1)\n\n\nThe previous line computed the features and trained the model, so now we’re ready to compute our forecasts."
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html#forecasting",
    "href": "docs/getting-started/quick_start_local.html#forecasting",
    "title": "Quick start (local)",
    "section": "Forecasting",
    "text": "Forecasting\nCompute the forecast for the next 12 months\n\npreds = fcst.predict(12)\npreds\n\n\n\n\n\n\n\n\nunique_id\nds\nLinearRegression\n\n\n\n\n0\nAirPassengers\n1961-01-01\n444.656555\n\n\n1\nAirPassengers\n1961-02-01\n417.470734\n\n\n2\nAirPassengers\n1961-03-01\n446.903046\n\n\n3\nAirPassengers\n1961-04-01\n491.014130\n\n\n4\nAirPassengers\n1961-05-01\n502.622223\n\n\n5\nAirPassengers\n1961-06-01\n568.751465\n\n\n6\nAirPassengers\n1961-07-01\n660.044312\n\n\n7\nAirPassengers\n1961-08-01\n643.343323\n\n\n8\nAirPassengers\n1961-09-01\n540.666687\n\n\n9\nAirPassengers\n1961-10-01\n491.462708\n\n\n10\nAirPassengers\n1961-11-01\n417.095154\n\n\n11\nAirPassengers\n1961-12-01\n461.206238"
  },
  {
    "objectID": "docs/getting-started/quick_start_local.html#visualize-results",
    "href": "docs/getting-started/quick_start_local.html#visualize-results",
    "title": "Quick start (local)",
    "section": "Visualize results",
    "text": "Visualize results\nWe can visualize what our prediction looks like.\n\nfig = plot_series(df, preds)\n\n\nAnd that’s it! You’ve trained a linear regression to predict the air passengers for 1961."
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html",
    "href": "docs/getting-started/end_to_end_walkthrough.html",
    "title": "End to end walkthrough",
    "section": "",
    "text": "For this example we’ll use a subset of the M4 hourly dataset. You can find the a notebook with the full dataset here.\n\nimport random\n\nimport pandas as pd\nfrom datasetsforecast.m4 import M4\nfrom utilsforecast.plotting import plot_series\n\n\nawait M4.async_download('data', group='Hourly')\ndf, *_ = M4.load('data', 'Hourly')\nuids = df['unique_id'].unique()\nrandom.seed(0)\nsample_uids = random.choices(uids, k=4)\ndf = df[df['unique_id'].isin(sample_uids)].reset_index(drop=True)\ndf['ds'] = df['ds'].astype('int64')\ndf\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH196\n1\n11.8\n\n\n1\nH196\n2\n11.4\n\n\n2\nH196\n3\n11.1\n\n\n3\nH196\n4\n10.8\n\n\n4\nH196\n5\n10.6\n\n\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n99.0\n\n\n4028\nH413\n1005\n88.0\n\n\n4029\nH413\n1006\n47.0\n\n\n4030\nH413\n1007\n41.0\n\n\n4031\nH413\n1008\n34.0\n\n\n\n\n4032 rows × 3 columns\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#data-setup",
    "href": "docs/getting-started/end_to_end_walkthrough.html#data-setup",
    "title": "End to end walkthrough",
    "section": "",
    "text": "For this example we’ll use a subset of the M4 hourly dataset. You can find the a notebook with the full dataset here.\n\nimport random\n\nimport pandas as pd\nfrom datasetsforecast.m4 import M4\nfrom utilsforecast.plotting import plot_series\n\n\nawait M4.async_download('data', group='Hourly')\ndf, *_ = M4.load('data', 'Hourly')\nuids = df['unique_id'].unique()\nrandom.seed(0)\nsample_uids = random.choices(uids, k=4)\ndf = df[df['unique_id'].isin(sample_uids)].reset_index(drop=True)\ndf['ds'] = df['ds'].astype('int64')\ndf\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH196\n1\n11.8\n\n\n1\nH196\n2\n11.4\n\n\n2\nH196\n3\n11.1\n\n\n3\nH196\n4\n10.8\n\n\n4\nH196\n5\n10.6\n\n\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n99.0\n\n\n4028\nH413\n1005\n88.0\n\n\n4029\nH413\n1006\n47.0\n\n\n4030\nH413\n1007\n41.0\n\n\n4031\nH413\n1008\n34.0\n\n\n\n\n4032 rows × 3 columns"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#eda",
    "href": "docs/getting-started/end_to_end_walkthrough.html#eda",
    "title": "End to end walkthrough",
    "section": "EDA",
    "text": "EDA\nWe’ll take a look at our series to get ideas for transformations and features.\n\nfig = plot_series(df, max_insample_length=24 * 14)\n\n\nWe can use the MLForecast.preprocess method to explore different transformations. It looks like these series have a strong seasonality on the hour of the day, so we can subtract the value from the same hour in the previous day to remove it. This can be done with the mlforecast.target_transforms.Differences transformer, which we pass through target_transforms.\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\n\n\nfcst = MLForecast(\n    models=[],  # we're not interested in modeling yet\n    freq=1,  # our series have integer timestamps, so we'll just add 1 in every timestep\n    target_transforms=[Differences([24])],\n)\nprep = fcst.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n24\nH196\n25\n0.3\n\n\n25\nH196\n26\n0.3\n\n\n26\nH196\n27\n0.1\n\n\n27\nH196\n28\n0.2\n\n\n28\nH196\n29\n0.2\n\n\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n39.0\n\n\n4028\nH413\n1005\n55.0\n\n\n4029\nH413\n1006\n14.0\n\n\n4030\nH413\n1007\n3.0\n\n\n4031\nH413\n1008\n4.0\n\n\n\n\n3936 rows × 3 columns\n\n\n\nThis has subtacted the lag 24 from each value, we can see what our series look like now.\n\nfig = plot_series(prep)"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#adding-features",
    "href": "docs/getting-started/end_to_end_walkthrough.html#adding-features",
    "title": "End to end walkthrough",
    "section": "Adding features",
    "text": "Adding features\n\nLags\nLooks like the seasonality is gone, we can now try adding some lag features.\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    lags=[1, 24],\n    target_transforms=[Differences([24])],    \n)\nprep = fcst.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlag1\nlag24\n\n\n\n\n48\nH196\n49\n0.1\n0.1\n0.3\n\n\n49\nH196\n50\n0.1\n0.1\n0.3\n\n\n50\nH196\n51\n0.2\n0.1\n0.1\n\n\n51\nH196\n52\n0.1\n0.2\n0.2\n\n\n52\nH196\n53\n0.1\n0.1\n0.2\n\n\n...\n...\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n39.0\n29.0\n1.0\n\n\n4028\nH413\n1005\n55.0\n39.0\n-25.0\n\n\n4029\nH413\n1006\n14.0\n55.0\n-20.0\n\n\n4030\nH413\n1007\n3.0\n14.0\n0.0\n\n\n4031\nH413\n1008\n4.0\n3.0\n-16.0\n\n\n\n\n3840 rows × 5 columns\n\n\n\n\nprep.drop(columns=['unique_id', 'ds']).corr()['y']\n\ny        1.000000\nlag1     0.622531\nlag24   -0.234268\nName: y, dtype: float64\n\n\n\n\nLag transforms\nLag transforms are defined as a dictionary where the keys are the lags and the values are lists of functions that transform an array. These must be numba jitted functions (so that computing the features doesn’t become a bottleneck). There are some implemented in the window-ops package but you can also implement your own.\nIf the function takes two or more arguments you can either:\n\nsupply a tuple (tfm_func, arg1, arg2, …)\ndefine a new function fixing the arguments\n\n\nfrom numba import njit\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\n\n@njit\ndef rolling_mean_48(x):\n    return rolling_mean(x, window_size=48)\n\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[Differences([24])],    \n    lag_transforms={\n        1: [expanding_mean],\n        24: [(rolling_mean, 48), rolling_mean_48],\n    },\n)\nprep = fcst.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nexpanding_mean_lag1\nrolling_mean_lag24_window_size48\nrolling_mean_48_lag24\n\n\n\n\n95\nH196\n96\n0.1\n0.174648\n0.150000\n0.150000\n\n\n96\nH196\n97\n0.3\n0.173611\n0.145833\n0.145833\n\n\n97\nH196\n98\n0.3\n0.175342\n0.141667\n0.141667\n\n\n98\nH196\n99\n0.3\n0.177027\n0.141667\n0.141667\n\n\n99\nH196\n100\n0.3\n0.178667\n0.141667\n0.141667\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n39.0\n0.242084\n3.437500\n3.437500\n\n\n4028\nH413\n1005\n55.0\n0.281633\n2.708333\n2.708333\n\n\n4029\nH413\n1006\n14.0\n0.337411\n2.125000\n2.125000\n\n\n4030\nH413\n1007\n3.0\n0.351324\n1.770833\n1.770833\n\n\n4031\nH413\n1008\n4.0\n0.354018\n1.208333\n1.208333\n\n\n\n\n3652 rows × 6 columns\n\n\n\nYou can see that both approaches get to the same result, you can use whichever one you feel most comfortable with.\n\n\nDate features\nIf your time column is made of timestamps then it might make sense to extract features like week, dayofweek, quarter, etc. You can do that by passing a list of strings with pandas time/date components. You can also pass functions that will take the time column as input, as we’ll show here.\n\ndef hour_index(times):\n    return times % 24\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    target_transforms=[Differences([24])],\n    date_features=[hour_index],\n)\nfcst.preprocess(df)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nhour_index\n\n\n\n\n24\nH196\n25\n0.3\n1\n\n\n25\nH196\n26\n0.3\n2\n\n\n26\nH196\n27\n0.1\n3\n\n\n27\nH196\n28\n0.2\n4\n\n\n28\nH196\n29\n0.2\n5\n\n\n...\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n39.0\n20\n\n\n4028\nH413\n1005\n55.0\n21\n\n\n4029\nH413\n1006\n14.0\n22\n\n\n4030\nH413\n1007\n3.0\n23\n\n\n4031\nH413\n1008\n4.0\n0\n\n\n\n\n3936 rows × 4 columns\n\n\n\n\n\nTarget transformations\nIf you want to do some transformation to your target before computing the features and then re-apply it after predicting you can use the target_transforms argument, which takes a list of transformations. You can find the implemented ones in mlforecast.target_transforms or you can implement your own as described in the target transformations guide.\n\nfrom mlforecast.target_transforms import LocalStandardScaler\n\n\nfcst = MLForecast(\n    models=[],\n    freq=1,\n    lags=[1],\n    target_transforms=[LocalStandardScaler()]\n)\nfcst.preprocess(df)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlag1\n\n\n\n\n1\nH196\n2\n-1.493026\n-1.383286\n\n\n2\nH196\n3\n-1.575331\n-1.493026\n\n\n3\nH196\n4\n-1.657635\n-1.575331\n\n\n4\nH196\n5\n-1.712505\n-1.657635\n\n\n5\nH196\n6\n-1.794810\n-1.712505\n\n\n...\n...\n...\n...\n...\n\n\n4027\nH413\n1004\n3.062766\n2.425012\n\n\n4028\nH413\n1005\n2.523128\n3.062766\n\n\n4029\nH413\n1006\n0.511751\n2.523128\n\n\n4030\nH413\n1007\n0.217403\n0.511751\n\n\n4031\nH413\n1008\n-0.126003\n0.217403\n\n\n\n\n4028 rows × 4 columns\n\n\n\nWe can define a naive model to test this\n\nfrom sklearn.base import BaseEstimator\n\nclass Naive(BaseEstimator):\n    def fit(self, X, y):\n        return self\n\n    def predict(self, X):\n        return X['lag1']\n\n\nfcst = MLForecast(\n    models=[Naive()],\n    freq=1,\n    lags=[1],\n    target_transforms=[LocalStandardScaler()]\n)\nfcst.fit(df)\npreds = fcst.predict(1)\npreds\n\n\n\n\n\n\n\n\nunique_id\nds\nNaive\n\n\n\n\n0\nH196\n1009\n16.8\n\n\n1\nH256\n1009\n13.4\n\n\n2\nH381\n1009\n207.0\n\n\n3\nH413\n1009\n34.0\n\n\n\n\n\n\n\nWe compare this with the last values of our serie\n\nlast_vals = df.groupby('unique_id').tail(1)\nlast_vals\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n1007\nH196\n1008\n16.8\n\n\n2015\nH256\n1008\n13.4\n\n\n3023\nH381\n1008\n207.0\n\n\n4031\nH413\n1008\n34.0\n\n\n\n\n\n\n\n\nimport numpy as np\n\n\nnp.testing.assert_allclose(preds['Naive'], last_vals['y'])"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#training",
    "href": "docs/getting-started/end_to_end_walkthrough.html#training",
    "title": "End to end walkthrough",
    "section": "Training",
    "text": "Training\nOnce you’ve decided the features, transformations and models that you want to use you can use the MLForecast.fit method instead, which will do the preprocessing and then train the models. The models can be specified as a list (which will name them by using their class name and an index if there are repeated classes) or as a dictionary where the keys are the names you want to give to the models, i.e. the name of the column that will hold their predictions, and the values are the models themselves.\n\nimport lightgbm as lgb\n\n\nlgb_params = {\n    'verbosity': -1,\n    'num_leaves': 512,\n}\n\nfcst = MLForecast(\n    models={\n        'avg': lgb.LGBMRegressor(**lgb_params),\n        'q75': lgb.LGBMRegressor(**lgb_params, objective='quantile', alpha=0.75),\n        'q25': lgb.LGBMRegressor(**lgb_params, objective='quantile', alpha=0.25),\n    },\n    freq=1,\n    target_transforms=[Differences([24])],\n    lags=[1, 24],\n    lag_transforms={\n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=[hour_index],\n)\nfcst.fit(df)\n\nMLForecast(models=[avg, q75, q25], freq=1, lag_features=['lag1', 'lag24', 'expanding_mean_lag1', 'rolling_mean_lag24_window_size48'], date_features=[&lt;function hour_index&gt;], num_threads=1)\n\n\nThis computed the features and trained three different models using them. We can now compute our forecasts."
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#forecasting",
    "href": "docs/getting-started/end_to_end_walkthrough.html#forecasting",
    "title": "End to end walkthrough",
    "section": "Forecasting",
    "text": "Forecasting\n\npreds = fcst.predict(48)\npreds\n\n\n\n\n\n\n\n\nunique_id\nds\navg\nq75\nq25\n\n\n\n\n0\nH196\n1009\n16.295257\n16.385859\n16.320666\n\n\n1\nH196\n1010\n15.910282\n16.012728\n15.856905\n\n\n2\nH196\n1011\n15.728367\n15.784867\n15.656658\n\n\n3\nH196\n1012\n15.468414\n15.503223\n15.401462\n\n\n4\nH196\n1013\n15.081279\n15.163606\n15.048576\n\n\n...\n...\n...\n...\n...\n...\n\n\n187\nH413\n1052\n100.450617\n116.461898\n52.276952\n\n\n188\nH413\n1053\n88.426800\n114.257158\n50.866960\n\n\n189\nH413\n1054\n59.675737\n89.672526\n16.440738\n\n\n190\nH413\n1055\n57.580356\n84.680943\n14.248400\n\n\n191\nH413\n1056\n42.669879\n52.000559\n12.440984\n\n\n\n\n192 rows × 5 columns\n\n\n\n\nfig = plot_series(df, preds, max_insample_length=24 * 7)"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#updating-series-values",
    "href": "docs/getting-started/end_to_end_walkthrough.html#updating-series-values",
    "title": "End to end walkthrough",
    "section": "Updating series’ values",
    "text": "Updating series’ values\nAfter you’ve trained a forecast object you can save it and load it to use later using pickle or cloudpickle. If by the time you want to use it you already know the following values of the target you can use the MLForecast.ts.update method to incorporate these, which will allow you to use these new values when computing predictions.\n\nIf no new values are provided for a serie that’s currently stored, only the previous ones are kept.\nIf new series are included they are added to the existing ones.\n\n\nfcst = MLForecast(\n    models=[Naive()],\n    freq=1,\n    lags=[1, 2, 3],\n)\nfcst.fit(df)\nfcst.predict(1)\n\n\n\n\n\n\n\n\nunique_id\nds\nNaive\n\n\n\n\n0\nH196\n1009\n16.8\n\n\n1\nH256\n1009\n13.4\n\n\n2\nH381\n1009\n207.0\n\n\n3\nH413\n1009\n34.0\n\n\n\n\n\n\n\n\nnew_values = pd.DataFrame({\n    'unique_id': ['H196', 'H256'],\n    'ds': [1009, 1009],\n    'y': [17.0, 14.0],\n})\nfcst.ts.update(new_values)\npreds = fcst.predict(1)\npreds\n\n\n\n\n\n\n\n\nunique_id\nds\nNaive\n\n\n\n\n0\nH196\n1010\n17.0\n\n\n1\nH256\n1010\n14.0\n\n\n2\nH381\n1009\n207.0\n\n\n3\nH413\n1009\n34.0"
  },
  {
    "objectID": "docs/getting-started/end_to_end_walkthrough.html#estimating-model-performance",
    "href": "docs/getting-started/end_to_end_walkthrough.html#estimating-model-performance",
    "title": "End to end walkthrough",
    "section": "Estimating model performance",
    "text": "Estimating model performance\n\nCross validation\nIn order to get an estimate of how well our model will be when predicting future data we can perform cross validation, which consist on training a few models independently on different subsets of the data, using them to predict a validation set and measuring their performance.\nSince our data depends on time, we make our splits by removing the last portions of the series and using them as validation sets. This process is implemented in MLForecast.cross_validation.\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(**lgb_params),\n    freq=1,\n    target_transforms=[Differences([24])],\n    lags=[1, 24],\n    lag_transforms={\n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=[hour_index],\n)\ncv_result = fcst.cross_validation(\n    df,\n    n_windows=4,  # number of models to train/splits to perform\n    h=48,  # length of the validation set in each window\n)\ncv_result\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\n\n\n\n\n0\nH196\n817\n816\n15.3\n15.383165\n\n\n1\nH196\n818\n816\n14.9\n14.923219\n\n\n2\nH196\n819\n816\n14.6\n14.667834\n\n\n3\nH196\n820\n816\n14.2\n14.275964\n\n\n4\nH196\n821\n816\n13.9\n13.973491\n\n\n...\n...\n...\n...\n...\n...\n\n\n187\nH413\n1004\n960\n99.0\n65.644823\n\n\n188\nH413\n1005\n960\n88.0\n71.717097\n\n\n189\nH413\n1006\n960\n47.0\n76.704377\n\n\n190\nH413\n1007\n960\n41.0\n53.446638\n\n\n191\nH413\n1008\n960\n34.0\n54.902634\n\n\n\n\n768 rows × 5 columns\n\n\n\n\nfig = plot_series(cv_result, cv_result.drop(columns='cutoff'), max_insample_length=0)\n\n\nWe can compute the RMSE on each split.\n\nfrom utilsforecast.losses import rmse\n\n\ndef evaluate_cv(df):\n    return rmse(df, models=['LGBMRegressor'], id_col='cutoff').set_index('cutoff')\n\nsplit_rmse = evaluate_cv(cv_result)\nsplit_rmse\n\n\n\n\n\n\n\n\nLGBMRegressor\n\n\ncutoff\n\n\n\n\n\n816\n29.418172\n\n\n864\n34.257598\n\n\n912\n13.145763\n\n\n960\n35.066261\n\n\n\n\n\n\n\nAnd the average RMSE across splits.\n\nsplit_rmse.mean()\n\nLGBMRegressor    27.971949\ndtype: float64\n\n\nYou can quickly try different features and evaluate them this way. We can try removing the differencing and using an exponentially weighted average of the lag 1 instead of the expanding mean.\n\nfrom window_ops.ewm import ewm_mean\n\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(**lgb_params),\n    freq=1,\n    lags=[1, 24],\n    lag_transforms={\n        1: [(ewm_mean, 0.5)],\n        24: [(rolling_mean, 48)],      \n    },\n    date_features=[hour_index],    \n)\ncv_result2 = fcst.cross_validation(\n    df,\n    n_windows=4,\n    h=48,\n)\nevaluate_cv(cv_result2).mean()\n\nLGBMRegressor    25.874446\ndtype: float64\n\n\n\n\nLightGBMCV\nIn the same spirit of estimating our model’s performance, LightGBMCV allows us to train a few LightGBM models on different partitions of the data. The main differences with MLForecast.cross_validation are:\n\nIt can only train LightGBM models.\nIt trains all models simultaneously and gives us per-iteration averages of the errors across the complete forecasting window, which allows us to find the best iteration.\n\n\nfrom mlforecast.lgb_cv import LightGBMCV\n\n\ncv = LightGBMCV(\n    freq=1,\n    target_transforms=[Differences([24])],\n    lags=[1, 24],\n    lag_transforms={\n        1: [expanding_mean],\n        24: [(rolling_mean, 48)],\n    },\n    date_features=[hour_index],\n    num_threads=2,\n)\ncv_hist = cv.fit(\n    df,\n    n_windows=4,\n    h=48,\n    params=lgb_params,\n    eval_every=5,\n    early_stopping_evals=5,    \n    compute_cv_preds=True,\n)\n\n[5] mape: 0.158639\n[10] mape: 0.163739\n[15] mape: 0.161535\n[20] mape: 0.169491\n[25] mape: 0.163690\n[30] mape: 0.164198\nEarly stopping at round 30\nUsing best iteration: 5\n\n\nAs you can see this gives us the error by iteration (controlled by the eval_every argument) and performs early stopping (which can be configured with early_stopping_evals and early_stopping_pct). If you set compute_cv_preds=True the out-of-fold predictions are computed using the best iteration found and are saved in the cv_preds_ attribute.\n\ncv.cv_preds_\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nBooster\nwindow\n\n\n\n\n0\nH196\n817\n15.3\n15.473182\n0\n\n\n1\nH196\n818\n14.9\n15.038571\n0\n\n\n2\nH196\n819\n14.6\n14.849409\n0\n\n\n3\nH196\n820\n14.2\n14.448379\n0\n\n\n4\nH196\n821\n13.9\n14.148379\n0\n\n\n...\n...\n...\n...\n...\n...\n\n\n187\nH413\n1004\n99.0\n61.425396\n3\n\n\n188\nH413\n1005\n88.0\n62.886890\n3\n\n\n189\nH413\n1006\n47.0\n57.886890\n3\n\n\n190\nH413\n1007\n41.0\n38.849009\n3\n\n\n191\nH413\n1008\n34.0\n44.720562\n3\n\n\n\n\n768 rows × 5 columns\n\n\n\n\nfig = plot_series(cv.cv_preds_, cv.cv_preds_.drop(columns='window'), max_insample_length=0)\n\n\nYou can use this class to quickly try different configurations of features and hyperparameters. Once you’ve found a combination that works you can train a model with those features and hyperparameters on all the data by creating an MLForecast object from the LightGBMCV one as follows:\n\nfinal_fcst = MLForecast.from_cv(cv)\nfinal_fcst.fit(df)\npreds = final_fcst.predict(48)\nfig = plot_series(df, preds, max_insample_length=24 * 14)"
  },
  {
    "objectID": "forecast.html",
    "href": "forecast.html",
    "title": "MLForecast",
    "section": "",
    "text": "Data\nThis shows an example with just 4 series of the M4 dataset. If you want to run it yourself on all of them, you can refer to this notebook.\n\nimport random\n\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xgboost as xgb\nfrom datasetsforecast.m4 import M4, M4Info\nfrom sklearn.linear_model import LinearRegression\nfrom utilsforecast.plotting import plot_series\nfrom window_ops.ewm import ewm_mean\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\nfrom mlforecast.lgb_cv import LightGBMCV\nfrom mlforecast.target_transforms import Differences, LocalStandardScaler\nfrom mlforecast.utils import generate_daily_series\n\n\ngroup = 'Hourly'\nawait M4.async_download('data', group=group)\ndf, *_ = M4.load(directory='data', group=group)\ndf['ds'] = df['ds'].astype('int')\nids = df['unique_id'].unique()\nrandom.seed(0)\nsample_ids = random.choices(ids, k=4)\nsample_df = df[df['unique_id'].isin(sample_ids)]\nsample_df\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n86796\nH196\n1\n11.8\n\n\n86797\nH196\n2\n11.4\n\n\n86798\nH196\n3\n11.1\n\n\n86799\nH196\n4\n10.8\n\n\n86800\nH196\n5\n10.6\n\n\n...\n...\n...\n...\n\n\n325235\nH413\n1004\n99.0\n\n\n325236\nH413\n1005\n88.0\n\n\n325237\nH413\n1006\n47.0\n\n\n325238\nH413\n1007\n41.0\n\n\n325239\nH413\n1008\n34.0\n\n\n\n\n4032 rows × 3 columns\n\n\n\nWe now split this data into train and validation.\n\ninfo = M4Info[group]\nhorizon = info.horizon\nvalid = sample_df.groupby('unique_id').tail(horizon)\ntrain = sample_df.drop(valid.index)\ntrain.shape, valid.shape\n\n((3840, 3), (192, 3))\n\n\n\n\n\nMLForecast\n\n MLForecast (models:Union[sklearn.base.BaseEstimator,List[sklearn.base.Bas\n             eEstimator],Dict[str,sklearn.base.BaseEstimator]],\n             freq:Union[int,str,pandas._libs.tslibs.offsets.BaseOffset],\n             lags:Optional[Iterable[int]]=None, lag_transforms:Optional[Di\n             ct[int,List[Union[Callable,Tuple[Callable,Any]]]]]=None,\n             date_features:Optional[Iterable[Union[str,Callable]]]=None,\n             num_threads:int=1, target_transforms:Optional[List[Union[mlfo\n             recast.target_transforms.BaseTargetTransform,mlforecast.targe\n             t_transforms.BaseGroupedArrayTargetTransform]]]=None)\n\nForecasting pipeline\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodels\ntyping.Union[sklearn.base.BaseEstimator, typing.List[sklearn.base.BaseEstimator], typing.Dict[str, sklearn.base.BaseEstimator]]\n\nModels that will be trained and used to compute the forecasts.\n\n\nfreq\ntyping.Union[int, str, pandas._libs.tslibs.offsets.BaseOffset]\n\nPandas offset, pandas offset alias, e.g. ‘D’, ‘W-THU’ or integer denoting the frequency of the series.\n\n\nlags\ntyping.Optional[typing.Iterable[int]]\nNone\nLags of the target to use as features.\n\n\nlag_transforms\ntyping.Optional[typing.Dict[int, typing.List[typing.Union[typing.Callable, typing.Tuple[typing.Callable, typing.Any]]]]]\nNone\nMapping of target lags to their transformations.\n\n\ndate_features\ntyping.Optional[typing.Iterable[typing.Union[str, typing.Callable]]]\nNone\nFeatures computed from the dates. Can be pandas date attributes or functions that will take the dates as input.\n\n\nnum_threads\nint\n1\nNumber of threads to use when computing the features.\n\n\ntarget_transforms\ntyping.Optional[typing.List[typing.Union[mlforecast.target_transforms.BaseTargetTransform, mlforecast.target_transforms.BaseGroupedArrayTargetTransform]]]\nNone\nTransformations that will be applied to the target before computing the features and restored after the forecasting step.\n\n\n\nThe MLForecast object encapsulates the feature engineering + training the models + forecasting\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(random_state=0, verbosity=-1),\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        48: [(ewm_mean, 0.3)],\n    },\n    num_threads=1,\n    target_transforms=[Differences([24])],\n)\nfcst\n\nMLForecast(models=[LGBMRegressor], freq=1, lag_features=['lag24', 'lag48', 'lag72', 'lag96', 'lag120', 'lag144', 'lag168', 'ewm_mean_lag48_alpha0.3'], date_features=[], num_threads=1)\n\n\nOnce we have this setup we can compute the features and fit the model.\n\n\n\nMLForecast.fit\n\n MLForecast.fit\n                 (df:Union[pandas.core.frame.DataFrame,polars.dataframe.fr\n                 ame.DataFrame], id_col:str='unique_id',\n                 time_col:str='ds', target_col:str='y',\n                 static_features:Optional[List[str]]=None,\n                 dropna:bool=True, keep_last_n:Optional[int]=None,\n                 max_horizon:Optional[int]=None, prediction_intervals:Opti\n                 onal[mlforecast.utils.PredictionIntervals]=None,\n                 fitted:bool=False, as_numpy:bool=False)\n\nApply the feature engineering and train the models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nSeries data in long format.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting. If None, will consider all columns (except id_col and time_col) as static.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nmax_horizon\ntyping.Optional[int]\nNone\nTrain this many models, where each model will predict a specific horizon.\n\n\nprediction_intervals\ntyping.Optional[mlforecast.utils.PredictionIntervals]\nNone\nConfiguration to calibrate prediction intervals (Conformal Prediction).\n\n\nfitted\nbool\nFalse\nSave in-sample predictions.\n\n\nas_numpy\nbool\nFalse\nCast features to numpy array.\n\n\nReturns\nMLForecast\n\nForecast object with series values and trained models.\n\n\n\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(random_state=0, verbosity=-1),\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        48: [(ewm_mean, 0.3)],\n    },\n    num_threads=1,\n    target_transforms=[Differences([24])],\n)\n\n\nfcst.fit(train, fitted=True);\n\n\n\n\nMLForecast.forecast_fitted_values\n\n MLForecast.forecast_fitted_values ()\n\nAccess in-sample predictions.\n\nfcst.forecast_fitted_values()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nLGBMRegressor\n\n\n\n\n0\nH196\n193\n12.7\n12.671271\n\n\n1\nH196\n194\n12.3\n12.271271\n\n\n2\nH196\n195\n11.9\n11.871271\n\n\n3\nH196\n196\n11.7\n11.671271\n\n\n4\nH196\n197\n11.4\n11.471271\n\n\n...\n...\n...\n...\n...\n\n\n3067\nH413\n956\n59.0\n68.280574\n\n\n3068\nH413\n957\n58.0\n70.427570\n\n\n3069\nH413\n958\n53.0\n44.767965\n\n\n3070\nH413\n959\n38.0\n48.691257\n\n\n3071\nH413\n960\n46.0\n46.652238\n\n\n\n\n3072 rows × 4 columns\n\n\n\nOnce we’ve run this we’re ready to compute our predictions.\n\n\n\nMLForecast.predict\n\n MLForecast.predict (h:int,\n                     before_predict_callback:Optional[Callable]=None,\n                     after_predict_callback:Optional[Callable]=None, new_d\n                     f:Union[pandas.core.frame.DataFrame,polars.dataframe.\n                     frame.DataFrame,NoneType]=None,\n                     level:Optional[List[Union[int,float]]]=None, X_df:Uni\n                     on[pandas.core.frame.DataFrame,polars.dataframe.frame\n                     .DataFrame,NoneType]=None,\n                     ids:Optional[List[str]]=None)\n\nCompute the predictions for the next h steps.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nNumber of periods to predict.\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\nnew_df\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame, NoneType]\nNone\nSeries data of new observations for which forecasts are to be generated.  This dataframe should have the same structure as the one used to fit the model, including any features and time series data.  If new_df is not None, the method will generate forecasts for the new observations.\n\n\nlevel\ntyping.Optional[typing.List[typing.Union[int, float]]]\nNone\nConfidence levels between 0 and 100 for prediction intervals.\n\n\nX_df\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame, NoneType]\nNone\nDataframe with the future exogenous features. Should have the id column and the time column.\n\n\nids\ntyping.Optional[typing.List[str]]\nNone\nList with subset of ids seen during training for which the forecasts should be computed.\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nPredictions for each serie and timestep, with one column per model.\n\n\n\n\npredictions = fcst.predict(horizon)\n\nWe can see at a couple of results.\n\nresults = valid.merge(predictions, on=['unique_id', 'ds'])\nfig = plot_series(train, results, max_insample_length=0)\nfig.savefig('figs/forecast__predict.png', bbox_inches='tight')\n\n\n\nPrediction intervals\nWith MLForecast, you can generate prediction intervals using Conformal Prediction. To configure Conformal Prediction, you need to pass an instance of the PredictionIntervals class to the prediction_intervals argument of the fit method. The class takes three parameters: n_windows, h and method.\n\nn_windows represents the number of cross-validation windows used to calibrate the intervals\nh is the forecast horizon\nmethod can be conformal_distribution or conformal_error; conformal_distribution (default) creates forecasts paths based on the cross-validation errors and calculate quantiles using those paths, on the other hand conformal_error calculates the error quantiles to produce prediction intervals. The strategy will adjust the intervals for each horizon step, resulting in different widths for each step. Please note that a minimum of 2 cross-validation windows must be used.\n\n\nfcst.fit(\n    train,\n    prediction_intervals=PredictionIntervals(n_windows=3, h=48)\n);\n\nAfter that, you just have to include your desired confidence levels to the predict method using the level argument. Levels must lie between 0 and 100.\n\npredictions_w_intervals = fcst.predict(48, level=[50, 80, 95])\n\n\npredictions_w_intervals.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\nLGBMRegressor-lo-95\nLGBMRegressor-lo-80\nLGBMRegressor-lo-50\nLGBMRegressor-hi-50\nLGBMRegressor-hi-80\nLGBMRegressor-hi-95\n\n\n\n\n0\nH196\n961\n16.071271\n15.958042\n15.971271\n16.005091\n16.137452\n16.171271\n16.184501\n\n\n1\nH196\n962\n15.671271\n15.553632\n15.553632\n15.578632\n15.763911\n15.788911\n15.788911\n\n\n2\nH196\n963\n15.271271\n15.153632\n15.153632\n15.162452\n15.380091\n15.388911\n15.388911\n\n\n3\nH196\n964\n14.971271\n14.858042\n14.871271\n14.905091\n15.037452\n15.071271\n15.084501\n\n\n4\nH196\n965\n14.671271\n14.553632\n14.553632\n14.562452\n14.780091\n14.788911\n14.788911\n\n\n\n\n\n\n\n\n# test we can forecast horizon lower than h \n# with prediction intervals\nfor method in ['conformal_distribution', 'conformal_errors']:\n    fcst.fit(\n        train, \n        prediction_intervals=PredictionIntervals(n_windows=3, h=48)\n    )\n\n    preds_h_lower_h = fcst.predict(1, level=[50, 80, 95])\n    preds_h_lower_h = fcst.predict(30, level=[50, 80, 95])\n\n    # test monotonicity of intervals\n    test_eq(\n        preds_h_lower_h.filter(regex='lo|hi').apply(\n            lambda x: x.is_monotonic_increasing,\n            axis=1\n        ).sum(),\n        len(preds_h_lower_h)\n    )\n\nLet’s explore the generated intervals.\n\nresults = valid.merge(predictions_w_intervals, on=['unique_id', 'ds'])\nfig = plot_series(train, results, max_insample_length=0, level=[50, 80, 95])\nfig.savefig('figs/forecast__predict_intervals.png', bbox_inches='tight')\n\n\nIf you want to reduce the computational time and produce intervals with the same width for the whole forecast horizon, simple pass h=1 to the PredictionIntervals class. The caveat of this strategy is that in some cases, variance of the absolute residuals maybe be small (even zero), so the intervals may be too narrow.\n\nfcst.fit(\n    train,  \n    prediction_intervals=PredictionIntervals(n_windows=3, h=1)\n);\n\n\npredictions_w_intervals_ws_1 = fcst.predict(48, level=[80, 90, 95])\n\nLet’s explore the generated intervals.\n\nresults = valid.merge(predictions_w_intervals_ws_1, on=['unique_id', 'ds'])\nfig = plot_series(train, results, max_insample_length=0, level=[90])\nfig.savefig('figs/forecast__predict_intervals_window_size_1.png', bbox_inches='tight')\n\n\n\n\nForecast using a pretrained model\nMLForecast allows you to use a pretrained model to generate forecasts for a new dataset. Simply provide a pandas dataframe containing the new observations as the value for the new_df argument when calling the predict method. The dataframe should have the same structure as the one used to fit the model, including any features and time series data. The function will then use the pretrained model to generate forecasts for the new observations. This allows you to easily apply a pretrained model to a new dataset and generate forecasts without the need to retrain the model.\n\nercot_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/ERCOT-clean.csv')\n# we have to convert the ds column to integers\n# since MLForecast was trained with that structure\nercot_df['ds'] = np.arange(1, len(ercot_df) + 1)\n# use the `new_df` argument to pass the ercot dataset \nercot_fcsts = fcst.predict(horizon, new_df=ercot_df)\nfig = plot_series(ercot_df, ercot_fcsts, max_insample_length=48 * 2)\n\n\nIf you want to take a look at the data that will be used to train the models you can call Forecast.preprocess.\n\n\n\n\nMLForecast.preprocess\n\n MLForecast.preprocess\n                        (df:Union[pandas.core.frame.DataFrame,polars.dataf\n                        rame.frame.DataFrame], id_col:str='unique_id',\n                        time_col:str='ds', target_col:str='y',\n                        static_features:Optional[List[str]]=None,\n                        dropna:bool=True, keep_last_n:Optional[int]=None,\n                        max_horizon:Optional[int]=None,\n                        return_X_y:bool=False, as_numpy:bool=False)\n\nAdd the features to data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nSeries data in long format.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nmax_horizon\ntyping.Optional[int]\nNone\nTrain this many models, where each model will predict a specific horizon.\n\n\nreturn_X_y\nbool\nFalse\nReturn a tuple with the features and the target. If False will return a single dataframe.\n\n\nas_numpy\nbool\nFalse\nCast features to numpy array. Only works for return_X_y=True.\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame, typing.Tuple[typing.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame], numpy.ndarray]]\n\ndf plus added features and target(s).\n\n\n\n\nprep_df = fcst.preprocess(train)\nprep_df\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlag24\nlag48\nlag72\nlag96\nlag120\nlag144\nlag168\newm_mean_lag48_alpha0.3\n\n\n\n\n86988\nH196\n193\n0.1\n0.0\n0.0\n0.0\n0.3\n0.1\n0.1\n0.3\n0.002810\n\n\n86989\nH196\n194\n0.1\n-0.1\n0.1\n0.0\n0.3\n0.1\n0.1\n0.3\n0.031967\n\n\n86990\nH196\n195\n0.1\n-0.1\n0.1\n0.0\n0.3\n0.1\n0.2\n0.1\n0.052377\n\n\n86991\nH196\n196\n0.1\n0.0\n0.0\n0.0\n0.3\n0.2\n0.1\n0.2\n0.036664\n\n\n86992\nH196\n197\n0.0\n0.0\n0.0\n0.1\n0.2\n0.2\n0.1\n0.2\n0.025665\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n325187\nH413\n956\n0.0\n10.0\n1.0\n6.0\n-53.0\n44.0\n-21.0\n21.0\n7.963225\n\n\n325188\nH413\n957\n9.0\n10.0\n10.0\n-7.0\n-46.0\n27.0\n-19.0\n24.0\n8.574257\n\n\n325189\nH413\n958\n16.0\n8.0\n5.0\n-9.0\n-36.0\n32.0\n-13.0\n8.0\n7.501980\n\n\n325190\nH413\n959\n-3.0\n17.0\n-7.0\n2.0\n-31.0\n22.0\n5.0\n-2.0\n3.151386\n\n\n325191\nH413\n960\n15.0\n11.0\n-6.0\n-5.0\n-17.0\n22.0\n-18.0\n10.0\n0.405970\n\n\n\n\n3072 rows × 11 columns\n\n\n\nIf we do this we then have to call Forecast.fit_models, since this only stores the series information.\n\n\n\nMLForecast.fit_models\n\n MLForecast.fit_models (X:Union[pandas.core.frame.DataFrame,polars.datafra\n                        me.frame.DataFrame,numpy.ndarray],\n                        y:numpy.ndarray)\n\nManually train models. Use this if you called MLForecast.preprocess beforehand.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame, numpy.ndarray]\nFeatures.\n\n\ny\nndarray\nTarget.\n\n\nReturns\nMLForecast\nForecast object with trained models.\n\n\n\n\nX, y = prep_df.drop(columns=['unique_id', 'ds', 'y']), prep_df['y']\nfcst.fit_models(X, y)\n\nMLForecast(models=[LGBMRegressor], freq=1, lag_features=['lag24', 'lag48', 'lag72', 'lag96', 'lag120', 'lag144', 'lag168', 'ewm_mean_lag48_alpha0.3'], date_features=[], num_threads=1)\n\n\n\npredictions2 = fcst.predict(horizon)\npd.testing.assert_frame_equal(predictions, predictions2)\n\n\n\n\nMLForecast.cross_validation\n\n MLForecast.cross_validation\n                              (df:Union[pandas.core.frame.DataFrame,polars\n                              .dataframe.frame.DataFrame], n_windows:int,\n                              h:int, id_col:str='unique_id',\n                              time_col:str='ds', target_col:str='y',\n                              step_size:Optional[int]=None,\n                              static_features:Optional[List[str]]=None,\n                              dropna:bool=True,\n                              keep_last_n:Optional[int]=None,\n                              refit:Union[bool,int]=True,\n                              max_horizon:Optional[int]=None, before_predi\n                              ct_callback:Optional[Callable]=None, after_p\n                              redict_callback:Optional[Callable]=None, pre\n                              diction_intervals:Optional[mlforecast.utils.\n                              PredictionIntervals]=None,\n                              level:Optional[List[Union[int,float]]]=None,\n                              input_size:Optional[int]=None,\n                              fitted:bool=False, as_numpy:bool=False)\n\nPerform time series cross validation. Creates n_windows splits where each window has h test periods, trains the models, computes the predictions and merges the actuals.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nSeries data in long format.\n\n\nn_windows\nint\n\nNumber of windows to evaluate.\n\n\nh\nint\n\nForecast horizon.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstep_size\ntyping.Optional[int]\nNone\nStep size between each cross validation window. If None it will be equal to h.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nrefit\ntyping.Union[bool, int]\nTrue\nRetrain model for each cross validation window.If False, the models are trained at the beginning and then used to predict each window.If positive int, the models are retrained every refit windows.\n\n\nmax_horizon\ntyping.Optional[int]\nNone\n\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\nprediction_intervals\ntyping.Optional[mlforecast.utils.PredictionIntervals]\nNone\nConfiguration to calibrate prediction intervals (Conformal Prediction).\n\n\nlevel\ntyping.Optional[typing.List[typing.Union[int, float]]]\nNone\nConfidence levels between 0 and 100 for prediction intervals.\n\n\ninput_size\ntyping.Optional[int]\nNone\nMaximum training samples per serie in each window. If None, will use an expanding window.\n\n\nfitted\nbool\nFalse\nStore the in-sample predictions.\n\n\nas_numpy\nbool\nFalse\nCast features to numpy array.\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nPredictions for each window with the series id, timestamp, last train date, target value and predictions from each model.\n\n\n\nIf we would like to know how good our forecast will be for a specific model and set of features then we can perform cross validation. What cross validation does is take our data and split it in two parts, where the first part is used for training and the second one for validation. Since the data is time dependant we usually take the last x observations from our data as the validation set.\nThis process is implemented in MLForecast.cross_validation, which takes our data and performs the process described above for n_windows times where each window has h validation samples in it. For example, if we have 100 samples and we want to perform 2 backtests each of size 14, the splits will be as follows:\n\nTrain: 1 to 72. Validation: 73 to 86.\nTrain: 1 to 86. Validation: 87 to 100.\n\nYou can control the size between each cross validation window using the step_size argument. For example, if we have 100 samples and we want to perform 2 backtests each of size 14 and move one step ahead in each fold (step_size=1), the splits will be as follows:\n\nTrain: 1 to 85. Validation: 86 to 99.\nTrain: 1 to 86. Validation: 87 to 100.\n\nYou can also perform cross validation without refitting your models for each window by setting refit=False. This allows you to evaluate the performance of your models using multiple window sizes without having to retrain them each time.\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(random_state=0, verbosity=-1),\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        1: [(rolling_mean, 24)],\n        24: [(rolling_mean, 24)],\n        48: [(ewm_mean, 0.3)],\n    },\n    num_threads=1,\n    target_transforms=[Differences([24])],\n)\ncv_results = fcst.cross_validation(\n    train,\n    n_windows=2,\n    h=horizon,\n    step_size=horizon,\n    fitted=True,\n)\ncv_results\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\n\n\n\n\n0\nH196\n865\n864\n15.5\n15.373393\n\n\n1\nH196\n866\n864\n15.1\n14.973393\n\n\n2\nH196\n867\n864\n14.8\n14.673393\n\n\n3\nH196\n868\n864\n14.4\n14.373393\n\n\n4\nH196\n869\n864\n14.2\n14.073393\n\n\n...\n...\n...\n...\n...\n...\n\n\n379\nH413\n956\n912\n59.0\n64.284167\n\n\n380\nH413\n957\n912\n58.0\n64.830429\n\n\n381\nH413\n958\n912\n53.0\n40.726851\n\n\n382\nH413\n959\n912\n38.0\n42.739657\n\n\n383\nH413\n960\n912\n46.0\n52.802769\n\n\n\n\n384 rows × 5 columns\n\n\n\nSince we set fitted=True we can access the predictions for the training sets as well with the cross_validation_fitted_values method.\n\nfcst.cross_validation_fitted_values()\n\n\n\n\n\n\n\n\nunique_id\nds\nfold\ny\nLGBMRegressor\n\n\n\n\n0\nH196\n193\n0\n12.7\n12.673393\n\n\n1\nH196\n194\n0\n12.3\n12.273393\n\n\n2\nH196\n195\n0\n11.9\n11.873393\n\n\n3\nH196\n196\n0\n11.7\n11.673393\n\n\n4\nH196\n197\n0\n11.4\n11.473393\n\n\n...\n...\n...\n...\n...\n...\n\n\n5563\nH413\n908\n1\n49.0\n50.620196\n\n\n5564\nH413\n909\n1\n39.0\n35.972331\n\n\n5565\nH413\n910\n1\n29.0\n29.359678\n\n\n5566\nH413\n911\n1\n24.0\n25.784563\n\n\n5567\nH413\n912\n1\n20.0\n23.168413\n\n\n\n\n5568 rows × 5 columns\n\n\n\nWe can also compute prediction intervals by passing a configuration to prediction_intervals as well as values for the width through levels.\n\ncv_results_intervals = fcst.cross_validation(\n    train,\n    n_windows=2,\n    h=horizon,\n    step_size=horizon,\n    prediction_intervals=PredictionIntervals(h=horizon),\n    level=[80, 90]\n)\ncv_results_intervals\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\nLGBMRegressor-lo-90\nLGBMRegressor-lo-80\nLGBMRegressor-hi-80\nLGBMRegressor-hi-90\n\n\n\n\n0\nH196\n865\n864\n15.5\n15.373393\n15.311379\n15.316528\n15.430258\n15.435407\n\n\n1\nH196\n866\n864\n15.1\n14.973393\n14.940556\n14.940556\n15.006230\n15.006230\n\n\n2\nH196\n867\n864\n14.8\n14.673393\n14.606230\n14.606230\n14.740556\n14.740556\n\n\n3\nH196\n868\n864\n14.4\n14.373393\n14.306230\n14.306230\n14.440556\n14.440556\n\n\n4\nH196\n869\n864\n14.2\n14.073393\n14.006230\n14.006230\n14.140556\n14.140556\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n379\nH413\n956\n912\n59.0\n64.284167\n29.890099\n34.371545\n94.196788\n98.678234\n\n\n380\nH413\n957\n912\n58.0\n64.830429\n56.874572\n57.827689\n71.833169\n72.786285\n\n\n381\nH413\n958\n912\n53.0\n40.726851\n35.296195\n35.846206\n45.607495\n46.157506\n\n\n382\nH413\n959\n912\n38.0\n42.739657\n35.292153\n35.807640\n49.671674\n50.187161\n\n\n383\nH413\n960\n912\n46.0\n52.802769\n42.465597\n43.895670\n61.709869\n63.139941\n\n\n\n\n384 rows × 9 columns\n\n\n\nThe refit argument allows us to control if we want to retrain the models in every window. It can either be:\n\nA boolean: True will retrain on every window and False only on the first one.\nA positive integer: The models will be trained on the first window and then every refit windows.\n\n\nfcst = MLForecast(\n    models=LinearRegression(),\n    freq=1,\n    lags=[1, 24],\n)\nfor refit, expected_models in zip([True, False, 2], [4, 1, 2]):\n    fcst.cross_validation(\n        train,\n        n_windows=4,\n        h=horizon,\n        refit=refit,\n    )\n    test_eq(len(fcst.cv_models_), expected_models)\n\n\nfig = plot_series(cv_results, cv_results.drop(columns='cutoff'), max_insample_length=0)\n\n\n\nfig = plot_series(cv_results_intervals, cv_results_intervals.drop(columns='cutoff'), level=[90], max_insample_length=0)\n\n\n\n\n\nMLForecast.from_cv\n\n MLForecast.from_cv (cv:mlforecast.lgb_cv.LightGBMCV)\n\nOnce you’ve found a set of features and parameters that work for your problem you can build a forecast object from it using MLForecast.from_cv, which takes the trained LightGBMCV object and builds an MLForecast object that will use the same features and parameters. Then you can call fit and predict as you normally would.\n\ncv = LightGBMCV(\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        48: [(ewm_mean, 0.3)],\n    },\n    num_threads=1,\n    target_transforms=[Differences([24])]\n)\nhist = cv.fit(\n    train,\n    n_windows=2,\n    h=horizon,\n    params={'verbosity': -1},\n)\n\n[LightGBM] [Info] Start training from score 0.084340\n[10] mape: 0.118569\n[20] mape: 0.111506\n[30] mape: 0.107314\n[40] mape: 0.106089\n[50] mape: 0.106630\nEarly stopping at round 50\nUsing best iteration: 40\n\n\n\nfcst = MLForecast.from_cv(cv)\nassert cv.best_iteration_ == fcst.models['LGBMRegressor'].n_estimators\n\n\nfcst.fit(train)\nfcst.predict(horizon)\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\n\n\n\n\n0\nH196\n961\n16.111079\n\n\n1\nH196\n962\n15.711079\n\n\n2\nH196\n963\n15.311079\n\n\n3\nH196\n964\n15.011079\n\n\n4\nH196\n965\n14.711079\n\n\n...\n...\n...\n...\n\n\n187\nH413\n1004\n92.722032\n\n\n188\nH413\n1005\n69.153603\n\n\n189\nH413\n1006\n68.811675\n\n\n190\nH413\n1007\n53.693346\n\n\n191\nH413\n1008\n46.055481\n\n\n\n\n192 rows × 3 columns\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "lgb_cv.html",
    "href": "lgb_cv.html",
    "title": "LightGBMCV",
    "section": "",
    "text": "Give us a ⭐ on Github"
  },
  {
    "objectID": "lgb_cv.html#example",
    "href": "lgb_cv.html#example",
    "title": "LightGBMCV",
    "section": "Example",
    "text": "Example\nThis shows an example with just 4 series of the M4 dataset. If you want to run it yourself on all of them, you can refer to this notebook.\n\nimport random\n\nfrom datasetsforecast.m4 import M4, M4Info\nfrom fastcore.test import test_eq, test_fail\nfrom mlforecast.target_transforms import Differences\nfrom nbdev import show_doc\nfrom window_ops.ewm import ewm_mean\nfrom window_ops.rolling import rolling_mean, seasonal_rolling_mean\n\n\ngroup = 'Hourly'\nawait M4.async_download('data', group=group)\ndf, *_ = M4.load(directory='data', group=group)\ndf['ds'] = df['ds'].astype('int')\nids = df['unique_id'].unique()\nrandom.seed(0)\nsample_ids = random.choices(ids, k=4)\nsample_df = df[df['unique_id'].isin(sample_ids)]\nsample_df\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n86796\nH196\n1\n11.8\n\n\n86797\nH196\n2\n11.4\n\n\n86798\nH196\n3\n11.1\n\n\n86799\nH196\n4\n10.8\n\n\n86800\nH196\n5\n10.6\n\n\n...\n...\n...\n...\n\n\n325235\nH413\n1004\n99.0\n\n\n325236\nH413\n1005\n88.0\n\n\n325237\nH413\n1006\n47.0\n\n\n325238\nH413\n1007\n41.0\n\n\n325239\nH413\n1008\n34.0\n\n\n\n\n4032 rows × 3 columns\n\n\n\n\ninfo = M4Info[group]\nhorizon = info.horizon\nvalid = sample_df.groupby('unique_id').tail(horizon)\ntrain = sample_df.drop(valid.index)\ntrain.shape, valid.shape\n\n((3840, 3), (192, 3))\n\n\nWhat LightGBMCV does is emulate LightGBM’s cv function where several Boosters are trained simultaneously on different partitions of the data, that is, one boosting iteration is performed on all of them at a time. This allows to have an estimate of the error by iteration, so if we combine this with early stopping we can find the best iteration to train a final model using all the data or even use these individual models’ predictions to compute an ensemble.\nIn order to have a good estimate of the forecasting performance of our model we compute predictions for the whole test period and compute a metric on that. Since this step can slow down training, there’s an eval_every parameter that can be used to control this, that is, if eval_every=10 (the default) every 10 boosting iterations we’re going to compute forecasts for the complete window and report the error.\nWe also have early stopping parameters:\n\nearly_stopping_evals: how many evaluations of the full window should we go without improving to stop training?\nearly_stopping_pct: what’s the minimum percentage improvement we want in these early_stopping_evals in order to keep training?\n\nThis makes the LightGBMCV class a good tool to quickly test different configurations of the model. Consider the following example, where we’re going to try to find out which features can improve the performance of our model. We start just using lags.\n\nstatic_fit_config = dict(\n    n_windows=2,\n    h=horizon,\n    params={'verbose': -1},\n    compute_cv_preds=True,\n)\ncv = LightGBMCV(\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],  # one week of lags\n)\n\n\n\nLightGBMCV.fit\n\n LightGBMCV.fit (df:pandas.core.frame.DataFrame, n_windows:int, h:int,\n                 id_col:str='unique_id', time_col:str='ds',\n                 target_col:str='y', step_size:Optional[int]=None,\n                 num_iterations:int=100,\n                 params:Optional[Dict[str,Any]]=None,\n                 static_features:Optional[List[str]]=None,\n                 dropna:bool=True, keep_last_n:Optional[int]=None,\n                 eval_every:int=10,\n                 weights:Optional[Sequence[float]]=None,\n                 metric:Union[str,Callable]='mape',\n                 verbose_eval:bool=True, early_stopping_evals:int=2,\n                 early_stopping_pct:float=0.01,\n                 compute_cv_preds:bool=False,\n                 before_predict_callback:Optional[Callable]=None,\n                 after_predict_callback:Optional[Callable]=None,\n                 input_size:Optional[int]=None)\n\nTrain boosters simultaneously and assess their performance on the complete forecasting window.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nSeries data in long format.\n\n\nn_windows\nint\n\nNumber of windows to evaluate.\n\n\nh\nint\n\nForecast horizon.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstep_size\ntyping.Optional[int]\nNone\nStep size between each cross validation window. If None it will be equal to h.\n\n\nnum_iterations\nint\n100\nMaximum number of boosting iterations to run.\n\n\nparams\ntyping.Optional[typing.Dict[str, typing.Any]]\nNone\nParameters to be passed to the LightGBM Boosters.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\neval_every\nint\n10\nNumber of boosting iterations to train before evaluating on the whole forecast window.\n\n\nweights\ntyping.Optional[typing.Sequence[float]]\nNone\nWeights to multiply the metric of each window. If None, all windows have the same weight.\n\n\nmetric\ntyping.Union[str, typing.Callable]\nmape\nMetric used to assess the performance of the models and perform early stopping.\n\n\nverbose_eval\nbool\nTrue\nPrint the metrics of each evaluation.\n\n\nearly_stopping_evals\nint\n2\nMaximum number of evaluations to run without improvement.\n\n\nearly_stopping_pct\nfloat\n0.01\nMinimum percentage improvement in metric value in early_stopping_evals evaluations.\n\n\ncompute_cv_preds\nbool\nFalse\nCompute predictions for each window after finding the best iteration.\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\ninput_size\ntyping.Optional[int]\nNone\nMaximum training samples per serie in each window. If None, will use an expanding window.\n\n\nReturns\ntyping.List[typing.Tuple[int, float]]\n\nList of (boosting rounds, metric value) tuples.\n\n\n\n\nhist = cv.fit(train, **static_fit_config)\n\n[LightGBM] [Info] Start training from score 51.745632\n[10] mape: 0.590690\n[20] mape: 0.251093\n[30] mape: 0.143643\n[40] mape: 0.109723\n[50] mape: 0.102099\n[60] mape: 0.099448\n[70] mape: 0.098349\n[80] mape: 0.098006\n[90] mape: 0.098718\nEarly stopping at round 90\nUsing best iteration: 80\n\n\nBy setting compute_cv_preds we get the predictions from each model on their corresponding validation fold.\n\ncv.cv_preds_\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nBooster\nwindow\n\n\n\n\n0\nH196\n865\n15.5\n15.522924\n0\n\n\n1\nH196\n866\n15.1\n14.985832\n0\n\n\n2\nH196\n867\n14.8\n14.667901\n0\n\n\n3\nH196\n868\n14.4\n14.514592\n0\n\n\n4\nH196\n869\n14.2\n14.035793\n0\n\n\n...\n...\n...\n...\n...\n...\n\n\n187\nH413\n956\n59.0\n77.227905\n1\n\n\n188\nH413\n957\n58.0\n80.589641\n1\n\n\n189\nH413\n958\n53.0\n53.986834\n1\n\n\n190\nH413\n959\n38.0\n36.749786\n1\n\n\n191\nH413\n960\n46.0\n36.281225\n1\n\n\n\n\n384 rows × 5 columns\n\n\n\nThe individual models we trained are saved, so calling predict returns the predictions from every model trained.\n\n\n\nLightGBMCV.predict\n\n LightGBMCV.predict (h:int,\n                     before_predict_callback:Optional[Callable]=None,\n                     after_predict_callback:Optional[Callable]=None,\n                     X_df:Optional[pandas.core.frame.DataFrame]=None)\n\nCompute predictions with each of the trained boosters.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon.\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\nX_df\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataframe with the future exogenous features. Should have the id column and the time column.\n\n\nReturns\nDataFrame\n\nPredictions for each serie and timestep, with one column per window.\n\n\n\n\npreds = cv.predict(horizon)\npreds\n\n\n\n\n\n\n\n\nunique_id\nds\nBooster0\nBooster1\n\n\n\n\n0\nH196\n961\n15.670252\n15.848888\n\n\n1\nH196\n962\n15.522924\n15.697399\n\n\n2\nH196\n963\n14.985832\n15.166213\n\n\n3\nH196\n964\n14.985832\n14.723238\n\n\n4\nH196\n965\n14.562152\n14.451092\n\n\n...\n...\n...\n...\n...\n\n\n187\nH413\n1004\n70.695242\n65.917620\n\n\n188\nH413\n1005\n66.216580\n62.615788\n\n\n189\nH413\n1006\n63.896573\n67.848598\n\n\n190\nH413\n1007\n46.922797\n50.981950\n\n\n191\nH413\n1008\n45.006541\n42.752819\n\n\n\n\n192 rows × 4 columns\n\n\n\nWe can average these predictions and evaluate them.\n\ndef evaluate_on_valid(preds):\n    preds = preds.copy()\n    preds['final_prediction'] = preds.drop(columns=['unique_id', 'ds']).mean(1)\n    merged = preds.merge(valid, on=['unique_id', 'ds'])\n    merged['abs_err'] = abs(merged['final_prediction'] - merged['y']) / merged['y']\n    return merged.groupby('unique_id')['abs_err'].mean().mean()\n\n\neval1 = evaluate_on_valid(preds)\neval1\n\n0.11036194712311806\n\n\nNow, since these series are hourly, maybe we can try to remove the daily seasonality by taking the 168th (24 * 7) difference, that is, substract the value at the same hour from one week ago, thus our target will be \\(z_t = y_{t} - y_{t-168}\\). The features will be computed from this target and when we predict they will be automatically re-applied.\n\ncv2 = LightGBMCV(\n    freq=1,\n    target_transforms=[Differences([24 * 7])],\n    lags=[24 * (i+1) for i in range(7)],\n)\nhist2 = cv2.fit(train, **static_fit_config)\n\n[LightGBM] [Info] Start training from score 0.519010\n[10] mape: 0.089024\n[20] mape: 0.090683\n[30] mape: 0.092316\nEarly stopping at round 30\nUsing best iteration: 10\n\n\n\nassert hist2[-1][1] &lt; hist[-1][1]\n\nNice! We achieve a better score in less iterations. Let’s see if this improvement translates to the validation set as well.\n\npreds2 = cv2.predict(horizon)\neval2 = evaluate_on_valid(preds2)\neval2\n\n0.08956665504570135\n\n\n\nassert eval2 &lt; eval1\n\nGreat! Maybe we can try some lag transforms now. We’ll try the seasonal rolling mean that averages the values “every season”, that is, if we set season_length=24 and window_size=7 then we’ll average the value at the same hour for every day of the week.\n\ncv3 = LightGBMCV(\n    freq=1,\n    target_transforms=[Differences([24 * 7])],\n    lags=[24 * (i+1) for i in range(7)],\n    lag_transforms={\n        48: [(seasonal_rolling_mean, 24, 7)],\n    },\n)\nhist3 = cv3.fit(train, **static_fit_config)\n\n[LightGBM] [Info] Start training from score 0.273641\n[10] mape: 0.086724\n[20] mape: 0.088466\n[30] mape: 0.090536\nEarly stopping at round 30\nUsing best iteration: 10\n\n\nSeems like this is helping as well!\n\nassert hist3[-1][1] &lt; hist2[-1][1]\n\nDoes this reflect on the validation set?\n\npreds3 = cv3.predict(horizon)\neval3 = evaluate_on_valid(preds3)\neval3\n\n0.08961279023129345\n\n\nNice! mlforecast also supports date features, but in this case our time column is made from integers so there aren’t many possibilites here. As you can see this allows you to iterate faster and get better estimates of the forecasting performance you can expect from your model.\nIf you’re doing hyperparameter tuning it’s useful to be able to run a couple of iterations, assess the performance, and determine if this particular configuration isn’t promising and should be discarded. For example, optuna has pruners that you can call with your current score and it decides if the trial should be discarded. We’ll now show how to do that.\nSince the CV requires a bit of setup, like the LightGBM datasets and the internal features, we have this setup method.\n\n\n\nLightGBMCV.setup\n\n LightGBMCV.setup (df:pandas.core.frame.DataFrame, n_windows:int, h:int,\n                   id_col:str='unique_id', time_col:str='ds',\n                   target_col:str='y', step_size:Optional[int]=None,\n                   params:Optional[Dict[str,Any]]=None,\n                   static_features:Optional[List[str]]=None,\n                   dropna:bool=True, keep_last_n:Optional[int]=None,\n                   weights:Optional[Sequence[float]]=None,\n                   metric:Union[str,Callable]='mape',\n                   input_size:Optional[int]=None)\n\nInitialize internal data structures to iteratively train the boosters. Use this before calling partial_fit.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nSeries data in long format.\n\n\nn_windows\nint\n\nNumber of windows to evaluate.\n\n\nh\nint\n\nForecast horizon.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nstep_size\ntyping.Optional[int]\nNone\nStep size between each cross validation window. If None it will be equal to h.\n\n\nparams\ntyping.Optional[typing.Dict[str, typing.Any]]\nNone\nParameters to be passed to the LightGBM Boosters.\n\n\nstatic_features\ntyping.Optional[typing.List[str]]\nNone\nNames of the features that are static and will be repeated when forecasting.\n\n\ndropna\nbool\nTrue\nDrop rows with missing values produced by the transformations.\n\n\nkeep_last_n\ntyping.Optional[int]\nNone\nKeep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.\n\n\nweights\ntyping.Optional[typing.Sequence[float]]\nNone\nWeights to multiply the metric of each window. If None, all windows have the same weight.\n\n\nmetric\ntyping.Union[str, typing.Callable]\nmape\nMetric used to assess the performance of the models and perform early stopping.\n\n\ninput_size\ntyping.Optional[int]\nNone\nMaximum training samples per serie in each window. If None, will use an expanding window.\n\n\nReturns\nLightGBMCV\n\nCV object with internal data structures for partial_fit.\n\n\n\n\ncv4 = LightGBMCV(\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n)\ncv4.setup(\n    train,\n    n_windows=2,\n    h=horizon,\n    params={'verbose': -1},\n)\n\nLightGBMCV(freq=1, lag_features=['lag24', 'lag48', 'lag72', 'lag96', 'lag120', 'lag144', 'lag168'], date_features=[], num_threads=1, bst_threads=8)\n\n\nOnce we have this we can call partial_fit to only train for some iterations and return the score of the forecast window.\n\n\n\nLightGBMCV.partial_fit\n\n LightGBMCV.partial_fit (num_iterations:int,\n                         before_predict_callback:Optional[Callable]=None,\n                         after_predict_callback:Optional[Callable]=None)\n\nTrain the boosters for some iterations.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum_iterations\nint\n\nNumber of boosting iterations to run\n\n\nbefore_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n\n\nafter_predict_callback\ntyping.Optional[typing.Callable]\nNone\nFunction to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n\n\nReturns\nfloat\n\nWeighted metric after training for num_iterations.\n\n\n\n\nscore = cv4.partial_fit(10)\nscore\n\n[LightGBM] [Info] Start training from score 51.745632\n\n\n0.5906900462828166\n\n\nThis is equal to the first evaluation from our first example.\n\nassert hist[0][1] == score\n\nWe can now use this score to decide if this configuration is promising. If we want to we can train some more iterations.\n\nscore2 = cv4.partial_fit(20)\n\nThis is now equal to our third metric from the first example, since this time we trained for 20 iterations.\n\nassert hist[2][1] == score2\n\n\n\nUsing a custom metric\nThe built-in metrics are MAPE and RMSE, which are computed by serie and then averaged across all series. If you want to do something different or use a different metric entirely, you can define your own metric like the following:\n\ndef weighted_mape(\n    y_true: pd.Series,\n    y_pred: pd.Series,\n    ids: pd.Series,\n    dates: pd.Series,\n):\n    \"\"\"Weighs the MAPE by the magnitude of the series values\"\"\"\n    abs_pct_err = abs(y_true - y_pred) / abs(y_true)\n    mape_by_serie = abs_pct_err.groupby(ids).mean()\n    totals_per_serie = y_pred.groupby(ids).sum()\n    series_weights = totals_per_serie / totals_per_serie.sum()\n    return (mape_by_serie * series_weights).sum()\n\n\n_ = LightGBMCV(\n    freq=1,\n    lags=[24 * (i+1) for i in range(7)],\n).fit(\n    train,\n    n_windows=2,\n    h=horizon,\n    params={'verbose': -1},\n    metric=weighted_mape,\n)\n\n[LightGBM] [Info] Start training from score 51.745632\n[10] weighted_mape: 0.480353\n[20] weighted_mape: 0.218670\n[30] weighted_mape: 0.161706\n[40] weighted_mape: 0.149992\n[50] weighted_mape: 0.149024\n[60] weighted_mape: 0.148496\nEarly stopping at round 60\nUsing best iteration: 60"
  },
  {
    "objectID": "compat.html",
    "href": "compat.html",
    "title": "mlforecast",
    "section": "",
    "text": "Give us a ⭐ on Github"
  },
  {
    "objectID": "distributed.models.ray.xgb.html",
    "href": "distributed.models.ray.xgb.html",
    "title": "RayXGBForecast",
    "section": "",
    "text": "Wrapper of xgboost.ray.RayXGBRegressor that adds a model_ property that contains the fitted model and is sent to the workers in the forecasting step.\n\n\nRayXGBForecast\n\n RayXGBForecast (objective:Union[str,Callable[[numpy.ndarray,numpy.ndarray\n                 ],Tuple[numpy.ndarray,numpy.ndarray]],NoneType]='reg:squa\n                 rederror', **kwargs:Any)\n\nImplementation of the scikit-learn API for Ray-distributed XGBoost regression. See :doc:/python/sklearn_estimator for more information.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nobjective\ntyping.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\nreg:squarederror\nSpecify the learning task and the corresponding learning objective ora custom objective function to be used (see note below).\n\n\nkwargs\ntyping.Any\n\nKeyword arguments for XGBoost Booster object. Full documentation of parameterscan be found :doc:here &lt;/parameter&gt;.Attempting to set a parameter via the constructor args and **kwargsdict simultaneously will result in a TypeError... note:: **kwargs unsupported by scikit-learn **kwargs is unsupported by scikit-learn. We do not guarantee that parameters passed via this argument will interact properly with scikit-learn... note:: Custom objective function A custom objective function can be provided for the objective parameter. In this case, it should have the signature objective(y_true, y_pred) -&gt; grad, hess: y_true: array_like of shape [n_samples] The target values y_pred: array_like of shape [n_samples] The predicted values grad: array_like of shape [n_samples] The value of the gradient for each sample point. hess: array_like of shape [n_samples] The value of the second derivative for each sample point\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mlforecast",
    "section": "",
    "text": "mlforecast is a framework to perform time series forecasting using machine learning models, with the option to scale to massive amounts of data using remote clusters.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "mlforecast",
    "section": "Install",
    "text": "Install\n\nPyPI\npip install mlforecast\n\n\nconda-forge\nconda install -c conda-forge mlforecast\nFor more detailed instructions you can refer to the installation page."
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "mlforecast",
    "section": "Quick Start",
    "text": "Quick Start\nMinimal Example\nimport lightgbm as lgb\n\nfrom mlforecast import MLForecast\nfrom sklearn.linear_model import LinearRegression\n\nmlf = MLForecast(\n    models = [LinearRegression(), lgb.LGBMRegressor()],\n    lags=[1, 12],\n    freq = 'M'\n)\nmlf.fit(df)\nmlf.predict(12)\nGet Started with this quick guide.\nFollow this end-to-end walkthrough for best practices.\n\nSample notebooks\n\nm5\nm5-polars\nm4\nm4-cv"
  },
  {
    "objectID": "index.html#why",
    "href": "index.html#why",
    "title": "mlforecast",
    "section": "Why?",
    "text": "Why?\nCurrent Python alternatives for machine learning models are slow, inaccurate and don’t scale well. So we created a library that can be used to forecast in production environments. MLForecast includes efficient feature engineering to train any machine learning model (with fit and predict methods such as sklearn) to fit millions of time series."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "mlforecast",
    "section": "Features",
    "text": "Features\n\nFastest implementations of feature engineering for time series forecasting in Python.\nOut-of-the-box compatibility with Spark, Dask, and Ray.\nProbabilistic Forecasting with Conformal Prediction.\nSupport for exogenous variables and static covariates.\nFamiliar sklearn syntax: .fit and .predict.\n\nMissing something? Please open an issue or write us in"
  },
  {
    "objectID": "index.html#examples-and-guides",
    "href": "index.html#examples-and-guides",
    "title": "mlforecast",
    "section": "Examples and Guides",
    "text": "Examples and Guides\n📚 End to End Walkthrough: model training, evaluation and selection for multiple time series.\n🔎 Probabilistic Forecasting: use Conformal Prediction to produce prediciton intervals.\n👩‍🔬 Cross Validation: robust model’s performance evaluation.\n🔌 Predict Demand Peaks: electricity load forecasting for detecting daily peaks and reducing electric bills.\n📈 Transfer Learning: pretrain a model using a set of time series and then predict another one using that pretrained model.\n🌡️ Distributed Training: use a Dask, Ray or Spark cluster to train models at scale."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "mlforecast",
    "section": "How to use",
    "text": "How to use\nThe following provides a very basic overview, for a more detailed description see the documentation.\n\nData setup\nStore your time series in a pandas dataframe in long format, that is, each row represents an observation for a specific serie and timestamp.\n\nfrom mlforecast.utils import generate_daily_series\n\nseries = generate_daily_series(\n    n_series=20,\n    max_length=100,\n    n_static_features=1,\n    static_as_categorical=False,\n    with_trend=True\n)\nseries.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\n\n\n\n\n0\nid_00\n2000-01-01\n17.519167\n72\n\n\n1\nid_00\n2000-01-02\n87.799695\n72\n\n\n2\nid_00\n2000-01-03\n177.442975\n72\n\n\n3\nid_00\n2000-01-04\n232.704110\n72\n\n\n4\nid_00\n2000-01-05\n317.510474\n72\n\n\n\n\n\n\n\n\n\nModels\nNext define your models. If you want to use the local interface this can be any regressor that follows the scikit-learn API. For distributed training there are LGBMForecast and XGBForecast.\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodels = [\n    lgb.LGBMRegressor(verbosity=-1),\n    xgb.XGBRegressor(),\n    RandomForestRegressor(random_state=0),\n]\n\n\n\nForecast object\nNow instantiate a MLForecast object with the models and the features that you want to use. The features can be lags, transformations on the lags and date features. The lag transformations are defined as numba jitted functions that transform an array, if they have additional arguments you can either supply a tuple (transform_func, arg1, arg2, …) or define new functions fixing the arguments. You can also define differences to apply to the series before fitting that will be restored when predicting.\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\nfrom numba import njit\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\n\n@njit\ndef rolling_mean_28(x):\n    return rolling_mean(x, window_size=28)\n\n\nfcst = MLForecast(\n    models=models,\n    freq='D',\n    lags=[7, 14],\n    lag_transforms={\n        1: [expanding_mean],\n        7: [rolling_mean_28]\n    },\n    date_features=['dayofweek'],\n    target_transforms=[Differences([1])],\n)\n\n\n\nTraining\nTo compute the features and train the models call fit on your Forecast object.\n\nfcst.fit(series)\n\nMLForecast(models=[LGBMRegressor, XGBRegressor, RandomForestRegressor], freq=&lt;Day&gt;, lag_features=['lag7', 'lag14', 'expanding_mean_lag1', 'rolling_mean_28_lag7'], date_features=['dayofweek'], num_threads=1)\n\n\n\n\nPredicting\nTo get the forecasts for the next n days call predict(n) on the forecast object. This will automatically handle the updates required by the features using a recursive strategy.\n\npredictions = fcst.predict(14)\npredictions\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\nXGBRegressor\nRandomForestRegressor\n\n\n\n\n0\nid_00\n2000-04-04\n299.923771\n309.664124\n298.424164\n\n\n1\nid_00\n2000-04-05\n365.424147\n382.150085\n365.816014\n\n\n2\nid_00\n2000-04-06\n432.562441\n453.373779\n436.360620\n\n\n3\nid_00\n2000-04-07\n495.628000\n527.965149\n503.670100\n\n\n4\nid_00\n2000-04-08\n60.786223\n75.762299\n62.176080\n\n\n...\n...\n...\n...\n...\n...\n\n\n275\nid_19\n2000-03-23\n36.266780\n29.889120\n34.799780\n\n\n276\nid_19\n2000-03-24\n44.370984\n34.968884\n39.920982\n\n\n277\nid_19\n2000-03-25\n50.746222\n39.970238\n46.196266\n\n\n278\nid_19\n2000-03-26\n58.906524\n45.125305\n51.653060\n\n\n279\nid_19\n2000-03-27\n63.073949\n50.682716\n56.845384\n\n\n\n\n280 rows × 5 columns\n\n\n\n\n\nVisualize results\n\nfrom utilsforecast.plotting import plot_series\n\n\nfig = plot_series(series, predictions, max_ids=4, plot_random=False)\nfig.savefig('figs/index.png', bbox_inches='tight')"
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "mlforecast",
    "section": "How to contribute",
    "text": "How to contribute\nSee CONTRIBUTING.md."
  },
  {
    "objectID": "distributed.models.dask.xgb.html",
    "href": "distributed.models.dask.xgb.html",
    "title": "DaskXGBForecast",
    "section": "",
    "text": "Wrapper of xgboost.dask.DaskXGBRegressor that adds a model_ property that contains the fitted model and is sent to the workers in the forecasting step.\n\n\nDaskXGBForecast\n\n DaskXGBForecast (max_depth:Optional[int]=None,\n                  max_leaves:Optional[int]=None,\n                  max_bin:Optional[int]=None,\n                  grow_policy:Optional[str]=None,\n                  learning_rate:Optional[float]=None,\n                  n_estimators:Optional[int]=None,\n                  verbosity:Optional[int]=None, objective:Union[str,Callab\n                  le[[numpy.ndarray,numpy.ndarray],Tuple[numpy.ndarray,num\n                  py.ndarray]],NoneType]=None, booster:Optional[str]=None,\n                  tree_method:Optional[str]=None,\n                  n_jobs:Optional[int]=None, gamma:Optional[float]=None,\n                  min_child_weight:Optional[float]=None,\n                  max_delta_step:Optional[float]=None,\n                  subsample:Optional[float]=None,\n                  sampling_method:Optional[str]=None,\n                  colsample_bytree:Optional[float]=None,\n                  colsample_bylevel:Optional[float]=None,\n                  colsample_bynode:Optional[float]=None,\n                  reg_alpha:Optional[float]=None,\n                  reg_lambda:Optional[float]=None,\n                  scale_pos_weight:Optional[float]=None,\n                  base_score:Optional[float]=None, random_state:Union[nump\n                  y.random.mtrand.RandomState,int,NoneType]=None,\n                  missing:float=nan, num_parallel_tree:Optional[int]=None,\n                  monotone_constraints:Union[Dict[str,int],str,NoneType]=N\n                  one, interaction_constraints:Union[str,Sequence[Sequence\n                  [str]],NoneType]=None,\n                  importance_type:Optional[str]=None,\n                  device:Optional[str]=None,\n                  validate_parameters:Optional[bool]=None,\n                  enable_categorical:bool=False,\n                  feature_types:Optional[Sequence[str]]=None,\n                  max_cat_to_onehot:Optional[int]=None,\n                  max_cat_threshold:Optional[int]=None,\n                  multi_strategy:Optional[str]=None,\n                  eval_metric:Union[str,List[str],Callable,NoneType]=None,\n                  early_stopping_rounds:Optional[int]=None, callbacks:Opti\n                  onal[List[xgboost.callback.TrainingCallback]]=None,\n                  **kwargs:Any)\n\nImplementation of the Scikit-Learn API for XGBoost. See :doc:/python/sklearn_estimator for more information.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmax_depth\ntyping.Optional[int]\nNone\nMaximum tree depth for base learners.\n\n\nmax_leaves\ntyping.Optional[int]\nNone\nMaximum number of leaves; 0 indicates no limit.\n\n\nmax_bin\ntyping.Optional[int]\nNone\nIf using histogram-based algorithm, maximum number of bins per feature\n\n\ngrow_policy\ntyping.Optional[str]\nNone\nTree growing policy. 0: favor splitting at nodes closest to the node, i.e. growdepth-wise. 1: favor splitting at nodes with highest loss change.\n\n\nlearning_rate\ntyping.Optional[float]\nNone\nBoosting learning rate (xgb’s “eta”)\n\n\nn_estimators\ntyping.Optional[int]\nNone\nNumber of gradient boosted trees. Equivalent to number of boostingrounds.\n\n\nverbosity\ntyping.Optional[int]\nNone\nThe degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n\n\nobjective\ntyping.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\nNone\nSpecify the learning task and the corresponding learning objective ora custom objective function to be used (see note below).\n\n\nbooster\ntyping.Optional[str]\nNone\n\n\n\ntree_method\ntyping.Optional[str]\nNone\n\n\n\nn_jobs\ntyping.Optional[int]\nNone\nNumber of parallel threads used to run xgboost. When used with otherScikit-Learn algorithms like grid search, you may choose which algorithm toparallelize and balance the threads. Creating thread contention willsignificantly slow down both algorithms.\n\n\ngamma\ntyping.Optional[float]\nNone\n(min_split_loss) Minimum loss reduction required to make a further partition on aleaf node of the tree.\n\n\nmin_child_weight\ntyping.Optional[float]\nNone\nMinimum sum of instance weight(hessian) needed in a child.\n\n\nmax_delta_step\ntyping.Optional[float]\nNone\nMaximum delta step we allow each tree’s weight estimation to be.\n\n\nsubsample\ntyping.Optional[float]\nNone\nSubsample ratio of the training instance.\n\n\nsampling_method\ntyping.Optional[str]\nNone\nSampling method. Used only by the GPU version of hist tree method. - uniform: select random training instances uniformly. - gradient_based select random training instances with higher probability when the gradient and hessian are larger. (cf. CatBoost)\n\n\ncolsample_bytree\ntyping.Optional[float]\nNone\nSubsample ratio of columns when constructing each tree.\n\n\ncolsample_bylevel\ntyping.Optional[float]\nNone\nSubsample ratio of columns for each level.\n\n\ncolsample_bynode\ntyping.Optional[float]\nNone\nSubsample ratio of columns for each split.\n\n\nreg_alpha\ntyping.Optional[float]\nNone\nL1 regularization term on weights (xgb’s alpha).\n\n\nreg_lambda\ntyping.Optional[float]\nNone\nL2 regularization term on weights (xgb’s lambda).\n\n\nscale_pos_weight\ntyping.Optional[float]\nNone\nBalancing of positive and negative weights.\n\n\nbase_score\ntyping.Optional[float]\nNone\nThe initial prediction score of all instances, global bias.\n\n\nrandom_state\ntyping.Union[numpy.random.mtrand.RandomState, int, NoneType]\nNone\nRandom number seed... note:: Using gblinear booster with shotgun updater is nondeterministic as it uses Hogwild algorithm.\n\n\nmissing\nfloat\nnan\nValue in the data which needs to be present as a missing value.\n\n\nnum_parallel_tree\ntyping.Optional[int]\nNone\n\n\n\nmonotone_constraints\ntyping.Union[typing.Dict[str, int], str, NoneType]\nNone\nConstraint of variable monotonicity. See :doc:tutorial &lt;/tutorials/monotonic&gt;for more information.\n\n\ninteraction_constraints\ntyping.Union[str, typing.Sequence[typing.Sequence[str]], NoneType]\nNone\nConstraints for interaction representing permitted interactions. Theconstraints must be specified in the form of a nested list, e.g. [[0, 1], [2,&lt;br&gt;3, 4]], where each inner list is a group of indices of features that areallowed to interact with each other. See :doc:tutorial&lt;br&gt;&lt;/tutorials/feature_interaction_constraint&gt; for more information\n\n\nimportance_type\ntyping.Optional[str]\nNone\n\n\n\ndevice\ntyping.Optional[str]\nNone\n.. versionadded:: 2.0.0Device ordinal, available options are cpu, cuda, and gpu.\n\n\nvalidate_parameters\ntyping.Optional[bool]\nNone\nGive warnings for unknown parameter.\n\n\nenable_categorical\nbool\nFalse\n.. versionadded:: 1.5.0.. note:: This parameter is experimentalExperimental support for categorical data. When enabled, cudf/pandas.DataFrameshould be used to specify categorical data type. Also, JSON/UBJSONserialization format is required.\n\n\nfeature_types\ntyping.Optional[typing.Sequence[str]]\nNone\n.. versionadded:: 1.7.0Used for specifying feature types without constructing a dataframe. See:py:class:DMatrix for details.\n\n\nmax_cat_to_onehot\ntyping.Optional[int]\nNone\n.. versionadded:: 1.6.0.. note:: This parameter is experimentalA threshold for deciding whether XGBoost should use one-hot encoding based splitfor categorical data. When number of categories is lesser than the thresholdthen one-hot encoding is chosen, otherwise the categories will be partitionedinto children nodes. Also, enable_categorical needs to be set to havecategorical feature support. See :doc:Categorical Data&lt;br&gt;&lt;/tutorials/categorical&gt; and :ref:cat-param for details.\n\n\nmax_cat_threshold\ntyping.Optional[int]\nNone\n.. versionadded:: 1.7.0.. note:: This parameter is experimentalMaximum number of categories considered for each split. Used only bypartition-based splits for preventing over-fitting. Also, enable_categoricalneeds to be set to have categorical feature support. See :doc:Categorical Data&lt;br&gt;&lt;/tutorials/categorical&gt; and :ref:cat-param for details.\n\n\nmulti_strategy\ntyping.Optional[str]\nNone\n.. versionadded:: 2.0.0.. note:: This parameter is working-in-progress.The strategy used for training multi-target models, including multi-targetregression and multi-class classification. See :doc:/tutorials/multioutput formore information.- one_output_per_tree: One model for each target.- multi_output_tree: Use multi-target trees.\n\n\neval_metric\ntyping.Union[str, typing.List[str], typing.Callable, NoneType]\nNone\n.. versionadded:: 1.6.0Metric used for monitoring the training result and early stopping. It can be astring or list of strings as names of predefined metric in XGBoost (Seedoc/parameter.rst), one of the metrics in :py:mod:sklearn.metrics, or any otheruser defined metric that looks like sklearn.metrics.If custom objective is also provided, then custom metric should implement thecorresponding reverse link function.Unlike the scoring parameter commonly used in scikit-learn, when a callableobject is provided, it’s assumed to be a cost function and by default XGBoost willminimize the result during early stopping.For advanced usage on Early stopping like directly choosing to maximize instead ofminimize, see :py:obj:xgboost.callback.EarlyStopping.See :doc:Custom Objective and Evaluation Metric &lt;/tutorials/custom_metric_obj&gt;for more... note:: This parameter replaces eval_metric in :py:meth:fit method. The old one receives un-transformed prediction regardless of whether custom objective is being used... code-block:: python from sklearn.datasets import load_diabetes from sklearn.metrics import mean_absolute_error X, y = load_diabetes(return_X_y=True) reg = xgb.XGBRegressor( tree_method=“hist”, eval_metric=mean_absolute_error, ) reg.fit(X, y, eval_set=[(X, y)])\n\n\nearly_stopping_rounds\ntyping.Optional[int]\nNone\n.. versionadded:: 1.6.0- Activates early stopping. Validation metric needs to improve at least once in every early_stopping_rounds round(s) to continue training. Requires at least one item in eval_set in :py:meth:fit.- If early stopping occurs, the model will have two additional attributes: :py:attr:best_score and :py:attr:best_iteration. These are used by the :py:meth:predict and :py:meth:apply methods to determine the optimal number of trees during inference. If users want to access the full model (including trees built after early stopping), they can specify the iteration_range in these inference methods. In addition, other utilities like model plotting can also use the entire model.- If you prefer to discard the trees after best_iteration, consider using the callback function :py:class:xgboost.callback.EarlyStopping.- If there’s more than one item in eval_set, the last entry will be used for early stopping. If there’s more than one metric in eval_metric, the last metric will be used for early stopping... note:: This parameter replaces early_stopping_rounds in :py:meth:fit method.\n\n\ncallbacks\ntyping.Optional[typing.List[xgboost.callback.TrainingCallback]]\nNone\nList of callback functions that are applied at end of each iteration.It is possible to use predefined callbacks by using:ref:Callback API &lt;callback_api&gt;... note:: States in callback are not preserved during training, which means callback objects can not be reused for multiple training sessions without reinitialization or deepcopy... code-block:: python for params in parameters_grid: # be sure to (re)initialize the callbacks before each run callbacks = [xgb.callback.LearningRateScheduler(custom_rates)] reg = xgboost.XGBRegressor(**params, callbacks=callbacks) reg.fit(X, y)\n\n\nkwargs\ntyping.Any\n\nKeyword arguments for XGBoost Booster object. Full documentation of parameterscan be found :doc:here &lt;/parameter&gt;.Attempting to set a parameter via the constructor args and **kwargsdict simultaneously will result in a TypeError... note:: **kwargs unsupported by scikit-learn **kwargs is unsupported by scikit-learn. We do not guarantee that parameters passed via this argument will interact properly with scikit-learn.\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "import datetime\n\nfrom nbdev import show_doc\nfrom fastcore.test import test_eq, test_fail, test_warns\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\nfrom window_ops.shift import shift_array\n\nfrom mlforecast.callbacks import SaveFeatures\nfrom mlforecast.lag_transforms import ExpandingMean, RollingMean\nfrom mlforecast.target_transforms import Differences, LocalStandardScaler\nfrom mlforecast.utils import generate_daily_series, generate_prices_for_series\nGive us a ⭐ on Github"
  },
  {
    "objectID": "core.html#data-format",
    "href": "core.html#data-format",
    "title": "Core",
    "section": "Data format",
    "text": "Data format\nThe required input format is a dataframe with at least the following columns: * unique_id with a unique identifier for each time serie * ds with the datestamp and a column * y with the values of the serie.\nEvery other column is considered a static feature unless stated otherwise in TimeSeries.fit\n\nseries = generate_daily_series(20, n_static_features=2)\nseries\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nstatic_1\n\n\n\n\n0\nid_00\n2000-01-01\n7.404529\n27\n53\n\n\n1\nid_00\n2000-01-02\n35.952624\n27\n53\n\n\n2\nid_00\n2000-01-03\n68.958353\n27\n53\n\n\n3\nid_00\n2000-01-04\n84.994505\n27\n53\n\n\n4\nid_00\n2000-01-05\n113.219810\n27\n53\n\n\n...\n...\n...\n...\n...\n...\n\n\n4869\nid_19\n2000-03-25\n400.606807\n97\n45\n\n\n4870\nid_19\n2000-03-26\n538.794824\n97\n45\n\n\n4871\nid_19\n2000-03-27\n620.202104\n97\n45\n\n\n4872\nid_19\n2000-03-28\n20.625426\n97\n45\n\n\n4873\nid_19\n2000-03-29\n141.513169\n97\n45\n\n\n\n\n4874 rows × 5 columns\n\n\n\nFor simplicity we’ll just take one time serie here.\n\nuids = series['unique_id'].unique()\nserie = series[series['unique_id'].eq(uids[0])]\nserie\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nstatic_1\n\n\n\n\n0\nid_00\n2000-01-01\n7.404529\n27\n53\n\n\n1\nid_00\n2000-01-02\n35.952624\n27\n53\n\n\n2\nid_00\n2000-01-03\n68.958353\n27\n53\n\n\n3\nid_00\n2000-01-04\n84.994505\n27\n53\n\n\n4\nid_00\n2000-01-05\n113.219810\n27\n53\n\n\n...\n...\n...\n...\n...\n...\n\n\n217\nid_00\n2000-08-05\n13.263188\n27\n53\n\n\n218\nid_00\n2000-08-06\n38.231981\n27\n53\n\n\n219\nid_00\n2000-08-07\n59.555183\n27\n53\n\n\n220\nid_00\n2000-08-08\n86.986368\n27\n53\n\n\n221\nid_00\n2000-08-09\n119.254810\n27\n53\n\n\n\n\n222 rows × 5 columns\n\n\n\n\n\nTimeSeries\n\n TimeSeries (freq:Union[int,str,pandas._libs.tslibs.offsets.BaseOffset,Non\n             eType]=None, lags:Optional[Iterable[int]]=None, lag_transform\n             s:Optional[Dict[int,List[Union[Callable,Tuple[Callable,Any]]]\n             ]]=None,\n             date_features:Optional[Iterable[Union[str,Callable]]]=None,\n             num_threads:int=1, target_transforms:Optional[List[Union[mlfo\n             recast.target_transforms.BaseTargetTransform,mlforecast.targe\n             t_transforms.BaseGroupedArrayTargetTransform]]]=None)\n\nUtility class for storing and transforming time series data.\nThe TimeSeries class takes care of defining the transformations to be performed (lags, lag_transforms and date_features). The transformations can be computed using multithreading if num_threads &gt; 1.\n\ndef month_start_or_end(dates):\n    return dates.is_month_start | dates.is_month_end\n\nflow_config = dict(\n    freq='W-THU',\n    lags=[7],\n    lag_transforms={\n        1: [expanding_mean, (rolling_mean, 7)]\n    },\n    date_features=['dayofweek', 'week', month_start_or_end]\n)\n\nts = TimeSeries(**flow_config)\nts\n\nTimeSeries(freq=W-THU, transforms=['lag7', 'expanding_mean_lag1', 'rolling_mean_lag1_window_size7'], date_features=['dayofweek', 'week', 'month_start_or_end'], num_threads=1)\n\n\nThe frequency is converted to an offset.\n\ntest_eq(ts.freq, pd.tseries.frequencies.to_offset(flow_config['freq']))\n\nThe date features are stored as they were passed to the constructor.\n\ntest_eq(ts.date_features, flow_config['date_features'])\n\nThe transformations are stored as a dictionary where the key is the name of the transformation (name of the column in the dataframe with the computed features), which is built using build_transform_name and the value is a tuple where the first element is the lag it is applied to, then the function and then the function arguments.\n\ntest_eq(\n    ts.transforms, \n    {\n        'lag7': Lag(7),\n        'expanding_mean_lag1': (1, expanding_mean), \n        'rolling_mean_lag1_window_size7': (1, rolling_mean, 7)\n        \n    }\n)\n\nNote that for lags we define the transformation as the identity function applied to its corresponding lag. This is because _transform_series takes the lag as an argument and shifts the array before computing the transformation."
  },
  {
    "objectID": "core.html#timeseries.fit_transform",
    "href": "core.html#timeseries.fit_transform",
    "title": "Core",
    "section": "TimeSeries.fit_transform",
    "text": "TimeSeries.fit_transform\n\n TimeSeries.fit_transform (data:Union[pandas.core.frame.DataFrame,polars.d\n                           ataframe.frame.DataFrame], id_col:str,\n                           time_col:str, target_col:str,\n                           static_features:Optional[List[str]]=None,\n                           dropna:bool=True,\n                           keep_last_n:Optional[int]=None,\n                           max_horizon:Optional[int]=None,\n                           return_X_y:bool=False, as_numpy:bool=False)\n\nAdd the features to data and save the required information for the predictions step.\nIf not all features are static, specify which ones are in static_features. If you don’t want to drop rows with null values after the transformations set dropna=False If keep_last_n is not None then that number of observations is kept across all series for updates.\n\nflow_config = dict(\n    freq='D',\n    lags=[7, 14],\n    lag_transforms={\n        2: [\n            (rolling_mean, 7),\n            (rolling_mean, 14),\n        ]\n    },\n    date_features=['dayofweek', 'month', 'year'],\n    num_threads=2\n)\n\nts = TimeSeries(**flow_config)\n_ = ts.fit_transform(series, id_col='unique_id', time_col='ds', target_col='y')\n\nThe series values are stored as a GroupedArray in an attribute ga. If the data type of the series values is an int then it is converted to np.float32, this is because lags generate np.nans so we need a float data type for them.\n\nnp.testing.assert_equal(ts.ga.data, series.y.values)\n\nThe series ids are stored in an uids attribute.\n\ntest_eq(ts.uids, series['unique_id'].unique())\n\nFor each time serie, the last observed date is stored so that predictions start from the last date + the frequency.\n\ntest_eq(ts.last_dates, series.groupby('unique_id')['ds'].max().values)\n\nThe last row of every serie without the y and ds columns are taken as static features.\n\npd.testing.assert_frame_equal(\n    ts.static_features_,\n    series.groupby('unique_id').tail(1).drop(columns=['ds', 'y']).reset_index(drop=True),\n)\n\nIf you pass static_features to TimeSeries.fit_transform then only these are kept.\n\nts.fit_transform(series, id_col='unique_id', time_col='ds', target_col='y', static_features=['static_0'])\n\npd.testing.assert_frame_equal(\n    ts.static_features_,\n    series.groupby('unique_id').tail(1)[['unique_id', 'static_0']].reset_index(drop=True),\n)\n\nYou can also specify keep_last_n in TimeSeries.fit_transform, which means that after computing the features for training we want to keep only the last n samples of each time serie for computing the updates. This saves both memory and time, since the updates are performed by running the transformation functions on all time series again and keeping only the last value (the update).\nIf you have very long time series and your updates only require a small sample it’s recommended that you set keep_last_n to the minimum number of samples required to compute the updates, which in this case is 15 since we have a rolling mean of size 14 over the lag 2 and in the first update the lag 2 becomes the lag 1. This is because in the first update the lag 1 is the last value of the series (or the lag 0), the lag 2 is the lag 1 and so on.\n\nkeep_last_n = 15\n\nts = TimeSeries(**flow_config)\ndf = ts.fit_transform(series, id_col='unique_id', time_col='ds', target_col='y', keep_last_n=keep_last_n)\nts._uids = ts.uids\nts._idxs = np.arange(len(ts.ga))\nts._predict_setup()\n\nexpected_lags = ['lag7', 'lag14']\nexpected_transforms = ['rolling_mean_lag2_window_size7', \n                       'rolling_mean_lag2_window_size14']\nexpected_date_features = ['dayofweek', 'month', 'year']\n\ntest_eq(ts.features, expected_lags + expected_transforms + expected_date_features)\ntest_eq(ts.static_features_.columns.tolist() + ts.features, df.columns.drop(['ds', 'y']).tolist())\n# we dropped 2 rows because of the lag 2 and 13 more to have the window of size 14\ntest_eq(df.shape[0], series.shape[0] - (2 + 13) * ts.ga.n_groups)\ntest_eq(ts.ga.data.size, ts.ga.n_groups * keep_last_n)\n\nTimeSeries.fit_transform requires that the y column doesn’t have any null values. This is because the transformations could propagate them forward, so if you have null values in the y column you’ll get an error.\n\nseries_with_nulls = series.copy()\nseries_with_nulls.loc[1, 'y'] = np.nan\ntest_fail(\n    lambda: ts.fit_transform(series_with_nulls, id_col='unique_id', time_col='ds', target_col='y'),\n    contains='y column contains null values'\n)"
  },
  {
    "objectID": "core.html#timeseries.predict",
    "href": "core.html#timeseries.predict",
    "title": "Core",
    "section": "TimeSeries.predict",
    "text": "TimeSeries.predict\n\n TimeSeries.predict (models:Dict[str,Union[sklearn.base.BaseEstimator,List\n                     [sklearn.base.BaseEstimator]]], horizon:int,\n                     before_predict_callback:Optional[Callable]=None,\n                     after_predict_callback:Optional[Callable]=None, X_df:\n                     Union[pandas.core.frame.DataFrame,polars.dataframe.fr\n                     ame.DataFrame,NoneType]=None,\n                     ids:Optional[List[str]]=None)\n\nOnce we have a trained model we can use TimeSeries.predict passing the model and the horizon to get the predictions back.\n\nclass DummyModel:\n    def predict(self, X: pd.DataFrame) -&gt; np.ndarray:\n        return X['lag7'].values\n\nhorizon = 7\nmodel = DummyModel()\nts = TimeSeries(**flow_config)\nts.fit_transform(series, id_col='unique_id', time_col='ds', target_col='y')\npredictions = ts.predict({'DummyModel': model}, horizon)\n\ngrouped_series = series.groupby('unique_id')\nexpected_preds = grouped_series['y'].tail(7)  # the model predicts the lag-7\nlast_dates = grouped_series['ds'].max()\nexpected_dsmin = last_dates + ts.freq\nexpected_dsmax = last_dates + horizon * ts.freq\ngrouped_preds = predictions.groupby('unique_id')\n\nnp.testing.assert_allclose(predictions['DummyModel'], expected_preds)\npd.testing.assert_series_equal(grouped_preds['ds'].min(), expected_dsmin)\npd.testing.assert_series_equal(grouped_preds['ds'].max(), expected_dsmax)\n\nIf we have dynamic features we can pass them to X_df.\n\nclass PredictPrice:\n    def predict(self, X):\n        return X['price']\n\nseries = generate_daily_series(20, n_static_features=2, equal_ends=True)\ndynamic_series = series.rename(columns={'static_1': 'product_id'})\nprices_catalog = generate_prices_for_series(dynamic_series)\nseries_with_prices = dynamic_series.merge(prices_catalog, how='left')\n\nmodel = PredictPrice()\nts = TimeSeries(**flow_config)\nts.fit_transform(\n    series_with_prices,\n    id_col='unique_id',\n    time_col='ds',\n    target_col='y',\n    static_features=['static_0', 'product_id'],\n)\npredictions = ts.predict({'PredictPrice': model}, horizon=1, X_df=prices_catalog)\npd.testing.assert_frame_equal(\n    predictions.rename(columns={'PredictPrice': 'price'}),\n    prices_catalog.merge(predictions[['unique_id', 'ds']])[['unique_id', 'ds', 'price']]\n)"
  },
  {
    "objectID": "core.html#timeseries.update",
    "href": "core.html#timeseries.update",
    "title": "Core",
    "section": "TimeSeries.update",
    "text": "TimeSeries.update\n\n TimeSeries.update\n                    (df:Union[pandas.core.frame.DataFrame,polars.dataframe\n                    .frame.DataFrame])\n\nUpdate the values of the stored series."
  },
  {
    "objectID": "target_transforms.html",
    "href": "target_transforms.html",
    "title": "Target transforms",
    "section": "",
    "text": "import pandas as pd\nfrom fastcore.test import test_fail\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PowerTransformer\nfrom utilsforecast.processing import counts_by_id\n\nfrom mlforecast import MLForecast\nfrom mlforecast.utils import generate_daily_series\n\n\n\nBaseTargetTransform\n\n BaseTargetTransform ()\n\nBase class used for target transformations.\n\n\n\nBaseGroupedArrayTargetTransform\n\n BaseGroupedArrayTargetTransform ()\n\nBase class used for target transformations that operate on grouped arrays.\n\n\n\nDifferences\n\n Differences (differences:Iterable[int])\n\nSubtracts previous values of the serie. Can be used to remove trend or seasonalities.\n\nseries = generate_daily_series(10, min_length=50, max_length=100)\n\n\ndiffs = Differences([1, 2, 5])\nid_counts = counts_by_id(series, 'unique_id')\nindptr = np.append(0, id_counts['counts'].cumsum())\nga = GroupedArray(series['y'].values, indptr)\n\n# differences are applied correctly\ntransformed = diffs.fit_transform(ga)\nassert diffs.fitted_ == []\nexpected = series.copy()\nfor d in diffs.differences:\n    expected['y'] -= expected.groupby('unique_id')['y'].shift(d)\nnp.testing.assert_allclose(transformed.data, expected['y'].values)\n\n# fitted differences are restored correctly\ndiffs.store_fitted = True\ntransformed = diffs.fit_transform(ga)\nkeep_mask = ~np.isnan(transformed.data)\nrestored = diffs.inverse_transform_fitted(transformed)\nnp.testing.assert_allclose(ga.data[keep_mask], restored.data[keep_mask])\nrestored_subs = diffs.inverse_transform_fitted(transformed.take_from_groups(slice(8, None)))\nnp.testing.assert_allclose(ga.data[keep_mask], restored_subs.data)\n\n# short series\nga = GroupedArray(np.arange(20), np.array([0, 2, 20]))\ntest_fail(lambda: diffs.fit_transform(ga), contains=\"[0]\")\n\n\ndef test_scaler(sc, series):\n    id_counts = counts_by_id(series, 'unique_id')\n    indptr = np.append(0, id_counts['counts'].cumsum())\n    ga = GroupedArray(series['y'].values, indptr)\n    transformed = sc.fit_transform(ga)\n    np.testing.assert_allclose(\n        sc.inverse_transform(transformed).data,\n        ga.data,\n    )\n    \n    def filter_df(df):\n        return (\n            df[df['unique_id'].isin(['id_0', 'id_7'])]\n            .groupby('unique_id', observed=True)\n            .head(10)\n        )\n    \n    idxs = [0, 7]\n    subset = ga.take(idxs)\n    transformed_subset = transformed.take(idxs)\n    sc.idxs = idxs\n    np.testing.assert_allclose(\n        sc.inverse_transform(transformed_subset).data,\n        subset.data,\n    )\n\n\n\n\nLocalStandardScaler\n\n LocalStandardScaler ()\n\nStandardizes each serie by subtracting its mean and dividing by its standard deviation.\n\ntest_scaler(LocalStandardScaler(), series)\n\n\n\n\nLocalMinMaxScaler\n\n LocalMinMaxScaler ()\n\nScales each serie to be in the [0, 1] interval.\n\ntest_scaler(LocalMinMaxScaler(), series)\n\n\n\n\nLocalRobustScaler\n\n LocalRobustScaler (scale:str)\n\nScaler robust to outliers.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nscale\nstr\nStatistic to use for scaling. Can be either ‘iqr’ (Inter Quartile Range) or ‘mad’ (Median Asbolute Deviation)\n\n\n\n\ntest_scaler(LocalRobustScaler(scale='iqr'), series)\n\n\ntest_scaler(LocalRobustScaler(scale='mad'), series)\n\n\n\n\nLocalBoxCox\n\n LocalBoxCox ()\n\nFinds the optimum lambda for each serie and applies the Box-Cox transformation\n\ntest_scaler(LocalBoxCox(), series)\n\n\n\n\nGlobalSklearnTransformer\n\n GlobalSklearnTransformer (transformer:sklearn.base.TransformerMixin)\n\nApplies the same scikit-learn transformer to all series.\n\n# need this import in order for isinstance to work\nfrom mlforecast.target_transforms import Differences as ExportedDifferences\n\n\nsk_boxcox = PowerTransformer(method='box-cox', standardize=False)\nboxcox_global = GlobalSklearnTransformer(sk_boxcox)\nsingle_difference = ExportedDifferences([1])\nseries = generate_daily_series(10)\nfcst = MLForecast(\n    models=[LinearRegression()],\n    freq='D',\n    lags=[1, 2],\n    target_transforms=[boxcox_global, single_difference]\n)\nprep = fcst.preprocess(series, dropna=False)\nexpected = (\n    pd.Series(\n        sk_boxcox.fit_transform(series[['y']])[:, 0], index=series['unique_id']\n    ).groupby('unique_id')\n    .diff()\n    .values\n)\nnp.testing.assert_allclose(prep['y'].values, expected)\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.models.spark.lgb.html",
    "href": "distributed.models.spark.lgb.html",
    "title": "SparkLGBMForecast",
    "section": "",
    "text": "Wrapper of synapse.ml.lightgbm.LightGBMRegressor that adds an extract_local_model method to get a local version of the trained model and broadcast it to the workers.\n\n\nSparkLGBMForecast\n\n SparkLGBMForecast ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "feature_engineering.html",
    "href": "feature_engineering.html",
    "title": "Feature engineering",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom nbdev import show_doc\nfrom window_ops.expanding import expanding_mean\n\nfrom mlforecast.utils import generate_daily_series\nGive us a ⭐ on Github"
  },
  {
    "objectID": "feature_engineering.html#setup",
    "href": "feature_engineering.html#setup",
    "title": "Feature engineering",
    "section": "Setup",
    "text": "Setup\n\nrng = np.random.RandomState(0)\nseries = generate_daily_series(100, equal_ends=True)\nstarts_ends = series.groupby('unique_id', as_index=False)['ds'].agg([min, max])\nprices = []\nfor r in starts_ends.itertuples():\n    dates = pd.date_range(r.min, r.max + 14 * pd.offsets.Day())\n    df = pd.DataFrame({'ds': dates, 'price': rng.rand(dates.size)})\n    df['unique_id'] = r.Index\n    prices.append(df)\nprices = pd.concat(prices)\nprices['price2'] = prices['price'] * rng.rand(prices.shape[0])\nprices.head()\n\n\n\n\n\n\n\n\nds\nprice\nunique_id\nprice2\n\n\n\n\n0\n2000-10-05\n0.548814\nid_00\n0.345011\n\n\n1\n2000-10-06\n0.715189\nid_00\n0.445598\n\n\n2\n2000-10-07\n0.602763\nid_00\n0.165147\n\n\n3\n2000-10-08\n0.544883\nid_00\n0.041373\n\n\n4\n2000-10-09\n0.423655\nid_00\n0.391577"
  },
  {
    "objectID": "feature_engineering.html#transform_exog",
    "href": "feature_engineering.html#transform_exog",
    "title": "Feature engineering",
    "section": "transform_exog",
    "text": "transform_exog\n\n transform_exog\n                 (df:Union[pandas.core.frame.DataFrame,polars.dataframe.fr\n                 ame.DataFrame], lags:Optional[Iterable[int]]=None, lag_tr\n                 ansforms:Optional[Dict[int,List[Union[Callable,Tuple[Call\n                 able,Any]]]]]=None, id_col:str='unique_id',\n                 time_col:str='ds', num_threads:int=1)\n\nCompute lag features for dynamic exogenous regressors.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nDataframe with ids, times and values for the exogenous regressors.\n\n\nlags\ntyping.Optional[typing.Iterable[int]]\nNone\nLags of the target to use as features.\n\n\nlag_transforms\ntyping.Optional[typing.Dict[int, typing.List[typing.Union[typing.Callable, typing.Tuple[typing.Callable, typing.Any]]]]]\nNone\nMapping of target lags to their transformations.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\nnum_threads\nint\n1\nNumber of threads to use when computing the features.\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nOriginal DataFrame with the computed features\n\n\n\n\ntransformed = transform_exog(\n    prices,\n    lags=[1, 2],\n    lag_transforms={1: [expanding_mean]}\n)\ntransformed.head()\n\n\n\n\n\n\n\n\nds\nprice\nunique_id\nprice2\nprice_lag1\nprice_lag2\nprice_expanding_mean_lag1\nprice2_lag1\nprice2_lag2\nprice2_expanding_mean_lag1\n\n\n\n\n0\n2000-10-05\n0.548814\nid_00\n0.345011\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2000-10-06\n0.715189\nid_00\n0.445598\n0.548814\nNaN\n0.548814\n0.345011\nNaN\n0.345011\n\n\n2\n2000-10-07\n0.602763\nid_00\n0.165147\n0.715189\n0.548814\n0.632001\n0.445598\n0.345011\n0.395304\n\n\n3\n2000-10-08\n0.544883\nid_00\n0.041373\n0.602763\n0.715189\n0.622255\n0.165147\n0.445598\n0.318585\n\n\n4\n2000-10-09\n0.423655\nid_00\n0.391577\n0.544883\n0.602763\n0.602912\n0.041373\n0.165147\n0.249282\n\n\n\n\n\n\n\n\nimport polars as pl\n\n\nprices_pl = pl.from_pandas(prices)\ntransformed_pl = transform_exog(\n    prices_pl,\n    lags=[1, 2],\n    lag_transforms={1: [expanding_mean]},\n    num_threads=2,\n)\ntransformed_pl.head()\n\n\nshape: (5, 10)\n\n\n\nds\nprice\nunique_id\nprice2\nprice_lag1\nprice_lag2\nprice_expanding_mean_lag1\nprice2_lag1\nprice2_lag2\nprice2_expanding_mean_lag1\n\n\ndatetime[ns]\nf64\nstr\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n2000-10-05 00:00:00\n0.548814\n\"id_00\"\n0.345011\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2000-10-06 00:00:00\n0.715189\n\"id_00\"\n0.445598\n0.548814\nNaN\n0.548814\n0.345011\nNaN\n0.345011\n\n\n2000-10-07 00:00:00\n0.602763\n\"id_00\"\n0.165147\n0.715189\n0.548814\n0.632001\n0.445598\n0.345011\n0.395304\n\n\n2000-10-08 00:00:00\n0.544883\n\"id_00\"\n0.041373\n0.602763\n0.715189\n0.622255\n0.165147\n0.445598\n0.318585\n\n\n2000-10-09 00:00:00\n0.423655\n\"id_00\"\n0.391577\n0.544883\n0.602763\n0.602912\n0.041373\n0.165147\n0.249282"
  },
  {
    "objectID": "lag_transforms.html",
    "href": "lag_transforms.html",
    "title": "Lag transforms",
    "section": "",
    "text": "RollingMax\n\n RollingMax (window_size:int, min_samples:Optional[int]=None)\n\nRolling statistic\n\n\n\nRollingMin\n\n RollingMin (window_size:int, min_samples:Optional[int]=None)\n\nRolling statistic\n\n\n\nRollingStd\n\n RollingStd (window_size:int, min_samples:Optional[int]=None)\n\nRolling statistic\n\n\n\nRollingMean\n\n RollingMean (window_size:int, min_samples:Optional[int]=None)\n\nRolling statistic\n\n\n\nSeasonalRollingMax\n\n SeasonalRollingMax (season_length:int, window_size:int,\n                     min_samples:Optional[int]=None)\n\nRolling statistic over seasonal periods\n\n\n\nSeasonalRollingMin\n\n SeasonalRollingMin (season_length:int, window_size:int,\n                     min_samples:Optional[int]=None)\n\nRolling statistic over seasonal periods\n\n\n\nSeasonalRollingStd\n\n SeasonalRollingStd (season_length:int, window_size:int,\n                     min_samples:Optional[int]=None)\n\nRolling statistic over seasonal periods\n\n\n\nSeasonalRollingMean\n\n SeasonalRollingMean (season_length:int, window_size:int,\n                      min_samples:Optional[int]=None)\n\nRolling statistic over seasonal periods\n\n\n\nExpandingMax\n\n ExpandingMax ()\n\nExpanding statistic\n\n\n\nExpandingMin\n\n ExpandingMin ()\n\nExpanding statistic\n\n\n\nExpandingStd\n\n ExpandingStd ()\n\nExpanding statistic\n\n\n\nExpandingMean\n\n ExpandingMean ()\n\nExpanding statistic\n\n\n\nExponentiallyWeightedMean\n\n ExponentiallyWeightedMean (alpha:float)\n\nExponentially weighted average\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "grouped_array.html",
    "href": "grouped_array.html",
    "title": "mlforecast",
    "section": "",
    "text": "GroupedArray\n\n GroupedArray (data:numpy.ndarray, indptr:numpy.ndarray)\n\nArray made up of different groups. Can be thought of (and iterated) as a list of arrays.\nAll the data is stored in a single 1d array data. The indices for the group boundaries are stored in another 1d array indptr.\n\nimport copy\n\nfrom fastcore.test import test_eq, test_fail\n\n\n# The `GroupedArray` is used internally for storing the series values and performing transformations.\ndata = np.arange(10, dtype=np.float32)\nindptr = np.array([0, 2, 10])  # group 1: [0, 1], group 2: [2..9]\nga = GroupedArray(data, indptr)\ntest_eq(len(ga), 2)\ntest_eq(str(ga), 'GroupedArray(ndata=10, n_groups=2)')\n\n\n# Iterate through the groups\nga_iter = iter(ga)\nnp.testing.assert_equal(next(ga_iter), np.array([0, 1]))\nnp.testing.assert_equal(next(ga_iter), np.arange(2, 10))\n\n\n# Take the last two observations from every group\nlast_2 = ga.take_from_groups(slice(-2, None))\nnp.testing.assert_equal(last_2.data, np.array([0, 1, 8, 9]))\nnp.testing.assert_equal(last_2.indptr, np.array([0, 2, 4]))\n\n\n# Take the last four observations from every group. Note that since group 1 only has two elements, only these are returned.\nlast_4 = ga.take_from_groups(slice(-4, None))\nnp.testing.assert_equal(last_4.data, np.array([0, 1, 6, 7, 8, 9]))\nnp.testing.assert_equal(last_4.indptr, np.array([0, 2, 6]))\n\n\n# Select a specific subset of groups\nindptr = np.array([0, 2, 4, 7, 10])\nga2 = GroupedArray(data, indptr)\nsubset = ga2.take([0, 2])\nnp.testing.assert_allclose(subset[0].data, ga2[0].data)\nnp.testing.assert_allclose(subset[1].data, ga2[2].data)\n\n\n# The groups are [0, 1], [2, ..., 9]. expand_target(2) should take rolling pairs of them and fill with nans when there aren't enough\nnp.testing.assert_equal(\n    ga.expand_target(2),\n    np.array([\n        [0, 1],\n        [1, np.nan],\n        [2, 3],\n        [3, 4],\n        [4, 5],\n        [5, 6],\n        [6, 7],\n        [7, 8],\n        [8, 9],\n        [9, np.nan]\n    ])\n)\n\n\n# try to append new values that don't match the number of groups\ntest_fail(lambda: ga.append(np.array([1., 2., 3.])), contains='new must be of size 2')\n\n\n# __setitem__\nnew_vals = np.array([10, 11])\nga[0] = new_vals\nnp.testing.assert_equal(ga.data, np.append(new_vals, np.arange(2, 10)))\n\n\nga_copy = copy.copy(ga)\nga_copy.data[0] = 900\nassert ga.data[0] == 10\nassert ga.indptr is ga_copy.indptr\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.models.ray.lgb.html",
    "href": "distributed.models.ray.lgb.html",
    "title": "RayLGBMForecast",
    "section": "",
    "text": "Wrapper of lightgbm.ray.RayLGBMRegressor that adds a model_ property that contains the fitted booster and is sent to the workers to in the forecasting step.\n\n\nRayLGBMForecast\n\n RayLGBMForecast (boosting_type:str='gbdt', num_leaves:int=31,\n                  max_depth:int=-1, learning_rate:float=0.1,\n                  n_estimators:int=100, subsample_for_bin:int=200000, obje\n                  ctive:Union[str,Callable[[Optional[numpy.ndarray],numpy.\n                  ndarray],Tuple[numpy.ndarray,numpy.ndarray]],Callable[[O\n                  ptional[numpy.ndarray],numpy.ndarray,Optional[numpy.ndar\n                  ray]],Tuple[numpy.ndarray,numpy.ndarray]],Callable[[Opti\n                  onal[numpy.ndarray],numpy.ndarray,Optional[numpy.ndarray\n                  ],Optional[numpy.ndarray]],Tuple[numpy.ndarray,numpy.nda\n                  rray]],NoneType]=None,\n                  class_weight:Union[Dict,str,NoneType]=None,\n                  min_split_gain:float=0.0, min_child_weight:float=0.001,\n                  min_child_samples:int=20, subsample:float=1.0,\n                  subsample_freq:int=0, colsample_bytree:float=1.0,\n                  reg_alpha:float=0.0, reg_lambda:float=0.0, random_state:\n                  Union[int,numpy.random.mtrand.RandomState,NoneType]=None\n                  , n_jobs:Optional[int]=None,\n                  importance_type:str='split', **kwargs)\n\nPublicAPI (beta): This API is in beta and may change before becoming stable.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/install.html",
    "href": "docs/getting-started/install.html",
    "title": "Install",
    "section": "",
    "text": "To install the latest release of mlforecast from PyPI you just have to run the following in a terminal:\npip install mlforecast\n\n\n\nIf you want a specific version you can include a filter, for example:\n\npip install \"mlforecast==0.3.0\" to install the 0.3.0 version\npip install \"mlforecast&lt;0.4.0\" to install any version prior to 0.4.0\n\n\n\n\n\n\n\nThe mlforecast package is also published to conda-forge, which you can install by running the following in a terminal:\nconda install -c conda-forge mlforecast\nNote that this happens about a day later after it is published to PyPI, so you may have to wait to get the latest release.\n\n\n\nIf you want a specific version you can include a filter, for example:\n\nconda install -c conda-forge \"mlforecast==0.3.0\" to install the 0.3.0 version\nconda install -c conda-forge \"mlforecast&lt;0.4.0\" to install any version prior to 0.4.0\n\n\n\n\n\nIf you want to perform distributed training you can use either dask, ray or spark. Once you know which framework you want to use you can include its extra:\n\ndask: pip install \"mlforecast[dask]\"\nray: pip install \"mlforecast[ray]\"\nspark: pip install \"mlforecast[spark]\"\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/install.html#released-versions",
    "href": "docs/getting-started/install.html#released-versions",
    "title": "Install",
    "section": "",
    "text": "To install the latest release of mlforecast from PyPI you just have to run the following in a terminal:\npip install mlforecast\n\n\n\nIf you want a specific version you can include a filter, for example:\n\npip install \"mlforecast==0.3.0\" to install the 0.3.0 version\npip install \"mlforecast&lt;0.4.0\" to install any version prior to 0.4.0\n\n\n\n\n\n\n\nThe mlforecast package is also published to conda-forge, which you can install by running the following in a terminal:\nconda install -c conda-forge mlforecast\nNote that this happens about a day later after it is published to PyPI, so you may have to wait to get the latest release.\n\n\n\nIf you want a specific version you can include a filter, for example:\n\nconda install -c conda-forge \"mlforecast==0.3.0\" to install the 0.3.0 version\nconda install -c conda-forge \"mlforecast&lt;0.4.0\" to install any version prior to 0.4.0\n\n\n\n\n\nIf you want to perform distributed training you can use either dask, ray or spark. Once you know which framework you want to use you can include its extra:\n\ndask: pip install \"mlforecast[dask]\"\nray: pip install \"mlforecast[ray]\"\nspark: pip install \"mlforecast[spark]\""
  },
  {
    "objectID": "docs/getting-started/install.html#development-version",
    "href": "docs/getting-started/install.html#development-version",
    "title": "Install",
    "section": "Development version",
    "text": "Development version\nIf you want to try out a new feature that hasn’t made it into a release yet you have the following options:\n\nInstall from github: pip install git+https://github.com/Nixtla/mlforecast\nClone and install:\n\ngit clone https://github.com/Nixtla/mlforecast\npip install mlforecast\n\n\nwhich will install the version from the current main branch."
  },
  {
    "objectID": "docs/getting-started/quick_start_distributed.html",
    "href": "docs/getting-started/quick_start_distributed.html",
    "title": "Quick start (distributed)",
    "section": "",
    "text": "The DistributedMLForecast class is a high level abstraction that encapsulates all the steps in the pipeline (preprocessing, fitting the model and computing predictions) and applies them in a distributed way.\nThe different things that you need to use DistributedMLForecast (as opposed to MLForecast) are:\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\nfrom mlforecast.distributed import DistributedMLForecast\nfrom mlforecast.target_transforms import Differences\nfrom mlforecast.utils import backtest_splits, generate_daily_series, generate_prices_for_series\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/quick_start_distributed.html#dask",
    "href": "docs/getting-started/quick_start_distributed.html#dask",
    "title": "Quick start (distributed)",
    "section": "Dask",
    "text": "Dask\n\nimport dask.dataframe as dd\nfrom dask.distributed import Client\n\n\nClient setup\n\nclient = Client(n_workers=2, threads_per_worker=1)\n\nHere we define a client that connects to a dask.distributed.LocalCluster, however it could be any other kind of cluster.\n\n\nData setup\nFor dask, the data must be a dask.dataframe.DataFrame. You need to make sure that each time serie is only in one partition and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set num_threads=1 to avoid having nested parallelism.\nThe required input format is the same as for MLForecast, except that it’s a dask.dataframe.DataFrame instead of a pandas.Dataframe.\n\nseries = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False, min_length=500, max_length=1_000)\nnpartitions = 10\npartitioned_series = dd.from_pandas(series.set_index('unique_id'), npartitions=npartitions)  # make sure we split by the id_col\npartitioned_series = partitioned_series.map_partitions(lambda df: df.reset_index())\npartitioned_series['unique_id'] = partitioned_series['unique_id'].astype(str)  # can't handle categoricals atm\npartitioned_series\n\nDask DataFrame Structure:\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nstatic_1\n\n\nnpartitions=10\n\n\n\n\n\n\n\n\n\nid_00\nobject\ndatetime64[ns]\nfloat64\nint64\nint64\n\n\nid_10\n...\n...\n...\n...\n...\n\n\n...\n...\n...\n...\n...\n...\n\n\nid_90\n...\n...\n...\n...\n...\n\n\nid_99\n...\n...\n...\n...\n...\n\n\n\n\n\nDask Name: assign, 5 graph layers\n\n\n\n\nModels\nIn order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using dask. The current implementations are in DaskLGBMForecast and DaskXGBForecast which are just wrappers around the native implementations.\n\nfrom mlforecast.distributed.models.dask.lgb import DaskLGBMForecast\nfrom mlforecast.distributed.models.dask.xgb import DaskXGBForecast\n\n\nmodels = [DaskXGBForecast(random_state=0), DaskLGBMForecast(random_state=0)]\n\n\n\nTraining\nOnce we have our models we instantiate a DistributedMLForecast object defining our features. We can then call fit on this object passing our dask dataframe.\n\nfcst = DistributedMLForecast(\n    models=models,\n    freq='D',\n    lags=[7],\n    lag_transforms={\n        1: [expanding_mean],\n        7: [(rolling_mean, 14)]\n    },\n    date_features=['dayofweek', 'month'],\n    num_threads=1,\n    engine=client,\n)\nfcst.fit(partitioned_series)\n\nOnce we have our fitted models we can compute the predictions for the next 7 timesteps.\n\n\nForecasting\n\npreds = fcst.predict(7)\npreds.compute().head()\n\n\n\n\n\n\n\n\nunique_id\nds\nDaskXGBForecast\nDaskLGBMForecast\n\n\n\n\n0\nid_00\n2002-09-27\n18.676165\n17.691819\n\n\n1\nid_00\n2002-09-28\n90.782455\n90.198168\n\n\n2\nid_00\n2002-09-29\n169.503098\n163.522410\n\n\n3\nid_00\n2002-09-30\n241.540359\n244.411795\n\n\n4\nid_00\n2002-10-01\n315.643768\n313.694593\n\n\n\n\n\n\n\n\n\nCross validation\n\ncv_res = fcst.cross_validation(\n    partitioned_series,\n    n_windows=3,\n    h=14,\n)\ncv_res\n\n\ncv_res.compute().head()\n\n\n\n\n\n\n\n\nunique_id\nds\nDaskXGBForecast\nDaskLGBMForecast\ncutoff\ny\n\n\n\n\n0\nid_00\n2002-08-16\n19.199099\n18.868631\n2002-08-15\n11.878591\n\n\n1\nid_00\n2002-08-17\n93.734985\n92.715766\n2002-08-15\n75.108162\n\n\n2\nid_00\n2002-08-18\n163.924606\n167.229730\n2002-08-15\n175.278407\n\n\n3\nid_00\n2002-08-19\n245.957672\n241.534768\n2002-08-15\n226.062025\n\n\n4\nid_00\n2002-08-20\n309.519073\n306.687081\n2002-08-15\n318.433401\n\n\n\n\n\n\n\n\nclient.close()"
  },
  {
    "objectID": "docs/getting-started/quick_start_distributed.html#spark",
    "href": "docs/getting-started/quick_start_distributed.html#spark",
    "title": "Quick start (distributed)",
    "section": "Spark",
    "text": "Spark\n\nSession setup\n\nfrom pyspark.sql import SparkSession\n\n\nspark = (\n    SparkSession\n    .builder\n    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.10.2\")\n    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n    .getOrCreate()\n)\n\n\n\nData setup\nFor spark, the data must be a pyspark DataFrame. You need to make sure that each time serie is only in one partition (which you can do using repartitionByRange, for example) and it is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set num_threads=1 to avoid having nested parallelism.\nThe required input format is the same as for MLForecast, i.e. it should have at least an id column, a time column and a target column.\n\nnumPartitions = 4\nseries = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\nspark_series = spark.createDataFrame(series).repartitionByRange(numPartitions, 'unique_id')\n\n\n\nModels\nIn order to perform distributed forecasting, we need to use a model that is able to train in a distributed way using spark. The current implementations are in SparkLGBMForecast and SparkXGBForecast which are just wrappers around the native implementations.\n\nfrom mlforecast.distributed.models.spark.lgb import SparkLGBMForecast\n\nmodels = [SparkLGBMForecast()]\ntry:\n    from xgboost.spark import SparkXGBRegressor\n    from mlforecast.distributed.models.spark.xgb import SparkXGBForecast\n    models.append(SparkXGBForecast())\nexcept ModuleNotFoundError:  # py &lt; 38\n    pass\n\n\n\nTraining\n\nfcst = DistributedMLForecast(\n    models,\n    freq='D',\n    lags=[1],\n    lag_transforms={\n        1: [expanding_mean]\n    },\n    date_features=['dayofweek'],\n)\nfcst.fit(\n    spark_series,\n    static_features=['static_0', 'static_1'],\n)\n\n\n\nForecasting\n\npreds = fcst.predict(14)\n\n\npreds.toPandas().head()\n\n/hdd/miniforge3/envs/mlforecast/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n  series = series.astype(t, copy=False)\n\n\n\n\n\n\n\n\n\nunique_id\nds\nSparkLGBMForecast\nSparkXGBForecast\n\n\n\n\n0\nid_00\n2001-05-15\n422.139843\n421.606537\n\n\n1\nid_00\n2001-05-16\n497.180212\n505.575836\n\n\n2\nid_00\n2001-05-17\n13.062478\n15.462178\n\n\n3\nid_00\n2001-05-18\n100.601041\n102.123245\n\n\n4\nid_00\n2001-05-19\n180.707848\n182.308197\n\n\n\n\n\n\n\n\n\nCross validation\n\ncv_res = fcst.cross_validation(\n    spark_series,\n    n_windows=3,\n    h=14,\n).toPandas()\n\n\ncv_res.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nSparkLGBMForecast\nSparkXGBForecast\ncutoff\ny\n\n\n\n\n0\nid_04\n2001-04-03\n206.226409\n202.242142\n2001-04-02\n216.937502\n\n\n1\nid_00\n2001-04-03\n415.538504\n420.034576\n2001-04-02\n429.217687\n\n\n2\nid_00\n2001-04-07\n180.093252\n179.349228\n2001-04-02\n192.303211\n\n\n3\nid_12\n2001-04-07\n143.923572\n145.318710\n2001-04-02\n155.071484\n\n\n4\nid_19\n2001-04-15\n19.385093\n74.153099\n2001-04-02\n14.420419\n\n\n\n\n\n\n\n\nspark.stop()"
  },
  {
    "objectID": "docs/getting-started/quick_start_distributed.html#ray",
    "href": "docs/getting-started/quick_start_distributed.html#ray",
    "title": "Quick start (distributed)",
    "section": "Ray",
    "text": "Ray\n\nSession setup\n\nimport ray\nfrom ray.cluster_utils import Cluster\n\n\nray_cluster = Cluster(\n    initialize_head=True,\n    head_node_args={\"num_cpus\": 2}\n)\nray.init(address=ray_cluster.address, ignore_reinit_error=True)\n# add mock node to simulate a cluster\nmock_node = ray_cluster.add_node(num_cpus=2)\n\n\n\nData setup\nFor ray, the data must be a ray DataFrame. It is recommended that you have as many partitions as you have workers. If you have more partitions than workers make sure to set num_threads=1 to avoid having nested parallelism.\nThe required input format is the same as for MLForecast, i.e. it should have at least an id column, a time column and a target column.\n\nseries = generate_daily_series(100, n_static_features=2, equal_ends=True, static_as_categorical=False)\n# we need noncategory unique_id\nseries['unique_id'] = series['unique_id'].astype(str)\nray_series = ray.data.from_pandas(series)\n\n\n\nModels\nThe ray integration allows to include lightgbm (RayLGBMRegressor), and xgboost (RayXGBRegressor).\n\nfrom mlforecast.distributed.models.ray.lgb import RayLGBMForecast\nfrom mlforecast.distributed.models.ray.xgb import RayXGBForecast\n\n\nmodels = [\n    RayLGBMForecast(),\n    RayXGBForecast(),\n]\n\n\n\nTraining\nTo control the number of partitions to use using Ray, we have to include num_partitions to DistributedMLForecast.\n\nnum_partitions = 4\n\n\nfcst = DistributedMLForecast(\n    models,\n    freq='D',\n    lags=[1],\n    lag_transforms={\n        1: [expanding_mean]\n    },\n    date_features=['dayofweek'],\n    num_partitions=num_partitions, # Use num_partitions to reduce overhead\n)\nfcst.fit(\n    ray_series,\n    static_features=['static_0', 'static_1'],\n)\n\n\n\nForecasting\n\npreds = fcst.predict(14).to_pandas()\n\n\npreds.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nRayLGBMForecast\nRayXGBForecast\n\n\n\n\n0\nid_00\n2001-05-15\n422.139843\n419.180908\n\n\n1\nid_00\n2001-05-16\n497.180212\n502.074249\n\n\n2\nid_00\n2001-05-17\n13.062478\n16.981802\n\n\n3\nid_00\n2001-05-18\n100.601041\n102.311279\n\n\n4\nid_00\n2001-05-19\n180.707848\n181.406143\n\n\n\n\n\n\n\n\n\nCross validation\n\ncv_res = fcst.cross_validation(\n    ray_series,\n    n_windows=3,\n    h=14,\n).to_pandas()\n\n\ncv_res.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nRayLGBMForecast\nRayXGBForecast\ncutoff\ny\n\n\n\n\n0\nid_01\n2001-05-01\n124.758319\n122.131401\n2001-04-30\n117.876479\n\n\n1\nid_01\n2001-05-02\n145.041000\n149.217972\n2001-04-30\n153.394375\n\n\n2\nid_01\n2001-05-03\n178.838681\n178.600784\n2001-04-30\n175.337772\n\n\n3\nid_01\n2001-05-04\n27.212783\n10.926006\n2001-04-30\n13.202898\n\n\n4\nid_01\n2001-05-05\n56.624979\n38.081158\n2001-04-30\n30.203090\n\n\n\n\n\n\n\n\nray.shutdown()"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html",
    "title": "Prediction intervals",
    "section": "",
    "text": "The objective of the following article is to obtain a step-by-step guide on building Prediction intervals in forecasting models using mlforecast.\nDuring this walkthrough, we will become familiar with the main MlForecast class and some relevant methods such as MLForecast.fit, MLForecast.predict and MLForecast.cross_validation in other.\nLet’s start!!!\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#forecast-distributions",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#forecast-distributions",
    "title": "Prediction intervals",
    "section": "Forecast distributions",
    "text": "Forecast distributions\nWe use forecast distributions to express the uncertainty in our predictions. These probability distributions describe the probability of observing different future values using the fitted model. The point forecast corresponds to the mean of this distribution. Most time series models generate forecasts that follow a normal distribution, which implies that we assume that possible future values follow a normal distribution. However, later in this section we will look at some alternatives to normal distributions.\n\nImportance of Confidence Interval Prediction in Time Series:\n\nUncertainty Estimation: The confidence interval provides a measure of the uncertainty associated with time series predictions. It enables variability and the range of possible future values to be quantified, which is essential for making informed decisions.\nPrecision evaluation: By having a confidence interval, the precision of the predictions can be evaluated. If the interval is narrow, it indicates that the forecast is more accurate and reliable. On the other hand, if the interval is wide, it indicates greater uncertainty and less precision in the predictions.\nRisk management: The confidence interval helps in risk management by providing information about possible future scenarios. It allows identifying the ranges in which the real values could be located and making decisions based on those possible scenarios.\nEffective communication: The confidence interval is a useful tool for communicating predictions clearly and accurately. It allows the variability and uncertainty associated with the predictions to be conveyed to the stakeholders, avoiding a wrong or overly optimistic interpretation of the results.\n\nTherefore, confidence interval prediction in time series is essential to understand and manage uncertainty, assess the accuracy of predictions, and make informed decisions based on possible future scenarios."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#prediction-intervals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#prediction-intervals",
    "title": "Prediction intervals",
    "section": "Prediction intervals",
    "text": "Prediction intervals\nA prediction interval gives us a range in which we expect \\(y_t\\) to lie with a specified probability. For example, if we assume that the distribution of future observations follows a normal distribution, a 95% prediction interval for the forecast of step h would be represented by the range\n\\[\\hat{y}_{T+h|T} \\pm 1.96 \\hat\\sigma_h,\\]\nWhere \\(\\hat\\sigma_h\\) is an estimate of the standard deviation of the h -step forecast distribution.\nMore generally, a prediction interval can be written as\n\\[\\hat{y}_{T+h|T} \\pm c \\hat\\sigma_h\\]\nIn this context, the term “multiplier c” is associated with the probability of coverage. In this article, intervals of 80% and 95% are typically calculated, but any other percentage can be used. The table below shows the values of c corresponding to different coverage probabilities, assuming a normal forecast distribution.\n\n\n\nPercentage\nMultiplier\n\n\n\n\n50\n0.67\n\n\n55\n0.76\n\n\n60\n0.84\n\n\n65\n0.93\n\n\n70\n1.04\n\n\n75\n1.15\n\n\n80\n1.28\n\n\n85\n1.44\n\n\n90\n1.64\n\n\n95\n1.96\n\n\n96\n2.05\n\n\n97\n2.17\n\n\n98\n2.33\n\n\n99\n2.58\n\n\n\nPrediction intervals are valuable because they reflect the uncertainty in the predictions. If we only generate point forecasts, we cannot assess how accurate those forecasts are. However, by providing prediction intervals, the amount of uncertainty associated with each forecast becomes apparent. For this reason, point forecasts may lack significant value without the inclusion of corresponding forecast intervals."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#one-step-prediction-intervals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#one-step-prediction-intervals",
    "title": "Prediction intervals",
    "section": "One-step prediction intervals",
    "text": "One-step prediction intervals\nWhen making a prediction for a future step, it is possible to estimate the standard deviation of the forecast distribution using the standard deviation of the residuals, which is calculated by\n\\[\\begin{equation}\n  \\hat{\\sigma} = \\sqrt{\\frac{1}{T-K-M}\\sum_{t=1}^T e_t^2}, \\tag{1}\n\\end{equation}\\]\nwhere \\(K\\) is the number of parameters estimated in the forecasting method, and \\(M\\) is the number of missing values in the residuals. (For example, \\(M=1\\) for a naive forecast, because we can’t forecast the first observation.)"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#multi-step-prediction-intervals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#multi-step-prediction-intervals",
    "title": "Prediction intervals",
    "section": "Multi-step prediction intervals",
    "text": "Multi-step prediction intervals\nA typical feature of forecast intervals is that they tend to increase in length as the forecast horizon lengthens. As we move further out in time, there is greater uncertainty associated with the prediction, resulting in wider prediction intervals. In general, σh tends to increase as h increases (although there are some nonlinear forecasting methods that do not follow this property).\nTo generate a prediction interval, it is necessary to have an estimate of σh. As mentioned above, for one-step forecasts (h=1), equation (1) provides a good estimate of the standard deviation of the forecast, σ1. However, for multi-step forecasts, a more complex calculation method is required. These calculations assume that the residuals are uncorrelated with each other."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#benchmark-methods",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#benchmark-methods",
    "title": "Prediction intervals",
    "section": "Benchmark methods",
    "text": "Benchmark methods\nFor the four benchmark methods, it is possible to mathematically derive the forecast standard deviation under the assumption of uncorrelated residuals. If \\(\\hat{\\sigma}_h\\) denotes the standard deviation of the \\(h\\) -step forecast distribution, and \\(\\hat{\\sigma}\\) is the residual standard deviation given by (1), then we can use the expressions shown in next Table. Note that when \\(h=1\\) and \\(T\\) is large, these all give the same approximate value \\(\\hat{\\sigma}\\).\n\n\n\nMethod\nh-step forecast standard deviation\n\n\n\n\nMean forecasts\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{1 + 1/T}\\)\n\n\nNaïve forecasts\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{h}\\)\n\n\nSeasonal naïve forecasts\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{k+1}\\)\n\n\nDrift forecasts\n\\(\\hat\\sigma_h = \\hat\\sigma\\sqrt{h(1+h/T)}\\)\n\n\n\nNote that when \\(h=1\\) and \\(T\\) is large, these all give the same approximate value \\(\\hat{\\sigma}\\)."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#prediction-intervals-from-bootstrapped-residuals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#prediction-intervals-from-bootstrapped-residuals",
    "title": "Prediction intervals",
    "section": "Prediction intervals from bootstrapped residuals",
    "text": "Prediction intervals from bootstrapped residuals\nWhen a normal distribution for the residuals is an unreasonable assumption, one alternative is to use bootstrapping, which only assumes that the residuals are uncorrelated with constant variance. We will illustrate the procedure using a naïve forecasting method.\nA one-step forecast error is defined as \\(e_t = y_t - \\hat{y}_{t|t-1}\\). For a naïve forecasting method, \\(\\hat{y}_{t|t-1} = y_{t-1}\\), so we can rewrite this as \\[y_t = y_{t-1} + e_t.\\]\nAssuming future errors will be similar to past errors, when \\(t&gt;T\\) we can replace \\(e_{t}\\) by sampling from the collection of errors we have seen in the past (i.e., the residuals). So we can simulate the next observation of a time series using\n\\[y^*_{T+1} = y_{T} + e^*_{T+1}\\]\nwhere \\(e^*_{T+1}\\) is a randomly sampled error from the past, and \\(y^*_{T+1}\\) is the possible future value that would arise if that particular error value occurred. We use We use a * to indicate that this is not the observed \\(y_{T+1}\\) value, but one possible future that could occur. Adding the new simulated observation to our data set, we can repeat the process to obtain\n\\[y^*_{T+2} = y_{T+1}^* + e^*_{T+2},\\]\nwhere \\(e^*_{T+2}\\) is another draw from the collection of residuals. Continuing in this way, we can simulate an entire set of future values for our time series."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#conformal-prediction",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#conformal-prediction",
    "title": "Prediction intervals",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nMulti-quantile losses and statistical models can provide provide prediction intervals, but the problem is that these are uncalibrated, meaning that the actual frequency of observations falling within the interval does not align with the confidence level associated with it. For example, a calibrated 95% prediction interval should contain the true value 95% of the time in repeated sampling. An uncalibrated 95% prediction interval, on the other hand, might contain the true value only 80% of the time, or perhaps 99% of the time. In the first case, the interval is too narrow and underestimates the uncertainty, while in the second case, it is too wide and overestimates the uncertainty.\nStatistical methods also assume normality. Here, we talk about another method called conformal prediction that doesn’t require any distributional assumptions.\nConformal prediction intervals use cross-validation on a point forecaster model to generate the intervals. This means that no prior probabilities are needed, and the output is well-calibrated. No additional training is needed, and the model is treated as a black box. The approach is compatible with any model\nmlforecast now supports Conformal Prediction on all available models."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#read-data",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#read-data",
    "title": "Prediction intervals",
    "section": "Read Data",
    "text": "Read Data\n\ndata_url = \"https://raw.githubusercontent.com/Naren8520/Serie-de-tiempo-con-Machine-Learning/main/Data/nyc_taxi.csv\"\ndf = pd.read_csv(data_url, parse_dates=[\"timestamp\"])\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n2014-07-01 00:00:00\n10844\n\n\n1\n2014-07-01 00:30:00\n8127\n\n\n2\n2014-07-01 01:00:00\n6210\n\n\n3\n2014-07-01 01:30:00\n4656\n\n\n4\n2014-07-01 02:00:00\n3820\n\n\n\n\n\n\n\nThe input to MlForecast is always a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int or category) represents an identifier for the series.\nThe ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\nThe y (numeric) represents the measurement we wish to forecast.\n\n\ndf[\"unique_id\"] = \"1\"\ndf.columns=[\"ds\", \"y\", \"unique_id\"]\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\nunique_id\n\n\n\n\n0\n2014-07-01 00:00:00\n10844\n1\n\n\n1\n2014-07-01 00:30:00\n8127\n1\n\n\n2\n2014-07-01 01:00:00\n6210\n1\n\n\n3\n2014-07-01 01:30:00\n4656\n1\n\n\n4\n2014-07-01 02:00:00\n3820\n1\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10320 entries, 0 to 10319\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   ds         10320 non-null  datetime64[ns]\n 1   y          10320 non-null  int64         \n 2   unique_id  10320 non-null  object        \ndtypes: datetime64[ns](1), int64(1), object(1)\nmemory usage: 242.0+ KB"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#the-augmented-dickey-fuller-test",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#the-augmented-dickey-fuller-test",
    "title": "Prediction intervals",
    "section": "The Augmented Dickey-Fuller Test",
    "text": "The Augmented Dickey-Fuller Test\nAn Augmented Dickey-Fuller (ADF) test is a type of statistical test that determines whether a unit root is present in time series data. Unit roots can cause unpredictable results in time series analysis. A null hypothesis is formed in the unit root test to determine how strongly time series data is affected by a trend. By accepting the null hypothesis, we accept the evidence that the time series data is not stationary. By rejecting the null hypothesis or accepting the alternative hypothesis, we accept the evidence that the time series data is generated by a stationary process. This process is also known as stationary trend. The values of the ADF test statistic are negative. Lower ADF values indicate a stronger rejection of the null hypothesis.\nAugmented Dickey-Fuller Test is a common statistical test used to test whether a given time series is stationary or not. We can achieve this by defining the null and alternate hypothesis.\n\nNull Hypothesis: Time Series is non-stationary. It gives a time-dependent trend.\nAlternate Hypothesis: Time Series is stationary. In another term, the series doesn’t depend on time.\nADF or t Statistic &lt; critical values: Reject the null hypothesis, time series is stationary.\nADF or t Statistic &gt; critical values: Failed to reject the null hypothesis, time series is non-stationary.\n\n\ndef augmented_dickey_fuller_test(series , column_name):\n    print (f'Dickey-Fuller test results for columns: {column_name}')\n    dftest = adfuller(series, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','No Lags Used','Number of observations used'])\n    for key,value in dftest[4].items():\n       dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n    if dftest[1] &lt;= 0.05:\n        print(\"Conclusion:====&gt;\")\n        print(\"Reject the null hypothesis\")\n        print(\"The data is stationary\")\n    else:\n        print(\"Conclusion:====&gt;\")\n        print(\"The null hypothesis cannot be rejected\")\n        print(\"The data is not stationary\")\n\n\naugmented_dickey_fuller_test(df[\"y\"],'Ads')\n\nDickey-Fuller test results for columns: Ads\nTest Statistic                -1.076452e+01\np-value                        2.472132e-19\nNo Lags Used                   3.900000e+01\nNumber of observations used    1.028000e+04\nCritical Value (1%)           -3.430986e+00\nCritical Value (5%)           -2.861821e+00\nCritical Value (10%)          -2.566920e+00\ndtype: float64\nConclusion:====&gt;\nReject the null hypothesis\nThe data is stationary"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#autocorrelation-plots",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#autocorrelation-plots",
    "title": "Prediction intervals",
    "section": "Autocorrelation plots",
    "text": "Autocorrelation plots\n\nAutocorrelation Function\nDefinition 1. Let \\(\\{x_t;1 ≤ t ≤ n\\}\\) be a time series sample of size n from \\(\\{X_t\\}\\). 1. \\(\\bar x = \\sum_{t=1}^n \\frac{x_t}{n}\\) is called the sample mean of \\(\\{X_t\\}\\). 2. \\(c_k =\\sum_{t=1}^{n−k} (x_{t+k}- \\bar x)(x_t−\\bar x)/n\\) is known as the sample autocovariance function of \\(\\{X_t\\}\\). 3. \\(r_k = c_k /c_0\\) is said to be the sample autocorrelation function of \\(\\{X_t\\}\\).\nNote the following remarks about this definition:\n\nLike most literature, this guide uses ACF to denote the sample autocorrelation function as well as the autocorrelation function. What is denoted by ACF can easily be identified in context.\nClearly c0 is the sample variance of \\(\\{X_t\\}\\). Besides, \\(r_0 = c_0/c_0 = 1\\) and for any integer \\(k, |r_k| ≤ 1\\).\nWhen we compute the ACF of any sample series with a fixed length \\(n\\), we cannot put too much confidence in the values of \\(r_k\\) for large k’s, since fewer pairs of \\((x_{t +k }, x_t )\\) are available for calculating \\(r_k\\) as \\(k\\) is large. One rule of thumb is not to estimate \\(r_k\\) for \\(k &gt; n/3\\), and another is \\(n ≥ 50, k ≤ n/4\\). In any case, it is always a good idea to be careful.\nWe also compute the ACF of a nonstationary time series sample by Definition 1. In this case, however, the ACF or \\(r_k\\) very slowly or hardly tapers off as \\(k\\) increases.\nPlotting the ACF \\((r_k)\\) against lag \\(k\\) is easy but very helpful in analyzing time series sample. Such an ACF plot is known as a correlogram.\nIf \\(\\{X_t\\}\\) is stationary with \\(E(X_t)=0\\) and \\(\\rho_k =0\\) for all \\(k \\neq 0\\),thatis,itisa white noise series, then the sampling distribution of \\(r_k\\) is asymptotically normal with the mean 0 and the variance of \\(1/n\\). Hence, there is about 95% chance that \\(r_k\\) falls in the interval \\([−1.96/√n, 1.96/√n]\\).\n\nNow we can give a summary that (1) if the time series plot of a time series clearly shows a trend or/and seasonality, it is surely nonstationary; (2) if the ACF \\(r_k\\) very slowly or hardly tapers off as lag \\(k\\) increases, the time series should also be nonstationary.\n\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\nplot_acf(df[\"y\"],  lags=30, ax=axs[0],color=\"fuchsia\")\naxs[0].set_title(\"Autocorrelation\");\n\n# Grafico\nplot_pacf(df[\"y\"],  lags=30, ax=axs[1],color=\"lime\")\naxs[1].set_title('Partial Autocorrelation')\nplt.savefig(\"../../figs/prediction_intervals_in_forecasting_models__autocorrelation.png\", bbox_inches='tight')\nplt.close();"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#decomposition-of-the-time-series",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#decomposition-of-the-time-series",
    "title": "Prediction intervals",
    "section": "Decomposition of the time series",
    "text": "Decomposition of the time series\nHow to decompose a time series and why?\nIn time series analysis to forecast new values, it is very important to know past data. More formally, we can say that it is very important to know the patterns that values follow over time. There can be many reasons that cause our forecast values to fall in the wrong direction. Basically, a time series consists of four components. The variation of those components causes the change in the pattern of the time series. These components are:\n\nLevel: This is the primary value that averages over time.\nTrend: The trend is the value that causes increasing or decreasing patterns in a time series.\nSeasonality: This is a cyclical event that occurs in a time series for a short time and causes short-term increasing or decreasing patterns in a time series.\nResidual/Noise: These are the random variations in the time series.\n\nCombining these components over time leads to the formation of a time series. Most time series consist of level and noise/residual and trend or seasonality are optional values.\nIf seasonality and trend are part of the time series, then there will be effects on the forecast value. As the pattern of the forecasted time series may be different from the previous time series.\nThe combination of the components in time series can be of two types: * Additive * multiplicative\nAdditive time series\nIf the components of the time series are added to make the time series. Then the time series is called the additive time series. By visualization, we can say that the time series is additive if the increasing or decreasing pattern of the time series is similar throughout the series. The mathematical function of any additive time series can be represented by: \\[y(t) = level + Trend + seasonality + noise\\]"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#multiplicative-time-series",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#multiplicative-time-series",
    "title": "Prediction intervals",
    "section": "Multiplicative time series",
    "text": "Multiplicative time series\nIf the components of the time series are multiplicative together, then the time series is called a multiplicative time series. For visualization, if the time series is having exponential growth or decline with time, then the time series can be considered as the multiplicative time series. The mathematical function of the multiplicative time series can be represented as.\n\\[y(t) = Level * Trend * seasonality * Noise\\]\n\nAdditive\n\na = seasonal_decompose(df[\"y\"], model = \"additive\", period=24).plot()\na.savefig('../../figs/prediction_intervals_in_forecasting_models__seasonal_decompose_aditive.png', bbox_inches='tight')\nplt.close()\n\n\n\n\nMultiplicative\n\nb = seasonal_decompose(df[\"y\"], model = \"Multiplicative\", period=24).plot()\nb.savefig('../../figs/prediction_intervals_in_forecasting_models__seasonal_decompose_multiplicative.png', bbox_inches='tight')\nplt.close();"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#building-model",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#building-model",
    "title": "Prediction intervals",
    "section": "Building Model",
    "text": "Building Model\nWe define the model that we want to use, for our example we are going to use the XGBoost model.\n\nmodel1 = [xgb.XGBRegressor()]\n\nWe can use the MLForecast.preprocess method to explore different transformations.\nIf it is true that the series we are working with is a stationary series see (Dickey fuller test), however for the sake of practice and instruction in this guide, we will apply the difference to our series, we will do this using the target_transforms parameter and calling the diff function like: mlforecast.target_transforms.Differences\n\nmlf = MLForecast(models=model1,\n                 freq='30min', \n                 target_transforms=[Differences([1])],\n                 )\n\nIt is important to take into account when we use the parameter target_transforms=[Differences([1])] in case the series is stationary we can use a difference, or in the case that the series is not stationary, we can use more than one difference so that the series is constant over time, that is, that it is constant in mean and in variance.\n\nprep = mlf.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nds\ny\nunique_id\n\n\n\n\n1\n2014-07-01 00:30:00\n-2717.0\n1\n\n\n2\n2014-07-01 01:00:00\n-1917.0\n1\n\n\n3\n2014-07-01 01:30:00\n-1554.0\n1\n\n\n4\n2014-07-01 02:00:00\n-836.0\n1\n\n\n5\n2014-07-01 02:30:00\n-947.0\n1\n\n\n...\n...\n...\n...\n\n\n10315\n2015-01-31 21:30:00\n951.0\n1\n\n\n10316\n2015-01-31 22:00:00\n1051.0\n1\n\n\n10317\n2015-01-31 22:30:00\n1588.0\n1\n\n\n10318\n2015-01-31 23:00:00\n-718.0\n1\n\n\n10319\n2015-01-31 23:30:00\n-303.0\n1\n\n\n\n\n10319 rows × 3 columns\n\n\n\nThis has subtacted the lag 1 from each value, we can see what our series look like now.\n\nfig = plot_series(prep)"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#adding-features",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#adding-features",
    "title": "Prediction intervals",
    "section": "Adding features",
    "text": "Adding features\n\nLags\nLooks like the seasonality is gone, we can now try adding some lag features.\n\nmlf = MLForecast(models=model1,\n                 freq='30min',  \n                 lags=[1,24],\n                 target_transforms=[Differences([1])],\n                 )\n\n\nprep = mlf.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nds\ny\nunique_id\nlag1\nlag24\n\n\n\n\n25\n2014-07-01 12:30:00\n-22.0\n1\n445.0\n-2717.0\n\n\n26\n2014-07-01 13:00:00\n-708.0\n1\n-22.0\n-1917.0\n\n\n27\n2014-07-01 13:30:00\n1281.0\n1\n-708.0\n-1554.0\n\n\n28\n2014-07-01 14:00:00\n87.0\n1\n1281.0\n-836.0\n\n\n29\n2014-07-01 14:30:00\n1045.0\n1\n87.0\n-947.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n10315\n2015-01-31 21:30:00\n951.0\n1\n428.0\n4642.0\n\n\n10316\n2015-01-31 22:00:00\n1051.0\n1\n951.0\n-519.0\n\n\n10317\n2015-01-31 22:30:00\n1588.0\n1\n1051.0\n2411.0\n\n\n10318\n2015-01-31 23:00:00\n-718.0\n1\n1588.0\n214.0\n\n\n10319\n2015-01-31 23:30:00\n-303.0\n1\n-718.0\n2595.0\n\n\n\n\n10295 rows × 5 columns\n\n\n\n\nprep.drop(columns=['unique_id', 'ds']).corr()['y']\n\ny        1.000000\nlag1     0.663082\nlag24    0.155366\nName: y, dtype: float64"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#lag-transforms",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#lag-transforms",
    "title": "Prediction intervals",
    "section": "Lag transforms",
    "text": "Lag transforms\nLag transforms are defined as a dictionary where the keys are the lags and the values are lists of functions that transform an array. These must be numba jitted functions (so that computing the features doesn’t become a bottleneck). There are some implemented in the window-ops package but you can also implement your own.\nIf the function takes two or more arguments you can either:\n\nsupply a tuple (tfm_func, arg1, arg2, …)\ndefine a new function fixing the arguments\n\n\nfrom numba import njit\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\n\n\nmlf = MLForecast(models=model1,\n                 freq='30min',  \n                 lags=[1,24],\n                 lag_transforms={1: [expanding_mean],24: [(rolling_mean, 7)] },\n                 target_transforms=[Differences([1])],\n                 )\n\n\nprep = mlf.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nds\ny\nunique_id\nlag1\nlag24\nexpanding_mean_lag1\nrolling_mean_lag24_window_size7\n\n\n\n\n31\n2014-07-01 15:30:00\n-836.0\n1\n-1211.0\n-305.0\n284.533325\n-1254.285767\n\n\n32\n2014-07-01 16:00:00\n-2316.0\n1\n-836.0\n157.0\n248.387100\n-843.714294\n\n\n33\n2014-07-01 16:30:00\n-1215.0\n1\n-2316.0\n-63.0\n168.250000\n-578.857117\n\n\n34\n2014-07-01 17:00:00\n2190.0\n1\n-1215.0\n357.0\n126.333336\n-305.857147\n\n\n35\n2014-07-01 17:30:00\n2322.0\n1\n2190.0\n1849.0\n187.029419\n77.714287\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n10315\n2015-01-31 21:30:00\n951.0\n1\n428.0\n4642.0\n1.248303\n2064.285645\n\n\n10316\n2015-01-31 22:00:00\n1051.0\n1\n951.0\n-519.0\n1.340378\n1873.428589\n\n\n10317\n2015-01-31 22:30:00\n1588.0\n1\n1051.0\n2411.0\n1.442129\n2179.000000\n\n\n10318\n2015-01-31 23:00:00\n-718.0\n1\n1588.0\n214.0\n1.595910\n1888.714233\n\n\n10319\n2015-01-31 23:30:00\n-303.0\n1\n-718.0\n2595.0\n1.526168\n2071.714355\n\n\n\n\n10289 rows × 7 columns\n\n\n\nYou can see that both approaches get to the same result, you can use whichever one you feel most comfortable with."
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#date-features",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#date-features",
    "title": "Prediction intervals",
    "section": "Date features",
    "text": "Date features\nIf your time column is made of timestamps then it might make sense to extract features like week, dayofweek, quarter, etc. You can do that by passing a list of strings with pandas time/date components. You can also pass functions that will take the time column as input, as we’ll show here.\n\nmlf = MLForecast(models=model1,\n                 freq='30min', \n                 lags=[1,24],\n                 lag_transforms={1: [expanding_mean],24: [(rolling_mean, 7)] },\n                 target_transforms=[Differences([1])],\n                 date_features=[\"year\", \"month\", \"day\", \"hour\"]) # Seasonal data\n\n\nprep = mlf.preprocess(df)\nprep\n\n\n\n\n\n\n\n\nds\ny\nunique_id\nlag1\nlag24\nexpanding_mean_lag1\nrolling_mean_lag24_window_size7\nyear\nmonth\nday\nhour\n\n\n\n\n31\n2014-07-01 15:30:00\n-836.0\n1\n-1211.0\n-305.0\n284.533325\n-1254.285767\n2014\n7\n1\n15\n\n\n32\n2014-07-01 16:00:00\n-2316.0\n1\n-836.0\n157.0\n248.387100\n-843.714294\n2014\n7\n1\n16\n\n\n33\n2014-07-01 16:30:00\n-1215.0\n1\n-2316.0\n-63.0\n168.250000\n-578.857117\n2014\n7\n1\n16\n\n\n34\n2014-07-01 17:00:00\n2190.0\n1\n-1215.0\n357.0\n126.333336\n-305.857147\n2014\n7\n1\n17\n\n\n35\n2014-07-01 17:30:00\n2322.0\n1\n2190.0\n1849.0\n187.029419\n77.714287\n2014\n7\n1\n17\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n10315\n2015-01-31 21:30:00\n951.0\n1\n428.0\n4642.0\n1.248303\n2064.285645\n2015\n1\n31\n21\n\n\n10316\n2015-01-31 22:00:00\n1051.0\n1\n951.0\n-519.0\n1.340378\n1873.428589\n2015\n1\n31\n22\n\n\n10317\n2015-01-31 22:30:00\n1588.0\n1\n1051.0\n2411.0\n1.442129\n2179.000000\n2015\n1\n31\n22\n\n\n10318\n2015-01-31 23:00:00\n-718.0\n1\n1588.0\n214.0\n1.595910\n1888.714233\n2015\n1\n31\n23\n\n\n10319\n2015-01-31 23:30:00\n-303.0\n1\n-718.0\n2595.0\n1.526168\n2071.714355\n2015\n1\n31\n23\n\n\n\n\n10289 rows × 11 columns"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#fit-the-model",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#fit-the-model",
    "title": "Prediction intervals",
    "section": "Fit the Model",
    "text": "Fit the Model\n\n# fit the models\nmlf.fit(df,  \n fitted=True, \nprediction_intervals=PredictionIntervals(n_windows=5, h=30, method=\"conformal_distribution\" )  )\n\nMLForecast(models=[XGBRegressor], freq=&lt;30 * Minutes&gt;, lag_features=['lag1', 'lag24', 'expanding_mean_lag1', 'rolling_mean_lag24_window_size7'], date_features=['year', 'month', 'day', 'hour'], num_threads=1)\n\n\nLet’s see the results of our model in this case the XGBoost model. We can observe it with the following instruction:\nLet us now visualize the fitted values of our models.\n\nresult=mlf.forecast_fitted_values()\nresult=result.set_index(\"unique_id\")\nresult\n\n\n\n\n\n\n\n\nds\ny\nXGBRegressor\n\n\nunique_id\n\n\n\n\n\n\n\n1\n2014-07-01 15:30:00\n18544.0\n18243.291016\n\n\n1\n2014-07-01 16:00:00\n16228.0\n16489.828125\n\n\n1\n2014-07-01 16:30:00\n15013.0\n15105.728516\n\n\n1\n2014-07-01 17:00:00\n17203.0\n17362.349609\n\n\n1\n2014-07-01 17:30:00\n19525.0\n19678.052734\n\n\n...\n...\n...\n...\n\n\n1\n2015-01-31 21:30:00\n24670.0\n24801.906250\n\n\n1\n2015-01-31 22:00:00\n25721.0\n25812.089844\n\n\n1\n2015-01-31 22:30:00\n27309.0\n27192.630859\n\n\n1\n2015-01-31 23:00:00\n26591.0\n27066.931641\n\n\n1\n2015-01-31 23:30:00\n26288.0\n25945.341797\n\n\n\n\n10289 rows × 3 columns\n\n\n\n\nfrom statsmodels.stats.diagnostic import normal_ad\nfrom scipy import stats\n\n\nsw_result = stats.shapiro(result[\"XGBRegressor\"])\nad_result = normal_ad(np.array(result[\"XGBRegressor\"]), axis=0)\ndag_result = stats.normaltest(result[\"XGBRegressor\"], axis=0, nan_policy='propagate')\n\nIt’s important to note that we can only use this method if we assume that the residuals of our validation predictions are normally distributed. To see if this is the case, we will use a PP-plot and test its normality with the Anderson-Darling, Kolmogorov-Smirnov, and D’Agostino K^2 tests.\nThe PP-plot(Probability-to-Probability) plots the data sample against the normal distribution plot in such a way that if normally distributed, the data points will form a straight line.\nThe three normality tests determine how likely a data sample is from a normally distributed population using p-values. The null hypothesis for each test is that “the sample came from a normally distributed population”. This means that if the resulting p-values are below a chosen alpha value, then the null hypothesis is rejected. Thus there is evidence to suggest that the data comes from a non-normal distribution. For this article, we will use an Alpha value of 0.01.\n\nresult=mlf.forecast_fitted_values()\nfig, axs = plt.subplots(nrows=2, ncols=2)\n\n# plot[1,1]\nresult[\"XGBRegressor\"].plot(ax=axs[0,0])\naxs[0,0].set_title(\"Residuals model\");\n\n# plot\naxs[0,1].hist(result[\"XGBRegressor\"], density=True,bins=50, alpha=0.5 )\naxs[0,1].set_title(\"Density plot - Residual\");\n\n# plot\nstats.probplot(result[\"XGBRegressor\"], dist=\"norm\", plot=axs[1,0])\naxs[1,0].set_title('Plot Q-Q')\naxs[1,0].annotate(\"SW p-val: {:.4f}\".format(sw_result[1]), xy=(0.05,0.9), xycoords='axes fraction', fontsize=15,\n            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n\naxs[1,0].annotate(\"AD p-val: {:.4f}\".format(ad_result[1]), xy=(0.05,0.8), xycoords='axes fraction', fontsize=15,\n            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n\naxs[1,0].annotate(\"DAG p-val: {:.4f}\".format(dag_result[1]), xy=(0.05,0.7), xycoords='axes fraction', fontsize=15,\n            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n# plot\nplot_acf(result[\"XGBRegressor\"],  lags=35, ax=axs[1,1],color=\"fuchsia\")\naxs[1,1].set_title(\"Autocorrelation\");\n\nplt.savefig(\"../../figs/prediction_intervals_in_forecasting_models__plot_residual_model.png\", bbox_inches='tight')\nplt.close();"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#predict-method-with-prediction-intervals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#predict-method-with-prediction-intervals",
    "title": "Prediction intervals",
    "section": "Predict method with prediction intervals",
    "text": "Predict method with prediction intervals\nTo generate forecasts use the predict method.\n\nforecast_df = mlf.predict(h=30, level=[80,95])\nforecast_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nXGBRegressor\nXGBRegressor-lo-95\nXGBRegressor-lo-80\nXGBRegressor-hi-80\nXGBRegressor-hi-95\n\n\n\n\n0\n1\n2015-02-01 00:00:00\n24608.865234\n24016.475873\n24085.588062\n25132.142407\n25201.254596\n\n\n1\n1\n2015-02-01 00:30:00\n23323.097656\n20511.105615\n21901.008398\n24745.186914\n26135.089697\n\n\n2\n1\n2015-02-01 01:00:00\n22223.435547\n20161.902002\n20995.971289\n23450.899805\n24284.969092\n\n\n3\n1\n2015-02-01 01:30:00\n20405.228516\n17227.147949\n17822.294922\n22988.162109\n23583.309082\n\n\n4\n1\n2015-02-01 02:00:00\n20014.324219\n17422.155518\n17923.692383\n22104.956055\n22606.492920"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals_in_forecasting_models.html#plot-prediction-intervals",
    "href": "docs/tutorials/prediction_intervals_in_forecasting_models.html#plot-prediction-intervals",
    "title": "Prediction intervals",
    "section": "Plot prediction intervals",
    "text": "Plot prediction intervals\nNow let’s visualize the result of our forecast and the historical data of our time series, also let’s draw the confidence interval that we have obtained when making the prediction with 95% confidence.\n\nfig = plot_series(df, forecast_df, level=[80,95], max_insample_length=200,engine=\"matplotlib\")\nfig.get_axes()[0].set_title(\"Prediction intervals\")\nfig.savefig('../../figs/prediction_intervals_in_forecasting_models__plot_forecasting_intervals.png', bbox_inches='tight')\n\n\nThe confidence interval is a range of values that has a high probability of containing the true value of a variable. In machine learning time series models, the confidence interval is used to estimate the uncertainty in the predictions.\nOne of the main benefits of using the confidence interval is that it allows users to understand the accuracy of the predictions. For example, if the confidence interval is very wide, it means that the prediction is less accurate. Conversely, if the confidence interval is very narrow, it means that the prediction is more accurate.\nAnother benefit of the confidence interval is that it helps users make informed decisions. For example, if a prediction is within the confidence interval, it means that it is likely to come true. Conversely, if a prediction is outside the confidence interval, it means that it is less likely to come true.\nIn general, the confidence interval is an important tool for machine learning time series models. It helps users understand the accuracy of the forecasts and make informed decisions."
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html",
    "href": "docs/tutorials/electricity_peak_forecasting.html",
    "title": "Detect Demand Peaks",
    "section": "",
    "text": "Predicting peaks in different markets is useful. In the electricity market, consuming electricity at peak demand is penalized with higher tarifs. When an individual or company consumes electricity when its most demanded, regulators calls that a coincident peak (CP).\nIn the Texas electricity market (ERCOT), the peak is the monthly 15-minute interval when the ERCOT Grid is at a point of highest capacity. The peak is caused by all consumers’ combined demand on the electrical grid. The coincident peak demand is an important factor used by ERCOT to determine final electricity consumption bills. ERCOT registers the CP demand of each client for 4 months, between June and September, and uses this to adjust electricity prices. Clients can therefore save on electricity bills by reducing the coincident peak demand.\nIn this example we will train a LightGBM model on historic load data to forecast day-ahead peaks on September 2022. Multiple seasonality is traditionally present in low sampled electricity data. Demand exhibits daily and weekly seasonality, with clear patterns for specific hours of the day such as 6:00pm vs 3:00am or for specific days such as Sunday vs Friday.\nFirst, we will load ERCOT historic demand, then we will use the MLForecast.cross_validation method to fit the LightGBM model and forecast daily load during September. Finally, we show how to use the forecasts to detect the coincident peak.\nOutline\n\nInstall libraries\nLoad and explore the data\nFit LightGBM model and forecast\nPeak detection\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#introduction",
    "href": "docs/tutorials/electricity_peak_forecasting.html#introduction",
    "title": "Detect Demand Peaks",
    "section": "",
    "text": "Predicting peaks in different markets is useful. In the electricity market, consuming electricity at peak demand is penalized with higher tarifs. When an individual or company consumes electricity when its most demanded, regulators calls that a coincident peak (CP).\nIn the Texas electricity market (ERCOT), the peak is the monthly 15-minute interval when the ERCOT Grid is at a point of highest capacity. The peak is caused by all consumers’ combined demand on the electrical grid. The coincident peak demand is an important factor used by ERCOT to determine final electricity consumption bills. ERCOT registers the CP demand of each client for 4 months, between June and September, and uses this to adjust electricity prices. Clients can therefore save on electricity bills by reducing the coincident peak demand.\nIn this example we will train a LightGBM model on historic load data to forecast day-ahead peaks on September 2022. Multiple seasonality is traditionally present in low sampled electricity data. Demand exhibits daily and weekly seasonality, with clear patterns for specific hours of the day such as 6:00pm vs 3:00am or for specific days such as Sunday vs Friday.\nFirst, we will load ERCOT historic demand, then we will use the MLForecast.cross_validation method to fit the LightGBM model and forecast daily load during September. Finally, we show how to use the forecasts to detect the coincident peak.\nOutline\n\nInstall libraries\nLoad and explore the data\nFit LightGBM model and forecast\nPeak detection\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively"
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#libraries",
    "href": "docs/tutorials/electricity_peak_forecasting.html#libraries",
    "title": "Detect Demand Peaks",
    "section": "Libraries",
    "text": "Libraries\nWe assume you have MLForecast already installed. Check this guide for instructions on how to install MLForecast.\nInstall the necessary packages using pip install mlforecast.\nAlso we have to install LightGBM using pip install lightgbm."
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#load-data",
    "href": "docs/tutorials/electricity_peak_forecasting.html#load-data",
    "title": "Detect Demand Peaks",
    "section": "Load Data",
    "text": "Load Data\nThe input to MLForecast is always a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int or category) represents an identifier for the series.\nThe ds (datestamp or int) column should be either an integer indexing time or a datestamp ideally like YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\nThe y (numeric) represents the measurement we wish to forecast. We will rename the\n\nFirst, read the 2022 historic total demand of the ERCOT market. We processed the original data (available here), by adding the missing hour due to daylight saving time, parsing the date to datetime format, and filtering columns of interest.\n\nimport numpy as np\nimport pandas as pd\nfrom utilsforecast.plotting import plot_series\n\n\n# Load data\nY_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/ERCOT-clean.csv', parse_dates=['ds'])\nY_df = Y_df.query(\"ds &gt;= '2022-01-01' & ds &lt;= '2022-10-01'\")\n\n\nfig = plot_series(Y_df)\n\n\nWe observe that the time series exhibits seasonal patterns. Moreover, the time series contains 6,552 observations, so it is necessary to use computationally efficient methods to deploy them in production."
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#fit-and-forecast-lightgbm-model",
    "href": "docs/tutorials/electricity_peak_forecasting.html#fit-and-forecast-lightgbm-model",
    "title": "Detect Demand Peaks",
    "section": "Fit and Forecast LightGBM model",
    "text": "Fit and Forecast LightGBM model\nImport the MLForecast class and the models you need.\n\nimport lightgbm as lgb\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\n\nFirst, instantiate the model and define the parameters.\n\n\n\n\n\n\nTip\n\n\n\nIn this example we are using the default parameters of the lgb.LGBMRegressor model, but you can change them to improve the forecasting performance.\n\n\n\nmodels = [\n    lgb.LGBMRegressor(verbosity=-1) # you can include more models here\n]\n\nWe fit the model by instantiating a MLForecast object with the following required parameters:\n\nmodels: a list of sklearn-like (fit and predict) models.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\ntarget_transforms: Transformations to apply to the target before computing the features. These are restored at the forecasting step.\nlags: Lags of the target to use as features.\n\n\n# Instantiate MLForecast class as mlf\nmlf = MLForecast(\n    models=models,\n    freq='H', \n    target_transforms=[Differences([24])],\n    lags=range(1, 25)\n)\n\n\n\n\n\n\n\nTip\n\n\n\nIn this example, we are only using differences and lags to produce features. See the full documentation to see all available features.\n\n\nThe cross_validation method allows the user to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with fit and predict methods. This method re-trains the model and forecast each window. See this tutorial for an animation of how the windows are defined.\nUse the cross_validation method to produce all the daily forecasts for September. To produce daily forecasts set the forecasting horizon window_size as 24. In this example we are simulating deploying the pipeline during September, so set the number of windows as 30 (one for each day). Finally, the step size between windows is 24 (equal to the window_size). This ensure to only produce one forecast per day.\nAdditionally,\n\nid_col: identifies each time series.\ntime_col: indetifies the temporal column of the time series.\ntarget_col: identifies the column to model.\n\n\ncrossvalidation_df = mlf.cross_validation(\n    df=Y_df,\n    h=24,\n    n_windows=30,\n)\n\n\ncrossvalidation_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\n\n\n\n\n0\nERCOT\n2022-09-01 00:00:00\n2022-08-31 23:00:00\n45482.471757\n45685.265537\n\n\n1\nERCOT\n2022-09-01 01:00:00\n2022-08-31 23:00:00\n43602.658043\n43779.819515\n\n\n2\nERCOT\n2022-09-01 02:00:00\n2022-08-31 23:00:00\n42284.817342\n42672.470923\n\n\n3\nERCOT\n2022-09-01 03:00:00\n2022-08-31 23:00:00\n41663.156771\n42091.768192\n\n\n4\nERCOT\n2022-09-01 04:00:00\n2022-08-31 23:00:00\n41710.621904\n42481.403168\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using cross_validation make sure the forecasts are produced at the desired timestamps. Check the cutoff column which specifices the last timestamp before the forecasting window."
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#peak-detection",
    "href": "docs/tutorials/electricity_peak_forecasting.html#peak-detection",
    "title": "Detect Demand Peaks",
    "section": "Peak Detection",
    "text": "Peak Detection\nFinally, we use the forecasts in crossvaldation_df to detect the daily hourly demand peaks. For each day, we set the detected peaks as the highest forecasts. In this case, we want to predict one peak (npeaks); depending on your setting and goals, this parameter might change. For example, the number of peaks can correspond to how many hours a battery can be discharged to reduce demand.\n\nnpeaks = 1 # Number of peaks\n\nFor the ERCOT 4CP detection task we are interested in correctly predicting the highest monthly load. Next, we filter the day in September with the highest hourly demand and predict the peak.\n\ncrossvalidation_df = crossvalidation_df.reset_index()[['ds','y','LGBMRegressor']]\nmax_day = crossvalidation_df.iloc[crossvalidation_df['y'].argmax()].ds.day # Day with maximum load\ncv_df_day = crossvalidation_df.query('ds.dt.day == @max_day')\nmax_hour = cv_df_day['y'].argmax()\npeaks = cv_df_day['LGBMRegressor'].argsort().iloc[-npeaks:].values # Predicted peaks\n\nIn the following plot we see how the LightGBM model is able to correctly detect the coincident peak for September 2022.\n\nimport matplotlib.pyplot as plt\n\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.axvline(cv_df_day.iloc[max_hour]['ds'], color='black', label='True Peak')\nax.scatter(cv_df_day.iloc[peaks]['ds'], cv_df_day.iloc[peaks]['LGBMRegressor'], color='green', label=f'Predicted Top-{npeaks}')\nax.plot(cv_df_day['ds'], cv_df_day['y'], label='y', color='blue')\nax.plot(cv_df_day['ds'], cv_df_day['LGBMRegressor'], label='Forecast', color='red')\nax.set(xlabel='Time', ylabel='Load (MW)')\nax.grid()\nax.legend()\nfig.savefig('../../figs/electricity_peak_forecasting__predicted_peak.png', bbox_inches='tight')\nplt.close()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this example we only include September. However, MLForecast and LightGBM can correctly predict the peaks for the 4 months of 2022. You can try this by increasing the n_windows parameter of cross_validation or filtering the Y_df dataset."
  },
  {
    "objectID": "docs/tutorials/electricity_peak_forecasting.html#next-steps",
    "href": "docs/tutorials/electricity_peak_forecasting.html#next-steps",
    "title": "Detect Demand Peaks",
    "section": "Next steps",
    "text": "Next steps\nMLForecast and LightGBM in particular are good benchmarking models for peak detection. However, it might be useful to explore further and newer forecasting algorithms or perform hyperparameter optimization."
  },
  {
    "objectID": "docs/how-to-guides/exogenous_features.html",
    "href": "docs/how-to-guides/exogenous_features.html",
    "title": "Exogenous features",
    "section": "",
    "text": "import lightgbm as lgb\nimport pandas as pd\nfrom mlforecast import MLForecast\nfrom mlforecast.utils import generate_daily_series, generate_prices_for_series\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.rolling import rolling_mean\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/exogenous_features.html#data-setup",
    "href": "docs/how-to-guides/exogenous_features.html#data-setup",
    "title": "Exogenous features",
    "section": "Data setup",
    "text": "Data setup\n\nseries = generate_daily_series(\n    100, equal_ends=True, n_static_features=2\n).rename(columns={'static_1': 'product_id'})\nseries.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nproduct_id\n\n\n\n\n0\nid_00\n2000-10-05\n39.811983\n79\n45\n\n\n1\nid_00\n2000-10-06\n103.274013\n79\n45\n\n\n2\nid_00\n2000-10-07\n176.574744\n79\n45\n\n\n3\nid_00\n2000-10-08\n258.987900\n79\n45\n\n\n4\nid_00\n2000-10-09\n344.940404\n79\n45\n\n\n\n\n\n\n\nIn mlforecast the required columns are the series identifier, time and target. Any extra columns you have, like static_0 and product_id here are considered to be static and are replicated when constructing the features for the next timestamp. You can disable this by passing static_features to MLForecast.preprocess or MLForecast.fit, which will only keep the columns you define there as static. Keep in mind that all features in your input dataframe will be used for training, so you’ll have to provide the future values of exogenous features to MLForecast.predict through the X_df argument.\nConsider the following example. Suppose that we have a prices catalog for each id and date.\n\nprices_catalog = generate_prices_for_series(series)\nprices_catalog.head()\n\n\n\n\n\n\n\n\nds\nunique_id\nprice\n\n\n\n\n0\n2000-10-05\nid_00\n0.548814\n\n\n1\n2000-10-06\nid_00\n0.715189\n\n\n2\n2000-10-07\nid_00\n0.602763\n\n\n3\n2000-10-08\nid_00\n0.544883\n\n\n4\n2000-10-09\nid_00\n0.423655\n\n\n\n\n\n\n\nAnd that you have already merged these prices into your series dataframe.\n\nseries_with_prices = series.merge(prices_catalog, how='left')\nseries_with_prices.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nproduct_id\nprice\n\n\n\n\n0\nid_00\n2000-10-05\n39.811983\n79\n45\n0.548814\n\n\n1\nid_00\n2000-10-06\n103.274013\n79\n45\n0.715189\n\n\n2\nid_00\n2000-10-07\n176.574744\n79\n45\n0.602763\n\n\n3\nid_00\n2000-10-08\n258.987900\n79\n45\n0.544883\n\n\n4\nid_00\n2000-10-09\n344.940404\n79\n45\n0.423655\n\n\n\n\n\n\n\nThis dataframe will be passed to MLForecast.fit (or MLForecast.preprocess). However, since the price is dynamic we have to tell that method that only static_0 and product_id are static.\n\nfcst = MLForecast(\n    models=lgb.LGBMRegressor(n_jobs=1, random_state=0, verbosity=-1),\n    freq='D',\n    lags=[7],\n    lag_transforms={\n        1: [expanding_mean],\n        7: [(rolling_mean, 14)]\n    },\n    date_features=['dayofweek', 'month'],\n    num_threads=2,\n)\nfcst.fit(series_with_prices, static_features=['static_0', 'product_id'])\n\nMLForecast(models=[LGBMRegressor], freq=&lt;Day&gt;, lag_features=['lag7', 'expanding_mean_lag1', 'rolling_mean_lag7_window_size14'], date_features=['dayofweek', 'month'], num_threads=2)\n\n\nThe features used for training are stored in MLForecast.ts.features_order_. As you can see price was used for training.\n\nfcst.ts.features_order_\n\n['static_0',\n 'product_id',\n 'price',\n 'lag7',\n 'expanding_mean_lag1',\n 'rolling_mean_lag7_window_size14',\n 'dayofweek',\n 'month']\n\n\nSo in order to update the price in each timestep we just call MLForecast.predict with our forecast horizon and pass the prices catalog through X_df.\n\npreds = fcst.predict(h=7, X_df=prices_catalog)\npreds.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\n\n\n\n\n0\nid_00\n2001-05-15\n418.930093\n\n\n1\nid_00\n2001-05-16\n499.487368\n\n\n2\nid_00\n2001-05-17\n20.321885\n\n\n3\nid_00\n2001-05-18\n102.310778\n\n\n4\nid_00\n2001-05-19\n185.340281"
  },
  {
    "objectID": "docs/how-to-guides/transforming_exog.html",
    "href": "docs/how-to-guides/transforming_exog.html",
    "title": "Transforming exogenous features",
    "section": "",
    "text": "The MLForecast class allows you to compute lag transformations on your target, however, sometimes you want to also compute transformations on your dynamic exogenous features. This guide shows you how to accomplish that.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/transforming_exog.html#data-setup",
    "href": "docs/how-to-guides/transforming_exog.html#data-setup",
    "title": "Transforming exogenous features",
    "section": "Data setup",
    "text": "Data setup\n\nfrom mlforecast.utils import generate_series, generate_prices_for_series\n\n\nseries = generate_series(10, equal_ends=True)\nprices = generate_prices_for_series(series)\nprices.head(2)\n\n\n\n\n\n\n\n\nds\nunique_id\nprice\n\n\n\n\n0\n2000-10-05\n0\n0.548814\n\n\n1\n2000-10-06\n0\n0.715189\n\n\n\n\n\n\n\nSuppose that you have some series along with their prices for each id and date and you want to compute forecasts for the next 7 days. Since the price is a dynamic feature you have to provide the future values through X_df in MLForecast.predict.\nIf you want to use not only the price but the lag7 of the price and the expanding mean of the lag1 for example, you can compute them before training, merge them with your series and then provide the future values through X_df. Consider the following example."
  },
  {
    "objectID": "docs/how-to-guides/transforming_exog.html#computing-the-transformations",
    "href": "docs/how-to-guides/transforming_exog.html#computing-the-transformations",
    "title": "Transforming exogenous features",
    "section": "Computing the transformations",
    "text": "Computing the transformations\n\nfrom window_ops.expanding import expanding_mean\n\nfrom mlforecast.feature_engineering import transform_exog\n\n\ntransformed_prices = transform_exog(prices, lags=[7], lag_transforms={1: [expanding_mean]})\ntransformed_prices.head(10)\n\n\n\n\n\n\n\n\nds\nunique_id\nprice\nprice_lag7\nprice_expanding_mean_lag1\n\n\n\n\n0\n2000-10-05\n0\n0.548814\nNaN\nNaN\n\n\n1\n2000-10-06\n0\n0.715189\nNaN\n0.548814\n\n\n2\n2000-10-07\n0\n0.602763\nNaN\n0.632001\n\n\n3\n2000-10-08\n0\n0.544883\nNaN\n0.622255\n\n\n4\n2000-10-09\n0\n0.423655\nNaN\n0.602912\n\n\n5\n2000-10-10\n0\n0.645894\nNaN\n0.567061\n\n\n6\n2000-10-11\n0\n0.437587\nNaN\n0.580200\n\n\n7\n2000-10-12\n0\n0.891773\n0.548814\n0.559827\n\n\n8\n2000-10-13\n0\n0.963663\n0.715189\n0.601320\n\n\n9\n2000-10-14\n0\n0.383442\n0.602763\n0.641580\n\n\n\n\n\n\n\nYou can now merge this with your original series\n\nseries_with_prices = series.merge(transformed_prices, on=['unique_id', 'ds'])\nseries_with_prices.head(10)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nprice\nprice_lag7\nprice_expanding_mean_lag1\n\n\n\n\n0\n0\n2000-10-05\n0.322947\n0.548814\nNaN\nNaN\n\n\n1\n0\n2000-10-06\n1.218794\n0.715189\nNaN\n0.548814\n\n\n2\n0\n2000-10-07\n2.445887\n0.602763\nNaN\n0.632001\n\n\n3\n0\n2000-10-08\n3.481831\n0.544883\nNaN\n0.622255\n\n\n4\n0\n2000-10-09\n4.191721\n0.423655\nNaN\n0.602912\n\n\n5\n0\n2000-10-10\n5.395863\n0.645894\nNaN\n0.567061\n\n\n6\n0\n2000-10-11\n6.264447\n0.437587\nNaN\n0.580200\n\n\n7\n0\n2000-10-12\n0.284022\n0.891773\n0.548814\n0.559827\n\n\n8\n0\n2000-10-13\n1.462798\n0.963663\n0.715189\n0.601320\n\n\n9\n0\n2000-10-14\n2.035518\n0.383442\n0.602763\n0.641580\n\n\n\n\n\n\n\nYou can then define your forecast object. Note that you can still compute lag features based on the target as you normally would.\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom mlforecast import MLForecast\n\n\nfcst = MLForecast(\n    models=[LinearRegression()],\n    freq='D',\n    lags=[1],\n    date_features=['dayofweek'],\n)\nfcst.preprocess(series_with_prices, dropna=True).head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nprice\nprice_lag7\nprice_expanding_mean_lag1\nlag1\ndayofweek\n\n\n\n\n1\n0\n2000-10-06\n1.218794\n0.715189\nNaN\n0.548814\n0.322947\n4\n\n\n2\n0\n2000-10-07\n2.445887\n0.602763\nNaN\n0.632001\n1.218794\n5\n\n\n3\n0\n2000-10-08\n3.481831\n0.544883\nNaN\n0.622255\n2.445887\n6\n\n\n4\n0\n2000-10-09\n4.191721\n0.423655\nNaN\n0.602912\n3.481831\n0\n\n\n5\n0\n2000-10-10\n5.395863\n0.645894\nNaN\n0.567061\n4.191721\n1\n\n\n\n\n\n\n\nIt’s important to note that the dropna argument only considers the null values generated by the lag features based on the target. If you want to drop all rows containing null values you have to do that in your original series.\n\nseries_with_prices2 = series_with_prices.dropna()\nfcst.preprocess(series_with_prices2, dropna=True, static_features=[]).head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nprice\nprice_lag7\nprice_expanding_mean_lag1\nlag1\ndayofweek\n\n\n\n\n8\n0\n2000-10-13\n1.462798\n0.963663\n0.715189\n0.601320\n0.284022\n4\n\n\n9\n0\n2000-10-14\n2.035518\n0.383442\n0.602763\n0.641580\n1.462798\n5\n\n\n10\n0\n2000-10-15\n3.043565\n0.791725\n0.544883\n0.615766\n2.035518\n6\n\n\n11\n0\n2000-10-16\n4.010109\n0.528895\n0.423655\n0.631763\n3.043565\n0\n\n\n12\n0\n2000-10-17\n5.416310\n0.568045\n0.645894\n0.623190\n4.010109\n1\n\n\n\n\n\n\n\nYou can now train the model.\n\nfcst.fit(series_with_prices2, static_features=[])\n\nMLForecast(models=[LinearRegression], freq=&lt;Day&gt;, lag_features=['lag1'], date_features=['dayofweek'], num_threads=1)\n\n\nAnd predict using the prices. Note that you can provide the dataframe with the full history and mlforecast will filter the required dates for the forecasting horizon.\n\nfcst.predict(1, X_df=transformed_prices).head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLinearRegression\n\n\n\n\n0\n0\n2001-05-15\n3.803967\n\n\n1\n1\n2001-05-15\n3.512489\n\n\n2\n2\n2001-05-15\n3.170019\n\n\n3\n3\n2001-05-15\n4.307121\n\n\n4\n4\n2001-05-15\n3.018758\n\n\n\n\n\n\n\nIn this example we have prices for the next 7 days, if you try to forecast a longer horizon you’ll get an error.\n\nfrom fastcore.test import test_fail\n\n\ntest_fail(lambda: fcst.predict(8, X_df=transformed_prices), contains='Found missing inputs in X_df')"
  },
  {
    "objectID": "docs/how-to-guides/analyzing_models.html",
    "href": "docs/how-to-guides/analyzing_models.html",
    "title": "Analyzing the trained models",
    "section": "",
    "text": "from mlforecast.utils import generate_daily_series\n\n\nseries = generate_daily_series(10)\nseries.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nid_0\n2000-01-01\n0.322947\n\n\n1\nid_0\n2000-01-02\n1.218794\n\n\n2\nid_0\n2000-01-03\n2.445887\n\n\n3\nid_0\n2000-01-04\n3.481831\n\n\n4\nid_0\n2000-01-05\n4.191721\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/analyzing_models.html#data-setup",
    "href": "docs/how-to-guides/analyzing_models.html#data-setup",
    "title": "Analyzing the trained models",
    "section": "",
    "text": "from mlforecast.utils import generate_daily_series\n\n\nseries = generate_daily_series(10)\nseries.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nid_0\n2000-01-01\n0.322947\n\n\n1\nid_0\n2000-01-02\n1.218794\n\n\n2\nid_0\n2000-01-03\n2.445887\n\n\n3\nid_0\n2000-01-04\n3.481831\n\n\n4\nid_0\n2000-01-05\n4.191721"
  },
  {
    "objectID": "docs/how-to-guides/analyzing_models.html#training",
    "href": "docs/how-to-guides/analyzing_models.html#training",
    "title": "Analyzing the trained models",
    "section": "Training",
    "text": "Training\nSuppose that you want to train a linear regression model using the day of the week and lag1 as features.\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom mlforecast import MLForecast\n\n\nfcst = MLForecast(\n    freq='D',\n    models={'lr': LinearRegression()},\n    lags=[1],\n    date_features=['dayofweek'],\n)\n\n\nfcst.fit(series)\n\nMLForecast(models=[lr], freq=&lt;Day&gt;, lag_features=['lag1'], date_features=['dayofweek'], num_threads=1)\n\n\nWhat MLForecast.fit does is save the required data for the predict step and also train the models (in this case the linear regression). The trained models are available in the MLForecast.models_ attribute, which is a dictionary where the keys are the model names and the values are the model themselves.\n\nfcst.models_\n\n{'lr': LinearRegression()}"
  },
  {
    "objectID": "docs/how-to-guides/analyzing_models.html#inspect-parameters",
    "href": "docs/how-to-guides/analyzing_models.html#inspect-parameters",
    "title": "Analyzing the trained models",
    "section": "Inspect parameters",
    "text": "Inspect parameters\nWe can access the linear regression coefficients in the following way:\n\nfcst.models_['lr'].intercept_, fcst.models_['lr'].coef_\n\n(3.2476337167384415, array([ 0.19896416, -0.21441331]))"
  },
  {
    "objectID": "docs/how-to-guides/analyzing_models.html#shap",
    "href": "docs/how-to-guides/analyzing_models.html#shap",
    "title": "Analyzing the trained models",
    "section": "SHAP",
    "text": "SHAP\n\nimport shap\n\n\nTraining set\nIf you need to generate the training data you can use MLForecast.preprocess.\n\nprep = fcst.preprocess(series)\nprep.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlag1\ndayofweek\n\n\n\n\n1\nid_0\n2000-01-02\n1.218794\n0.322947\n6\n\n\n2\nid_0\n2000-01-03\n2.445887\n1.218794\n0\n\n\n3\nid_0\n2000-01-04\n3.481831\n2.445887\n1\n\n\n4\nid_0\n2000-01-05\n4.191721\n3.481831\n2\n\n\n5\nid_0\n2000-01-06\n5.395863\n4.191721\n3\n\n\n\n\n\n\n\nWe extract the X, which involves dropping the info columns (id + times) and the target\n\nX = prep.drop(columns=['unique_id', 'ds', 'y'])\nX.head()\n\n\n\n\n\n\n\n\nlag1\ndayofweek\n\n\n\n\n1\n0.322947\n6\n\n\n2\n1.218794\n0\n\n\n3\n2.445887\n1\n\n\n4\n3.481831\n2\n\n\n5\n4.191721\n3\n\n\n\n\n\n\n\nWe can now compute the shap values\n\nX100 = shap.utils.sample(X, 100)\nexplainer = shap.Explainer(fcst.models_['lr'].predict, X100)\nshap_values = explainer(X)\n\nAnd visualize them\n\nshap.plots.beeswarm(shap_values)\n\n\n\n\n\n\nPredictions\nSometimes you want to determine why the model gave a specific prediction. In order to do this you need the input features, which aren’t returned by default, but you can retrieve them using a callback.\n\nfrom mlforecast.callbacks import SaveFeatures\n\n\nsave_feats = SaveFeatures()\npreds = fcst.predict(1, before_predict_callback=save_feats)\npreds.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nlr\n\n\n\n\n0\nid_0\n2000-08-10\n3.468643\n\n\n1\nid_1\n2000-04-07\n3.016877\n\n\n2\nid_2\n2000-06-16\n2.815249\n\n\n3\nid_3\n2000-08-30\n4.048894\n\n\n4\nid_4\n2001-01-08\n3.524532\n\n\n\n\n\n\n\nYou can now retrieve the features by using SaveFeatures.get_features\n\nfeatures = save_feats.get_features()\nfeatures.head()\n\n\n\n\n\n\n\n\nlag1\ndayofweek\n\n\n\n\n0\n4.343744\n3\n\n\n1\n3.150799\n4\n\n\n2\n2.137412\n4\n\n\n3\n6.182456\n2\n\n\n4\n1.391698\n0\n\n\n\n\n\n\n\nAnd use those features to compute the shap values.\n\nshap_values_predictions = explainer(features)\n\nWe can now analyze what influenced the prediction for 'id_4'.\n\nround(preds.loc[4, 'lr'], 3)\n\n3.525\n\n\n\nshap.plots.waterfall(shap_values_predictions[4])"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html",
    "href": "docs/how-to-guides/cross_validation.html",
    "title": "Cross validation",
    "section": "",
    "text": "Prerequesites\n\n\n\n\n\nThis tutorial assumes basic familiarity with MLForecast. For a minimal example visit the Quick Start\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#introduction",
    "href": "docs/how-to-guides/cross_validation.html#introduction",
    "title": "Cross validation",
    "section": "Introduction",
    "text": "Introduction\nTime series cross-validation is a method for evaluating how a model would have performed in the past. It works by defining a sliding window across the historical data and predicting the period following it.\n\nMLForecast has an implementation of time series cross-validation that is fast and easy to use. This implementation makes cross-validation a efficient operation, which makes it less time-consuming. In this notebook, we’ll use it on a subset of the M4 Competition hourly dataset.\nOutline:\n\nInstall libraries\nLoad and explore data\nTrain model\nPerform time series cross-validation\nEvaluate results\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#install-libraries",
    "href": "docs/how-to-guides/cross_validation.html#install-libraries",
    "title": "Cross validation",
    "section": "Install libraries",
    "text": "Install libraries\nWe assume that you have MLForecast already installed. If not, check this guide for instructions on how to install MLForecast.\nInstall the necessary packages with pip install mlforecast.\n\n# pip install mlforecast lightgbm\n\n\nimport pandas as pd \n\nfrom utilsforecast.plotting import plot_series\n\nfrom mlforecast import MLForecast # required to instantiate MLForecast object and use cross-validation method"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#load-and-explore-the-data",
    "href": "docs/how-to-guides/cross_validation.html#load-and-explore-the-data",
    "title": "Cross validation",
    "section": "Load and explore the data",
    "text": "Load and explore the data\nAs stated in the introduction, we’ll use the M4 Competition hourly dataset. We’ll first import the data from an URL using pandas.\n\nY_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/m4-hourly.csv') # load the data \nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH1\n1\n605.0\n\n\n1\nH1\n2\n586.0\n\n\n2\nH1\n3\n586.0\n\n\n3\nH1\n4\n559.0\n\n\n4\nH1\n5\n511.0\n\n\n\n\n\n\n\nThe input to MLForecast is a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int, or category) represents an identifier for the series.\nThe ds (datestamp or int) column should be either an integer indexing time or a datestamp in format YYYY-MM-DD or YYYY-MM-DD HH:MM:SS.\nThe y (numeric) represents the measurement we wish to forecast.\n\nThe data in this example already has this format, so no changes are needed.\nWe can plot the time series we’ll work with using the following function.\n\nfig = plot_series(Y_df, max_ids=4, plot_random=False, max_insample_length=24 * 14)"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#define-forecast-object",
    "href": "docs/how-to-guides/cross_validation.html#define-forecast-object",
    "title": "Cross validation",
    "section": "Define forecast object",
    "text": "Define forecast object\nFor this example, we’ll use LightGBM. We first need to import it and then we need to instantiate a new MLForecast object.\nIn this example, we are only using differences and lags to produce features. See the full documentation to see all available features.\nAny settings are passed into the constructor. Then you call its fit method and pass in the historical data frame df.\n\nimport lightgbm as lgb\nfrom mlforecast.target_transforms import Differences\n\n\nmodels = [lgb.LGBMRegressor(verbosity=-1)]\n\nmlf = MLForecast(\n    models = models, \n    freq = 1,# our series have integer timestamps, so we'll just add 1 in every timeste, \n    target_transforms=[Differences([24])],\n    lags=range(1, 25, 1)\n)"
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#perform-time-series-cross-validation",
    "href": "docs/how-to-guides/cross_validation.html#perform-time-series-cross-validation",
    "title": "Cross validation",
    "section": "Perform time series cross-validation",
    "text": "Perform time series cross-validation\nOnce the MLForecast object has been instantiated, we can use the cross_validation method.\nFor this particular example, we’ll use 3 windows of 24 hours.\n\ncrossvalidation_df = mlf.cross_validation(\n    df=Y_df,\n    h=24,\n    n_windows=3,\n)\n\nThe crossvaldation_df object is a new data frame that includes the following columns:\n\nunique_id: identifies each time series.\nds: datestamp or temporal index.\ncutoff: the last datestamp or temporal index for the n_windows.\ny: true value\n\"model\": columns with the model’s name and fitted value.\n\n\ncrossvalidation_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\n\n\n\n\n0\nH1\n677\n676\n691.0\n673.703191\n\n\n1\nH1\n678\n676\n618.0\n552.306270\n\n\n2\nH1\n679\n676\n563.0\n541.778027\n\n\n3\nH1\n680\n676\n529.0\n502.778027\n\n\n4\nH1\n681\n676\n504.0\n480.778027\n\n\n\n\n\n\n\nWe’ll now plot the forecast for each cutoff period.\n\nimport matplotlib.pyplot as plt\n\n\ndef plot_cv(df, df_cv, uid, fname, last_n=24 * 14):\n    cutoffs = df_cv.query('unique_id == @uid')['cutoff'].unique()\n    fig, ax = plt.subplots(nrows=len(cutoffs), ncols=1, figsize=(14, 6), gridspec_kw=dict(hspace=0.8))\n    for cutoff, axi in zip(cutoffs, ax.flat):\n        df.query('unique_id == @uid').tail(last_n).set_index('ds').plot(ax=axi, title=uid, y='y')\n        df_cv.query('unique_id == @uid & cutoff == @cutoff').set_index('ds').plot(ax=axi, title=uid, y='LGBMRegressor')\n    fig.savefig(fname, bbox_inches='tight')\n    plt.close()\n\n\nplot_cv(Y_df, crossvalidation_df, 'H1', '../../figs/cross_validation__predictions.png')\n\n\nNotice that in each cutoff period, we generated a forecast for the next 24 hours using only the data y before said period."
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#evaluate-results",
    "href": "docs/how-to-guides/cross_validation.html#evaluate-results",
    "title": "Cross validation",
    "section": "Evaluate results",
    "text": "Evaluate results\nWe can now compute the accuracy of the forecast using an appropiate accuracy metric. Here we’ll use the Root Mean Squared Error (RMSE). To do this, we can use utilsforecast, a Python library developed by Nixtla that includes a function to compute the RMSE.\n\nfrom utilsforecast.losses import rmse\n\nWe’ll compute the rmse per time series and cutoff. To do this we’ll concatenate the id and the cutoff columns, then we will take the mean of the results.\n\ncrossvalidation_df['id_cutoff'] = crossvalidation_df['unique_id'] + '_' + crossvalidation_df['cutoff'].astype(str)\ncv_rmse = rmse(crossvalidation_df, models=['LGBMRegressor'], id_col='id_cutoff')['LGBMRegressor'].mean()\nprint(\"RMSE using cross-validation: \", cv_rmse)\n\nRMSE using cross-validation:  249.90517171185527\n\n\nThis measure should better reflect the predictive abilities of our model, since it used different time periods to test its accuracy."
  },
  {
    "objectID": "docs/how-to-guides/cross_validation.html#references",
    "href": "docs/how-to-guides/cross_validation.html#references",
    "title": "Cross validation",
    "section": "References",
    "text": "References\nRob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Time series cross-validation”."
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html",
    "href": "docs/how-to-guides/transfer_learning.html",
    "title": "Transfer Learning",
    "section": "",
    "text": "Transfer learning refers to the process of pre-training a flexible model on a large dataset and using it later on other data with little to no training. It is one of the most outstanding 🚀 achievements in Machine Learning and has many practical applications.\nFor time series forecasting, the technique allows you to get lightning-fast predictions ⚡ bypassing the tradeoff between accuracy and speed (more than 30 times faster than our already fast AutoARIMA for a similar accuracy).\nThis notebook shows how to generate a pre-trained model to forecast new time series never seen by the model.\nTable of Contents\nYou can run these experiments with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html#installing-libraries",
    "href": "docs/how-to-guides/transfer_learning.html#installing-libraries",
    "title": "Transfer Learning",
    "section": "Installing Libraries",
    "text": "Installing Libraries\n\n# !pip install mlforecast datasetsforecast utilsforecast s3fs\n\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom datasetsforecast.m3 import M3\nfrom sklearn.metrics import mean_absolute_error\nfrom utilsforecast.plotting import plot_series\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences"
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html#load-m3-data",
    "href": "docs/how-to-guides/transfer_learning.html#load-m3-data",
    "title": "Transfer Learning",
    "section": "Load M3 Data",
    "text": "Load M3 Data\nThe M3 class will automatically download the complete M3 dataset and process it.\nIt return three Dataframes: Y_df contains the values for the target variables, X_df contains exogenous calendar features and S_df contains static features for each time-series. For this example we will only use Y_df.\nIf you want to use your own data just replace Y_df. Be sure to use a long format and have a simmilar structure than our data set.\n\nY_df_M3, _, _ = M3.load(directory='./', group='Monthly')\n\nIn this tutorial we are only using 1_000 series to speed up computations. Remove the filter to use the whole dataset.\n\nfig = plot_series(Y_df_M3)"
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html#model-training",
    "href": "docs/how-to-guides/transfer_learning.html#model-training",
    "title": "Transfer Learning",
    "section": "Model Training",
    "text": "Model Training\nUsing the MLForecast.fit method you can train a set of models to your dataset. You can modify the hyperparameters of the model to get a better accuracy, in this case we will use the default hyperparameters of lgb.LGBMRegressor.\n\nmodels = [lgb.LGBMRegressor(verbosity=-1)]\n\nThe MLForecast object has the following parameters:\n\nmodels: a list of sklearn-like (fit and predict) models.\nfreq: a string indicating the frequency of the data. See panda’s available frequencies.\ndifferences: Differences to take of the target before computing the features. These are restored at the forecasting step.\nlags: Lags of the target to use as features.\n\nIn this example, we are only using differences and lags to produce features. See the full documentation to see all available features.\nAny settings are passed into the constructor. Then you call its fit method and pass in the historical data frame Y_df_M3.\n\nfcst = MLForecast(\n    models=models, \n    lags=range(1, 13),\n    freq='MS',\n    target_transforms=[Differences([1, 12])],\n)\nfcst.fit(Y_df_M3);"
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html#transfer-m3-to-airpassengers",
    "href": "docs/how-to-guides/transfer_learning.html#transfer-m3-to-airpassengers",
    "title": "Transfer Learning",
    "section": "Transfer M3 to AirPassengers",
    "text": "Transfer M3 to AirPassengers\nNow we can transfer the trained model to forecast AirPassengers with the MLForecast.predict method, we just have to pass the new dataframe to the new_data argument.\n\nY_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/air-passengers.csv', parse_dates=['ds'])\n\n# We define the train df. \nY_train_df = Y_df[Y_df.ds&lt;='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds&gt;'1959-12-31']   # 12 test\n\n\nY_hat_df = fcst.predict(h=12, new_df=Y_train_df)\nY_hat_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\n\n\n\n\n0\nAirPassengers\n1960-01-01\n422.740096\n\n\n1\nAirPassengers\n1960-02-01\n399.480193\n\n\n2\nAirPassengers\n1960-03-01\n458.220289\n\n\n3\nAirPassengers\n1960-04-01\n442.960385\n\n\n4\nAirPassengers\n1960-05-01\n461.700482\n\n\n\n\n\n\n\n\nY_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\n\n\nfig = plot_series(Y_train_df, Y_hat_df)"
  },
  {
    "objectID": "docs/how-to-guides/transfer_learning.html#evaluate-results",
    "href": "docs/how-to-guides/transfer_learning.html#evaluate-results",
    "title": "Transfer Learning",
    "section": "Evaluate Results",
    "text": "Evaluate Results\nWe evaluate the forecasts of the pre-trained model with the Mean Absolute Error (mae).\n\\[\n\\qquad MAE = \\frac{1}{Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}|\\qquad\n\\]\n\ny_true = Y_test_df.y.values\ny_hat = Y_hat_df['LGBMRegressor'].values\n\n\nprint(f'LGBMRegressor     MAE: {mean_absolute_error(y_hat, y_true):.3f}')\nprint('ETS               MAE: 16.222')\nprint('AutoARIMA         MAE: 18.551')\n\nLGBMRegressor     MAE: 13.560\nETS               MAE: 16.222\nAutoARIMA         MAE: 18.551"
  },
  {
    "objectID": "docs/how-to-guides/lag_transforms_guide.html",
    "href": "docs/how-to-guides/lag_transforms_guide.html",
    "title": "Lag transformations",
    "section": "",
    "text": "mlforecast allows you to define transformations on the lags to use as features. These are provided through the lag_transforms argument, which is a dict where the keys are the lags and the values are a list of transformations to apply to that lag.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/lag_transforms_guide.html#data-setup",
    "href": "docs/how-to-guides/lag_transforms_guide.html#data-setup",
    "title": "Lag transformations",
    "section": "Data setup",
    "text": "Data setup\n\nfrom mlforecast.utils import generate_daily_series\n\n\ndata = generate_daily_series(10)"
  },
  {
    "objectID": "docs/how-to-guides/lag_transforms_guide.html#window-ops",
    "href": "docs/how-to-guides/lag_transforms_guide.html#window-ops",
    "title": "Lag transformations",
    "section": "window-ops",
    "text": "window-ops\nThe window-ops package provides transformations defined as numba JIT compiled functions, which allows you to use them directly and also composing them very easily. We use numba because it makes them really fast and can also bypass python’s GIL, which allows running them concurrently with multithreading.\n\nimport numpy as np\nfrom numba import njit\nfrom window_ops.expanding import expanding_mean\nfrom window_ops.shift import shift_array\n\nfrom mlforecast import MLForecast\n\n\n@njit\ndef ratio_over_previous(x, offset=1):\n    \"\"\"Computes the ratio between the current value and its `offset` lag\"\"\"\n    return x / shift_array(x, offset=offset)\n\n@njit\ndef diff_over_previous(x, offset=1):\n    \"\"\"Computes the difference between the current value and its `offset` lag\"\"\"\n    return x - shift_array(x, offset=offset)\n\nIf your function takes more arguments than the input array you can provide a tuple like: (func, arg1, arg2, ...)\n\nfcst = MLForecast(\n    models=[],\n    freq='D',\n    lags=[1, 2, 3],\n    lag_transforms={\n        1: [expanding_mean, ratio_over_previous, (ratio_over_previous, 2)],  # the second ratio sets offset=2\n        2: [diff_over_previous],\n    },\n)\nprep = fcst.preprocess(data)\nprep.head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nlag1\nlag2\nlag3\nexpanding_mean_lag1\nratio_over_previous_lag1\nratio_over_previous_lag1_offset2\ndiff_over_previous_lag2\n\n\n\n\n3\nid_0\n2000-01-04\n3.481831\n2.445887\n1.218794\n0.322947\n1.329209\n2.006809\n7.573645\n0.895847\n\n\n4\nid_0\n2000-01-05\n4.191721\n3.481831\n2.445887\n1.218794\n1.867365\n1.423546\n2.856785\n1.227093\n\n\n\n\n\n\n\nAs you can see the name of the function is used as the transformation name plus the _lag suffix. If the function has other arguments and they’re not set to their default values they’re included as well, as is done with offset=2 here.\n\nnp.testing.assert_allclose(prep['lag1'] / prep['lag2'], prep['ratio_over_previous_lag1'])\nnp.testing.assert_allclose(prep['lag1'] / prep['lag3'], prep['ratio_over_previous_lag1_offset2'])\nnp.testing.assert_allclose(prep['lag2'] - prep['lag3'], prep['diff_over_previous_lag2'])"
  },
  {
    "objectID": "docs/how-to-guides/lag_transforms_guide.html#built-in-transformations-experimental",
    "href": "docs/how-to-guides/lag_transforms_guide.html#built-in-transformations-experimental",
    "title": "Lag transformations",
    "section": "Built-in transformations (experimental)",
    "text": "Built-in transformations (experimental)\nThe built-in lag transformations are in the mlforecast.lag_transforms module. This module is experimental, so in order to use it you need the coreforecast package, which you can get with: pip install coreforecast or pip install \"mlforecast[lag_transforms]\". If you’re using conda please install it with conda install -c conda-forge coreforecast instead.\nThe main benefit of using these transformations is that since they’re defined as classes they contain more information on the transformation that is being applied and can thus make it more efficiently, e.g. in order to update a rolling mean it just looks at the last window_size values, whereas the functions from window-ops have to re-apply the transformation on the full history. Another benefit is that the multithreading is done on the series, as opposed to the transformations, which can help in cases where the transformations are very different. Also, the multithreading is done in C++, so there’s no risk of getting blocked by the GIL.\n\nfrom mlforecast.lag_transforms import RollingMean, ExpandingStd\n\n\nfcst = MLForecast(\n    models=[],\n    freq='D',\n    lag_transforms={\n        1: [ExpandingStd()],\n        7: [RollingMean(window_size=7, min_samples=1), RollingMean(window_size=14)]\n    },\n)\n\nOnce you define your transformations you can see what they look like with MLForecast.preprocess.\n\nfcst.preprocess(data).head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nexpanding_std_lag1\nrolling_mean_lag7_window_size7_min_samples1\nrolling_mean_lag7_window_size14\n\n\n\n\n20\nid_0\n2000-01-21\n6.319961\n1.956363\n3.234486\n3.283064\n\n\n21\nid_0\n2000-01-22\n0.071677\n2.028545\n3.256055\n3.291068\n\n\n\n\n\n\n\n\nExtending the built-in transformations\nYou can compose these transformations by defining a new class that defines the transform and update methods. Consider the following example:\n\nimport coreforecast.lag_transforms as core_tfms\nfrom coreforecast.grouped_array import GroupedArray\n\n\nclass RollingMeansRatioCore:\n    def __init__(self, lag: int, window_one: int, window_two: int):\n        self.lag = lag\n        self.window_one = window_one\n        self.window_two = window_two\n\n    def transform(self, ga: GroupedArray) -&gt; np.ndarray:\n        self.tfm1 = core_tfms.RollingMean(self.lag, self.window_one)\n        self.tfm2 = core_tfms.RollingMean(self.lag, self.window_two)\n        return self.tfm1.transform(ga) / self.tfm2.transform(ga)\n\n    def update(self, ga: GroupedArray) -&gt; np.ndarray:\n        return self.tfm1.update(ga) / self.tfm2.update(ga)\n\nIn order to keep the mlforecast API for lag transforms where the lag is the key, we have to wrap this transformation in another one. We hope to deprecate this in the future so that you only need to define the previous class. The wrapper class needs to implement the _set_core_tfm method which takes the lag and sets the _core_tfm attribute to be a transformation like the one we defined above.\n\nfrom mlforecast.lag_transforms import BaseLagTransform\n\n\nclass RollingMeansRatio(BaseLagTransform):\n    def __init__(self, window_one: int, window_two: int):\n        self.window_one = window_one\n        self.window_two = window_two\n\n    def _set_core_tfm(self, lag: int):\n        self._core_tfm = RollingMeansRatioCore(lag, self.window_one, self.window_two)\n        return self\n\n\nfcst = MLForecast(\n    models=[],\n    freq='D',\n    lag_transforms={\n        1: [\n            RollingMean(window_size=7),\n            RollingMean(window_size=14),\n            RollingMeansRatio(window_one=7, window_two=14)\n        ],\n    },\n)\nprep = fcst.preprocess(data)\nprep.head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nrolling_mean_lag1_window_size7\nrolling_mean_lag1_window_size14\nrolling_means_ratio_lag1_window_one7_window_two14\n\n\n\n\n14\nid_0\n2000-01-15\n0.435006\n3.234486\n3.283064\n0.985204\n\n\n15\nid_0\n2000-01-16\n1.489309\n3.256055\n3.291068\n0.989361\n\n\n\n\n\n\n\n\nnp.testing.assert_allclose(\n    prep['rolling_mean_lag1_window_size7'] / prep['rolling_mean_lag1_window_size14'],\n    prep['rolling_means_ratio_lag1_window_one7_window_two14']\n)"
  },
  {
    "objectID": "docs/how-to-guides/custom_date_features.html",
    "href": "docs/how-to-guides/custom_date_features.html",
    "title": "Custom date features",
    "section": "",
    "text": "from mlforecast import MLForecast\nfrom mlforecast.utils import generate_daily_series\n\nThe date_features argument of MLForecast can take pandas date attributes as well as functions that take a pandas DatetimeIndex and return a numeric value. The name of the function is used as the name of the feature, so please use unique and descriptive names.\n\nseries = generate_daily_series(1, min_length=6, max_length=6)\n\n\ndef even_day(dates):\n    \"\"\"Day of month is even\"\"\"\n    return dates.day % 2 == 0\n\ndef month_start_or_end(dates):\n    \"\"\"Date is month start or month end\"\"\"\n    return dates.is_month_start | dates.is_month_end\n\ndef is_monday(dates):\n    \"\"\"Date is monday\"\"\"\n    return dates.dayofweek == 0\n\n\nfcst = MLForecast(\n    [],\n    freq='D',\n    date_features=['dayofweek', 'dayofyear', even_day, month_start_or_end, is_monday]\n)\nfcst.preprocess(series)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\ndayofweek\ndayofyear\neven_day\nmonth_start_or_end\nis_monday\n\n\n\n\n0\nid_0\n2000-01-01\n0.274407\n5\n1\nFalse\nTrue\nFalse\n\n\n1\nid_0\n2000-01-02\n1.357595\n6\n2\nTrue\nFalse\nFalse\n\n\n2\nid_0\n2000-01-03\n2.301382\n0\n3\nFalse\nFalse\nTrue\n\n\n3\nid_0\n2000-01-04\n3.272442\n1\n4\nTrue\nFalse\nFalse\n\n\n4\nid_0\n2000-01-05\n4.211827\n2\n5\nFalse\nFalse\nFalse\n\n\n5\nid_0\n2000-01-06\n5.322947\n3\n6\nTrue\nFalse\nFalse\n\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "from fastcore.test import test_eq, test_fail\nfrom nbdev import show_doc\n\n\n\ngenerate_daily_series\n\n generate_daily_series (n_series:int, min_length:int=50,\n                        max_length:int=500, n_static_features:int=0,\n                        equal_ends:bool=False,\n                        static_as_categorical:bool=True,\n                        with_trend:bool=False, seed:int=0,\n                        engine:str='pandas')\n\nGenerate Synthetic Panel Series.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_series\nint\n\nNumber of series for synthetic panel.\n\n\nmin_length\nint\n50\nMinimum length of synthetic panel’s series.\n\n\nmax_length\nint\n500\nMaximum length of synthetic panel’s series.\n\n\nn_static_features\nint\n0\nNumber of static exogenous variables for synthetic panel’s series.\n\n\nequal_ends\nbool\nFalse\nSeries should end in the same date stamp ds.\n\n\nstatic_as_categorical\nbool\nTrue\nStatic features should have a categorical data type.\n\n\nwith_trend\nbool\nFalse\nSeries should have a (positive) trend.\n\n\nseed\nint\n0\nRandom seed used for generating the data.\n\n\nengine\nstr\npandas\nOutput Dataframe type.\n\n\nReturns\ntyping.Union[pandas.core.frame.DataFrame, polars.dataframe.frame.DataFrame]\n\nSynthetic panel with columns [unique_id, ds, y] and exogenous features.\n\n\n\nGenerate 20 series with lengths between 100 and 1,000.\n\nn_series = 20\nmin_length = 100\nmax_length = 1000\n\nseries = generate_daily_series(n_series, min_length, max_length)\nseries\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nid_00\n2000-01-01\n0.395863\n\n\n1\nid_00\n2000-01-02\n1.264447\n\n\n2\nid_00\n2000-01-03\n2.284022\n\n\n3\nid_00\n2000-01-04\n3.462798\n\n\n4\nid_00\n2000-01-05\n4.035518\n\n\n...\n...\n...\n...\n\n\n12446\nid_19\n2002-03-11\n0.309275\n\n\n12447\nid_19\n2002-03-12\n1.189464\n\n\n12448\nid_19\n2002-03-13\n2.325032\n\n\n12449\nid_19\n2002-03-14\n3.333198\n\n\n12450\nid_19\n2002-03-15\n4.306117\n\n\n\n\n12451 rows × 3 columns\n\n\n\nWe can also add static features to each serie (these can be things like product_id or store_id). Only the first static feature (static_0) is relevant to the target.\n\nn_static_features = 2\n\nseries_with_statics = generate_daily_series(n_series, min_length, max_length, n_static_features)\nseries_with_statics\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nstatic_0\nstatic_1\n\n\n\n\n0\nid_00\n2000-01-01\n7.521388\n18\n10\n\n\n1\nid_00\n2000-01-02\n24.024502\n18\n10\n\n\n2\nid_00\n2000-01-03\n43.396423\n18\n10\n\n\n3\nid_00\n2000-01-04\n65.793168\n18\n10\n\n\n4\nid_00\n2000-01-05\n76.674843\n18\n10\n\n\n...\n...\n...\n...\n...\n...\n\n\n12446\nid_19\n2002-03-11\n27.834771\n89\n42\n\n\n12447\nid_19\n2002-03-12\n107.051746\n89\n42\n\n\n12448\nid_19\n2002-03-13\n209.252845\n89\n42\n\n\n12449\nid_19\n2002-03-14\n299.987801\n89\n42\n\n\n12450\nid_19\n2002-03-15\n387.550536\n89\n42\n\n\n\n\n12451 rows × 5 columns\n\n\n\n\nfor i in range(n_static_features):\n    assert all(series_with_statics.groupby('unique_id')[f'static_{i}'].nunique() == 1)\n\nIf equal_ends=False (the default) then every serie has a different end date.\n\nassert series_with_statics.groupby('unique_id')['ds'].max().nunique() &gt; 1\n\nWe can have all of them end at the same date by specifying equal_ends=True.\n\nseries_equal_ends = generate_daily_series(n_series, min_length, max_length, equal_ends=True)\n\nassert series_equal_ends.groupby('unique_id')['ds'].max().nunique() == 1\n\n\n\n\ngenerate_prices_for_series\n\n generate_prices_for_series (series:pandas.core.frame.DataFrame,\n                             horizon:int=7, seed:int=0)\n\n\nseries_for_prices = generate_daily_series(20, n_static_features=2, equal_ends=True)\nseries_for_prices.rename(columns={'static_1': 'product_id'}, inplace=True)\nprices_catalog = generate_prices_for_series(series_for_prices, horizon=7)\nprices_catalog\n\n\n\n\n\n\n\n\nds\nunique_id\nprice\n\n\n\n\n0\n2000-10-05\nid_00\n0.548814\n\n\n1\n2000-10-06\nid_00\n0.715189\n\n\n2\n2000-10-07\nid_00\n0.602763\n\n\n3\n2000-10-08\nid_00\n0.544883\n\n\n4\n2000-10-09\nid_00\n0.423655\n\n\n...\n...\n...\n...\n\n\n5009\n2001-05-17\nid_19\n0.288027\n\n\n5010\n2001-05-18\nid_19\n0.846305\n\n\n5011\n2001-05-19\nid_19\n0.791284\n\n\n5012\n2001-05-20\nid_19\n0.578636\n\n\n5013\n2001-05-21\nid_19\n0.288589\n\n\n\n\n5014 rows × 3 columns\n\n\n\n\ntest_eq(set(prices_catalog['unique_id']), set(series_for_prices['unique_id']))\ntest_fail(lambda: generate_prices_for_series(series), contains='equal ends')\n\n\n\n\nbacktest_splits\n\n backtest_splits\n                  (df:Union[pandas.core.frame.DataFrame,polars.dataframe.f\n                  rame.DataFrame], n_windows:int, h:int, id_col:str,\n                  time_col:str,\n                  freq:Union[pandas._libs.tslibs.offsets.BaseOffset,int],\n                  step_size:Optional[int]=None,\n                  input_size:Optional[int]=None)\n\n\n\n\nPredictionIntervals\n\n PredictionIntervals (n_windows:int=2, h:int=1,\n                      method:str='conformal_distribution')\n\nClass for storing prediction intervals metadata information.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.models.spark.xgb.html",
    "href": "distributed.models.spark.xgb.html",
    "title": "SparkXGBForecast",
    "section": "",
    "text": "Wrapper of xgboost.spark.SparkXGBRegressor that adds an extract_local_model method to get a local version of the trained model and broadcast it to the workers.\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Note\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\nSparkXGBForecast\n\n SparkXGBForecast (features_col:Union[str,List[str]]='features',\n                   label_col:str='label', prediction_col:str='prediction',\n                   pred_contrib_col:Optional[str]=None,\n                   validation_indicator_col:Optional[str]=None,\n                   weight_col:Optional[str]=None,\n                   base_margin_col:Optional[str]=None, num_workers:int=1,\n                   use_gpu:Optional[bool]=None, device:Optional[str]=None,\n                   force_repartition:bool=False,\n                   repartition_random_shuffle:bool=False,\n                   enable_sparse_data_optim:bool=False, **kwargs:Any)\n\nSparkXGBRegressor is a PySpark ML estimator. It implements the XGBoost regression algorithm based on XGBoost python library, and it can be used in PySpark Pipeline and PySpark ML meta algorithms like - :py:class:~pyspark.ml.tuning.CrossValidator/ - :py:class:~pyspark.ml.tuning.TrainValidationSplit/ - :py:class:~pyspark.ml.classification.OneVsRest\nSparkXGBRegressor automatically supports most of the parameters in :py:class:xgboost.XGBRegressor constructor and most of the parameters used in :py:meth:xgboost.XGBRegressor.fit and :py:meth:xgboost.XGBRegressor.predict method.\nTo enable GPU support, set device to cuda or gpu.\nSparkXGBRegressor doesn’t support setting base_margin explicitly as well, but support another param called base_margin_col. see doc below for more details.\nSparkXGBRegressor doesn’t support validate_features and output_margin param.\nSparkXGBRegressor doesn’t support setting nthread xgboost param, instead, the nthread param for each xgboost worker will be set equal to spark.task.cpus config value.\n\n\n\n\nGive us a ⭐ on Github"
  }
]