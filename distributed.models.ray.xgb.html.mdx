---
description: ray XGBoost forecaster
output-file: distributed.models.ray.xgb.html
title: RayXGBForecast
---


Wrapper of `xgboost.ray.RayXGBRegressor` that adds a `model_` property
that contains the fitted model and is sent to the workers in the
forecasting step.

------------------------------------------------------------------------

<a
href="https://github.com/Nixtla/mlforecast/blob/main/mlforecast/distributed/models/ray/xgb.py#L11"
target="_blank" style={{ float: "right", fontSize: "smaller" }}>source</a>

### RayXGBForecast

> ``` text
>  RayXGBForecast (objective:Union[str,xgboost.sklearn._SklObjWProto,Callabl
>                  e[[Any,Any],Tuple[numpy.ndarray,numpy.ndarray]],NoneType]
>                  ='reg:squarederror', **kwargs:Any)
> ```

*Implementation of the scikit-learn API for Ray-distributed XGBoost
regression. See :doc:`/python/sklearn_estimator` for more information.*

|  | **Type** | **Default** | **Details** |
|------|------------------|-------------------------|-------------------------|
| objective | Union | reg:squarederror | Specify the learning task and the corresponding learning objective or a custom<br/>objective function to be used.<br/><br/>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br/>:ref:`custom-obj-metric` for more information, along with the end note for<br/>function signatures. |
| kwargs | Any |  | Keyword arguments for XGBoost Booster object. Full documentation of parameters<br/>can be found :doc:`here </parameter>`.<br/>Attempting to set a parameter via the constructor args and \*\*kwargs<br/>dict simultaneously will result in a TypeError.<br/><br/>.. note:: \*\*kwargs unsupported by scikit-learn<br/><br/> \*\*kwargs is unsupported by scikit-learn. We do not guarantee<br/> that parameters passed via this argument will interact properly<br/> with scikit-learn.<br/><br/>.. note:: Custom objective function<br/><br/> A custom objective function can be provided for the `objective`<br/> parameter. In this case, it should have the signature `objective(y_true,<br/>    y_pred) -> [grad, hess]` or `objective(y_true, y_pred, *, sample_weight)<br/>    -> [grad, hess]`:<br/><br/> y_true: array_like of shape \[n_samples\]<br/> The target values<br/> y_pred: array_like of shape \[n_samples\]<br/> The predicted values<br/> sample_weight :<br/> Optional sample weights.<br/><br/> grad: array_like of shape \[n_samples\]<br/> The value of the gradient for each sample point.<br/> hess: array_like of shape \[n_samples\]<br/> The value of the second derivative for each sample point |
| **Returns** | **None** |  |  |

