---

title: XGBForecast


keywords: fastai
sidebar: home_sidebar

summary: "XGBoost forecaster"
description: "XGBoost forecaster"
nb_path: "nbs/distributed.models.xgb.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/distributed.models.xgb.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wrapper of <code>xgboost.dask.DaskXGBRegressor</code> that adds a <code>model_</code> property that contains the fitted model and is sent to the workers in the forecasting step.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="XGBForecast" class="doc_header"><code>class</code> <code>XGBForecast</code><a href="https://github.com/Nixtla/mlforecast/tree/main/mlforecast/distributed/models/xgb.py#L10" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>XGBForecast</code>(<strong><code>max_depth</code></strong>=<em><code>None</code></em>, <strong><code>learning_rate</code></strong>=<em><code>None</code></em>, <strong><code>n_estimators</code></strong>=<em><code>100</code></em>, <strong><code>verbosity</code></strong>=<em><code>None</code></em>, <strong><code>objective</code></strong>=<em><code>None</code></em>, <strong><code>booster</code></strong>=<em><code>None</code></em>, <strong><code>tree_method</code></strong>=<em><code>None</code></em>, <strong><code>n_jobs</code></strong>=<em><code>None</code></em>, <strong><code>gamma</code></strong>=<em><code>None</code></em>, <strong><code>min_child_weight</code></strong>=<em><code>None</code></em>, <strong><code>max_delta_step</code></strong>=<em><code>None</code></em>, <strong><code>subsample</code></strong>=<em><code>None</code></em>, <strong><code>colsample_bytree</code></strong>=<em><code>None</code></em>, <strong><code>colsample_bylevel</code></strong>=<em><code>None</code></em>, <strong><code>colsample_bynode</code></strong>=<em><code>None</code></em>, <strong><code>reg_alpha</code></strong>=<em><code>None</code></em>, <strong><code>reg_lambda</code></strong>=<em><code>None</code></em>, <strong><code>scale_pos_weight</code></strong>=<em><code>None</code></em>, <strong><code>base_score</code></strong>=<em><code>None</code></em>, <strong><code>random_state</code></strong>=<em><code>None</code></em>, <strong><code>missing</code></strong>=<em><code>nan</code></em>, <strong><code>num_parallel_tree</code></strong>=<em><code>None</code></em>, <strong><code>monotone_constraints</code></strong>=<em><code>None</code></em>, <strong><code>interaction_constraints</code></strong>=<em><code>None</code></em>, <strong><code>importance_type</code></strong>=<em><code>'gain'</code></em>, <strong><code>gpu_id</code></strong>=<em><code>None</code></em>, <strong><code>validate_parameters</code></strong>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>DaskXGBRegressor</code></p>
</blockquote>
<p>Implementation of the Scikit-Learn API for XGBoost.</p>
<h2 id="Parameters">Parameters<a class="anchor-link" href="#Parameters"> </a></h2>
<pre><code>n_estimators : int
    Number of gradient boosted trees.  Equivalent to number of boosting
    rounds.

max_depth : int
    Maximum tree depth for base learners.
learning_rate : float
    Boosting learning rate (xgb's "eta")
verbosity : int
    The degree of verbosity. Valid values are 0 (silent) - 3 (debug).
objective : string or callable
    Specify the learning task and the corresponding learning objective or
    a custom objective function to be used (see note below).
booster: string
    Specify which booster to use: gbtree, gblinear or dart.
tree_method: string
    Specify which tree method to use.  Default to auto.  If this parameter
    is set to default, XGBoost will choose the most conservative option
    available.  It's recommended to study this option from parameters
    document.
n_jobs : int
    Number of parallel threads used to run xgboost.  When used with other Scikit-Learn
    algorithms like grid search, you may choose which algorithm to parallelize and
    balance the threads.  Creating thread contention will significantly slow down both
    algorithms.
gamma : float
    Minimum loss reduction required to make a further partition on a leaf
    node of the tree.
min_child_weight : float
    Minimum sum of instance weight(hessian) needed in a child.
max_delta_step : float
    Maximum delta step we allow each tree's weight estimation to be.
subsample : float
    Subsample ratio of the training instance.
colsample_bytree : float
    Subsample ratio of columns when constructing each tree.
colsample_bylevel : float
    Subsample ratio of columns for each level.
colsample_bynode : float
    Subsample ratio of columns for each split.
reg_alpha : float (xgb's alpha)
    L1 regularization term on weights
reg_lambda : float (xgb's lambda)
    L2 regularization term on weights
scale_pos_weight : float
    Balancing of positive and negative weights.
base_score:
    The initial prediction score of all instances, global bias.
random_state : int
    Random number seed.

    .. note::

       Using gblinear booster with shotgun updater is nondeterministic as
       it uses Hogwild algorithm.

missing : float, default np.nan
    Value in the data which needs to be present as a missing value.
num_parallel_tree: int
    Used for boosting random forest.
monotone_constraints : str
    Constraint of variable monotonicity.  See tutorial for more
    information.
interaction_constraints : str
    Constraints for interaction representing permitted interactions.  The
    constraints must be specified in the form of a nest list, e.g. [[0, 1],
    [2, 3, 4]], where each inner list is a group of indices of features
    that are allowed to interact with each other.  See tutorial for more
    information
importance_type: string, default "gain"
    The feature importance type for the feature_importances\_ property:
    either "gain", "weight", "cover", "total_gain" or "total_cover".
gpu_id :
    Device ordinal.
validate_parameters :
    Give warnings for unknown parameter.

\*\*kwargs : dict, optional
    Keyword arguments for XGBoost Booster object.  Full documentation of
    parameters can be found here:
    https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.
    Attempting to set a parameter via the constructor args and \*\*kwargs
    dict simultaneously will result in a TypeError.

    .. note:: \*\*kwargs unsupported by scikit-learn

        \*\*kwargs is unsupported by scikit-learn.  We do not guarantee
        that parameters passed via this argument will interact properly
        with scikit-learn.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dask</span>
<span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">mlforecast.core</span> <span class="kn">import</span> <span class="n">TimeSeries</span>
<span class="kn">from</span> <span class="nn">mlforecast.distributed.forecast</span> <span class="kn">import</span> <span class="n">DistributedForecast</span>
<span class="kn">from</span> <span class="nn">mlforecast.utils</span> <span class="kn">import</span> <span class="n">generate_daily_series</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">series</span> <span class="o">=</span> <span class="n">generate_daily_series</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">distr_series</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">npartitions</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fcst</span> <span class="o">=</span> <span class="n">DistributedForecast</span><span class="p">(</span>
    <span class="n">XGBForecast</span><span class="p">(),</span>
    <span class="n">TimeSeries</span><span class="p">(</span><span class="n">lags</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">])</span>
<span class="p">)</span>
<span class="n">fcst</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">distr_series</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">fcst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_updates</span><span class="p">(</span><span class="n">ts</span><span class="p">):</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">_predict_setup</span><span class="p">()</span>
    <span class="n">upd</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">_update_features</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">upd</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">upd_futures</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">get_updates</span><span class="p">,</span> <span class="n">fcst</span><span class="o">.</span><span class="n">dts</span><span class="o">.</span><span class="n">ts</span><span class="p">)</span>
<span class="n">upd_ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_delayed</span><span class="p">(</span><span class="n">upd_futures</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">fcst</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">upd_ddf</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">actual</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

