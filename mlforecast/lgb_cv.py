# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/lgb_cv.ipynb.

# %% auto 0
__all__ = ['LightGBMCV']

# %% ../nbs/lgb_cv.ipynb 3
import copy
import os
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union

import lightgbm as lgb
import numpy as np
import pandas as pd

from . import Forecast, TimeSeries
from .utils import backtest_splits

# %% ../nbs/lgb_cv.ipynb 4
class EarlyStopException(BaseException):
    ...


def _mape(y_true, y_pred):
    abs_pct_err = abs(y_true - y_pred) / y_true
    return (
        abs_pct_err.groupby(y_true.index.get_level_values(0), observed=True)
        .mean()
        .mean()
    )


def _rmse(y_true, y_pred):
    sq_err = (y_true - y_pred) ** 2
    return (
        sq_err.groupby(y_true.index.get_level_values(0), observed=True)
        .mean()
        .pow(0.5)
        .mean()
    )


def _update(bst, n):
    for _ in range(n):
        bst.update()


def _predict(ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs):
    preds = ts.predict(bst, h, dynamic_dfs, predict_fn, **predict_fn_kwargs).set_index(
        time_col, append=True
    )
    preds = preds.join(valid)
    return preds


def _update_and_predict(
    ts, bst, valid, n, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs
):
    _update(bst, n)
    return _predict(
        ts, bst, valid, h, time_col, dynamic_dfs, predict_fn, **predict_fn_kwargs
    )

# %% ../nbs/lgb_cv.ipynb 5
class LightGBMCV:
    def __init__(
        self,
        freq: Optional[str] = None,  # pandas offset alias, e.g. D, W, M
        lags: List[int] = [],  # list of lags to use as features
        lag_transforms: Dict[
            int, List[Tuple]
        ] = {},  # list of transformations to apply to each lag
        date_features: List[
            str
        ] = [],  # list of names of pandas date attributes to use as features, e.g. dayofweek
        num_threads: int = 1,  # number of threads to use when computing the predictions of each window.
    ):
        self.num_threads = num_threads
        cpu_count = os.cpu_count()
        if cpu_count is None:
            num_cpus = 1
        else:
            num_cpus = cpu_count
        self.bst_threads = num_cpus // num_threads
        self.ts = TimeSeries(
            freq, lags, lag_transforms, date_features, self.bst_threads
        )

    def _should_stop(self, hist, early_stopping_evals, early_stopping_pct):
        if len(hist) < early_stopping_evals + 1:
            return False
        improvement_pct = 1 - hist[-1][1] / hist[-(early_stopping_evals + 1)][1]
        return improvement_pct < early_stopping_pct

    def fit(
        self,
        data: pd.DataFrame,  # time series
        n_windows: int,  # number of windows to evaluate
        window_size: int,  # test size in each window
        params: Dict[str, Any] = {},  # lightgbm parameters
        id_col: str = "index",  # column that identifies each serie, can also be the index.
        time_col: str = "ds",  # column with the timestamps
        target_col: str = "y",  # column with the series values
        static_features: Optional[
            List[str]
        ] = None,  # column names of the features that don't change in time
        dropna: bool = True,  # drop rows with missing values created by lags
        keep_last_n: Optional[
            int
        ] = None,  # keep only this many observations of each serie for computing the updates
        dynamic_dfs: Optional[
            List[pd.DataFrame]
        ] = None,  # future values for dynamic features
        weights: Sequence[float] = None,  # weight for each window
        eval_every: int = 10,  # number of iterations to train before evaluating the full window
        fit_on_all: bool = False,  # return model fitted on all data
        compute_cv_preds: bool = False,  # compute predictions on all folds using final models
        verbose_eval: bool = True,  # print evaluation metrics
        metric: Union[str, Callable] = "mape",  # evaluation metric
        early_stopping_evals: int = 2,  # stop if the score doesn't improve in these many evaluations
        early_stopping_pct: float = 0.01,  # score must improve at least in this percentage to keep training
        predict_fn: Optional[Callable] = None,  # custom function to compute predictions
        **predict_fn_kwargs,  # additional arguments passed to predict_fn
    ):
        if eval_every <= 0:
            raise ValueError(
                "eval_every should be > 0. If you don't want to evaluate the complete horizon use "
                "Forecast.cross_validation instead."
            )
        if weights is None:
            use_weights = np.full(n_windows, 1 / n_windows)
        elif len(weights) != n_windows:
            raise ValueError("Must specify as many weights as the number of windows")
        else:
            use_weights = np.asarray(weights)
        metric2fn = {"mape": _mape, "rmse": _rmse}
        if callable(metric):
            metric_fn = metric
            metric_name = "metric"
        else:
            if metric not in metric2fn:
                raise ValueError(
                    f'{metric} is not one of the implemented metrics: ({", ".join(metric2fn.keys())})'
                )
            metric_fn = metric2fn[metric]
            metric_name = metric

        if id_col != "index":
            data = data.set_index(id_col)

        if np.issubdtype(data["ds"].dtype.type, np.integer):
            freq = 1
        else:
            freq = self.ts.freq
        items = []
        for _, train, valid in backtest_splits(data, n_windows, window_size, freq):
            ts = copy.deepcopy(self.ts)
            prep = ts.fit_transform(
                train,
                id_col,
                time_col,
                target_col,
                static_features,
                dropna,
                keep_last_n,
            )
            ds = lgb.Dataset(
                prep.drop(columns=[time_col, target_col]), prep[target_col]
            ).construct()
            bst = lgb.Booster({**params, "num_threads": self.bst_threads}, ds)
            bst.predict = partial(bst.predict, num_threads=self.bst_threads)
            valid = valid.set_index(time_col, append=True)
            items.append((ts, bst, valid))

        hist = []
        n_iter = lgb.basic._choose_param_value("num_iterations", params, 100)[
            "num_iterations"
        ]
        metric_values = np.empty(n_windows)

        if self.num_threads == 1:
            try:
                for i in range(0, n_iter, eval_every):
                    for j, (ts, bst, valid) in enumerate(items):
                        preds = _update_and_predict(
                            ts,
                            bst,
                            valid,
                            eval_every,
                            window_size,
                            time_col,
                            dynamic_dfs,
                            predict_fn,
                            **predict_fn_kwargs,
                        )
                        metric_values[j] = metric_fn(
                            preds[target_col], preds["Booster"]
                        )
                    metric_value = metric_values @ use_weights
                    rounds = eval_every + i
                    hist.append((rounds, metric_value))
                    if verbose_eval:
                        print(f"[{rounds:,d}] {metric_name}: {metric_value:,f}")
                    if self._should_stop(
                        hist, early_stopping_evals, early_stopping_pct
                    ):
                        raise EarlyStopException
            except EarlyStopException:
                print(f"Early stopping at round {rounds:,}")
        else:
            try:
                with ThreadPoolExecutor(self.num_threads) as executor:
                    for i in range(0, n_iter, eval_every):
                        futures = []
                        for ts, bst, valid in items:
                            _update(bst, eval_every)
                            future = executor.submit(
                                _predict,
                                ts,
                                bst,
                                valid,
                                window_size,
                                time_col,
                                dynamic_dfs,
                                predict_fn,
                                **predict_fn_kwargs,
                            )
                            futures.append(future)
                        cv_preds = [f.result() for f in futures]
                        metric_values[:] = [
                            metric_fn(preds[target_col], preds["Booster"])
                            for preds in cv_preds
                        ]
                        metric_value = metric_values @ use_weights
                        rounds = eval_every + i
                        hist.append((rounds, metric_value))
                        if verbose_eval:
                            print(f"[{rounds:,d}] {metric_name}: {metric_value:,f}")
                        if self._should_stop(
                            hist, early_stopping_evals, early_stopping_pct
                        ):
                            raise EarlyStopException
            except EarlyStopException:
                print(f"Early stopping at round {rounds:,}.")

        self.cv_models_ = [item[1] for item in items]
        if compute_cv_preds:
            with ThreadPoolExecutor(self.num_threads) as executor:
                futures = []
                for ts, bst, valid in items:
                    future = executor.submit(
                        _predict,
                        ts,
                        bst,
                        valid,
                        window_size,
                        time_col,
                        dynamic_dfs,
                        predict_fn,
                        **predict_fn_kwargs,
                    )
                    futures.append(future)
                self.cv_preds_ = [f.result() for f in futures]

        if fit_on_all:
            params["num_iterations"] = rounds
            self.fcst = Forecast([])
            self.fcst.ts = self.ts
            self.fcst.models = [lgb.LGBMRegressor(**params)]
            self.fcst.fit(
                data,
                id_col,
                time_col,
                target_col,
                static_features,
                dropna,
                keep_last_n,
            )
        else:
            self.ts._fit(
                data, id_col, time_col, target_col, static_features, keep_last_n
            )
        return hist

    def predict(
        self,
        horizon: int,  # number of periods to predict in the future
        dynamic_dfs: Optional[
            List[pd.DataFrame]
        ] = None,  # future values for dynamic features
        predict_fn: Optional[Callable] = None,  # custom function to compute predictions
        **predict_fn_kwargs,  # additional arguments passed to predict_fn
    ) -> pd.DataFrame:
        """Computes the predictions of the final model trained using all of the data."""
        if not hasattr(self, "fcst"):
            raise ValueError(
                "Must call fit with fit_on_all=True before. Did you mean cv_predict?"
            )
        return self.fcst.predict(horizon, dynamic_dfs, predict_fn, **predict_fn_kwargs)

    def cv_predict(
        self,
        horizon: int,  # number of periods to predict in the future
        dynamic_dfs: Optional[
            List[pd.DataFrame]
        ] = None,  # future values for dynamic features
        predict_fn: Optional[Callable] = None,  # custom function to compute predictions
        **predict_fn_kwargs,  # additional arguments passed to predict_fn
    ) -> pd.DataFrame:
        """Computes the predictions of the models fitted during the CV step."""
        return self.ts.predict(self.cv_models_, horizon)
