# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/distributed.forecast.ipynb (unless otherwise specified).

__all__ = ['DistributedForecast']

# Cell
from typing import Generator, Optional

import dask.dataframe as dd
from dask.distributed import Client, default_client

from ..utils import backtest_splits
from .core import DistributedTimeSeries


# Cell
class DistributedForecast:
    """Full pipeline encapsulation.

    Takes a model (`LGBMForecast` or `XGBForecast`), a flow configuration and a client."""

    def __init__(
        self, model, dts: DistributedTimeSeries, client: Optional[Client] = None
    ):
        self.model = model
        self.dts = dts
        self.client = client or default_client()
        self.model.client = self.client

    def __repr__(self) -> str:
        return f'DistributedForecast(model={self.model}, dts={self.dts})'

    def preprocess(self, data: dd.DataFrame) -> dd.DataFrame:
        """Applies `prep_fn(partition, **self.flow_config)` on each partition of `data`.

        Saves the resulting `TimeSeries` objects as well as the divisions in `data` for the forecasting step.
        Returns a dask dataframe with the computed features."""
        self.data_divisions = data.divisions
        return self.dts.fit_transform(data)

    def fit(
        self,
        data: dd.DataFrame,
        **fit_kwargs,
    ) -> 'DistributedForecast':
        """Perform the preprocessing and fit the model."""
        train_ddf = self.preprocess(data)
        X, y = train_ddf.drop(columns=['ds', 'y']), train_ddf.y
        self.model.fit(X, y, **fit_kwargs)
        return self

    def predict(self, horizon: int, **kwargs) -> dd.DataFrame:
        """Compute the predictions for the next `horizon` steps using `predict_fn`."""
        return self.dts.predict(self.model.model_, horizon, **kwargs)

    def backtest(
        self,
        data: dd.DataFrame,
        n_windows: int,
        window_size: int,
        **predict_kwargs,
    ) -> Generator[dd.DataFrame, None, None]:
        """Creates `n_windows` splits of `window_size` from `data`, trains the model
        on the training set, predicts the window and merges the actuals and the predictions
        in a dataframe.

        Returns a generator to the dataframes containing the datestamps, actual values
        and predictions."""
        for train, valid in backtest_splits(data, n_windows, window_size):
            self.fit(train)
            y_pred = self.predict(window_size, **predict_kwargs)
            y_valid = valid[['ds', 'y']]
            result = y_valid.merge(y_pred, on=['unique_id', 'ds'], how='left')
            yield result
