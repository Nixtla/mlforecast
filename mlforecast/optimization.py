# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/optimization.ipynb.

# %% auto 0
__all__ = ['mlforecast_objective']

# %% ../nbs/optimization.ipynb 3
import copy
from typing import Any, Callable, Dict, Optional

import numpy as np
import optuna
import utilsforecast.processing as ufp
from sklearn.base import BaseEstimator, clone
from utilsforecast.compat import DataFrame

from . import MLForecast
from .compat import CatBoostRegressor
from .core import Freq

# %% ../nbs/optimization.ipynb 4
_TrialToConfig = Callable[[optuna.Trial], Dict[str, Any]]

# %% ../nbs/optimization.ipynb 5
def mlforecast_objective(
    df: DataFrame,
    config_fn: _TrialToConfig,
    loss: Callable,
    model: BaseEstimator,
    freq: Freq,
    n_windows: int,
    h: int,
    id_col: str = "unique_id",
    time_col: str = "ds",
    target_col: str = "y",
) -> Callable[[optuna.Trial], float]:
    """optuna objective function for the MLForecast class

    Parameters
    ----------
    config_fn : callable
        Function that takes an optuna trial and produces a configuration with the following keys:
        - model_params
        - mlf_init_params
        - mlf_fit_params
    loss : callable
        Function that takes the validation and train dataframes and produces a float.
    model : BaseEstimator
        scikit-learn compatible model to be trained
    freq : str or int
        pandas' or polars' offset alias or integer denoting the frequency of the series.
    n_windows : int
        Number of windows to evaluate.
    h : int
        Forecast horizon.
    id_col : str (default='unique_id')
        Column that identifies each serie.
    time_col : str (default='ds')
        Column that identifies each timestep, its values can be timestamps or integers.
    target_col : str (default='y')
        Column that contains the target.
    study_kwargs : dict, optional (default=None)
    """

    def objective(trial: optuna.Trial) -> float:
        config = config_fn(trial)
        trial.set_user_attr("config", copy.deepcopy(config))
        if all(
            config["mlf_init_params"].get(k, None) is None
            for k in ["lags", "lag_transforms", "date_features"]
        ):
            # no features
            return np.inf
        splits = ufp.backtest_splits(
            df,
            n_windows=n_windows,
            h=h,
            id_col=id_col,
            time_col=time_col,
            freq=freq,
        )
        model_copy = clone(model)
        model_params = config["model_params"]
        if config["mlf_fit_params"].get("static_features", []) and isinstance(
            model, CatBoostRegressor
        ):
            # catboost needs the categorical features in the init signature
            # we assume all statics are categoricals
            model_params["cat_features"] = config["mlf_fit_params"]["static_features"]
        model_copy.set_params(**config["model_params"])
        metrics = []
        for i, (_, train, valid) in enumerate(splits):
            mlf = MLForecast(
                models={"model": model_copy},
                freq=freq,
                **config["mlf_init_params"],
            )
            mlf.fit(
                train,
                id_col=id_col,
                time_col=time_col,
                target_col=target_col,
                **config["mlf_fit_params"],
            )
            static = [c for c in mlf.ts.static_features_.columns if c != id_col]
            dynamic = [
                c
                for c in valid.columns
                if c not in static + [id_col, time_col, target_col]
            ]
            if dynamic:
                X_df: Optional[DataFrame] = ufp.drop_columns(
                    valid, static + [target_col]
                )
            else:
                X_df = None
            preds = mlf.predict(h=h, X_df=X_df)
            result = ufp.join(
                valid[[id_col, time_col, target_col]],
                preds,
                on=[id_col, time_col],
            )
            if result.shape[0] < valid.shape[0]:
                raise ValueError(
                    "Cross validation result produced less results than expected. "
                    "Please verify that the passed frequency (freq) matches your series' "
                    "and that there aren't any missing periods."
                )
            metric = loss(result, train_df=train)
            metrics.append(metric)
            trial.report(metric, step=i)
            if trial.should_prune():
                raise optuna.TrialPruned()
        return np.mean(metrics).item()

    return objective
