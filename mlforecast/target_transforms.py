# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/target_transforms.ipynb.

# %% auto 0
__all__ = ['BaseTargetTransform', 'Differences', 'LocalStandardScaler']

# %% ../nbs/target_transforms.ipynb 2
import abc
import reprlib
from typing import TYPE_CHECKING, Iterable, Optional

if TYPE_CHECKING:
    import pandas as pd
import numpy as np
from numba import njit

from .grouped_array import GroupedArray, _apply_difference

# %% ../nbs/target_transforms.ipynb 3
class BaseTargetTransform(abc.ABC):
    idxs: Optional[np.ndarray] = None

    def set_column_names(self, id_col: str, time_col: str, target_col: str):
        self.id_col = id_col
        self.time_col = time_col
        self.target_col = target_col

    @abc.abstractmethod
    def fit_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        raise NotImplementedError

    @abc.abstractmethod
    def inverse_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        raise NotImplementedError

# %% ../nbs/target_transforms.ipynb 4
class Differences(BaseTargetTransform):
    def __init__(self, differences: Iterable[int]):
        self.differences = list(differences)

    def fit_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        ga = GroupedArray.from_sorted_df(df, self.id_col, self.target_col)
        uids = df[self.id_col].unique()
        original_sizes = ga.indptr[1:].cumsum()
        total_diffs = sum(self.differences)
        small_series = uids[original_sizes < total_diffs]
        if small_series.size:
            msg = reprlib.repr(small_series.tolist())
            raise ValueError(
                f"The following series are too short for the differences: {msg}"
            )
        self.original_values_ = []
        n_series = len(ga.indptr) - 1
        for d in self.differences:
            new_data = np.empty_like(ga.data, shape=n_series * d)
            new_indptr = d * np.arange(n_series + 1, dtype=np.int32)
            _apply_difference(ga.data, ga.indptr, new_data, new_indptr, d)
            self.original_values_.append(GroupedArray(new_data, new_indptr))
        df = df.copy(deep=False)
        df[self.target_col] = ga.data
        return df

    def inverse_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        model_cols = df.columns.drop([self.id_col, self.time_col])
        df = df.copy(deep=False)
        for model in model_cols:
            model_preds = df[model].values.copy()
            for d, ga in zip(
                reversed(self.differences), reversed(self.original_values_)
            ):
                if self.idxs is not None:
                    ga = ga[self.idxs]
                ga.restore_difference(model_preds, d)
            df[model] = model_preds
        return df

# %% ../nbs/target_transforms.ipynb 5
@njit
def _standard_scaler_transform(data, indptr, stats, out):
    n_series = len(indptr) - 1
    for i in range(n_series):
        sl = slice(indptr[i], indptr[i + 1])
        subs = data[sl]
        mean_ = subs.mean()
        std_ = subs.std()
        stats[i] = mean_, std_
        out[sl] = (data[sl] - mean_) / std_


@njit
def _standard_scaler_inverse_transform(preds, stats):
    n_series = stats.shape[0]
    h = preds.size // n_series
    k = 0
    for i in range(n_series):
        mean_, std_ = stats[i]
        for _ in range(h):
            preds[k] = preds[k] * std_ + mean_
            k += 1

# %% ../nbs/target_transforms.ipynb 6
class LocalStandardScaler(BaseTargetTransform):
    """Standardizes each serie by subtracting its mean and dividing by its standard deviation."""

    def fit_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        ga = GroupedArray.from_sorted_df(df, self.id_col, self.target_col)
        self.stats_ = np.empty((len(ga.indptr) - 1, 2))
        out = np.empty_like(ga.data)
        _standard_scaler_transform(ga.data, ga.indptr, self.stats_, out)
        df = df.copy(deep=False)
        df[self.target_col] = out
        return df

    def inverse_transform(self, df: "pd.DataFrame") -> "pd.DataFrame":
        df = df.copy(deep=False)
        model_cols = df.columns.drop([self.id_col, self.time_col])
        stats = self.stats_ if self.idxs is None else self.stats_[self.idxs]
        for model in model_cols:
            model_preds = df[model].values
            _standard_scaler_inverse_transform(model_preds, stats)
            df[model] = model_preds
        return df
